# Data Preparation Guide for Surya Fine-tuning

This directory contains data and utilities for preparing fine-tuning datasets for Surya models. Follow these instructions to prepare your data for fine-tuning.

## Directory Structure

When preparing data for fine-tuning, you should organize it in the following structure:

```
data/
├── layout/              # For layout model fine-tuning
│   ├── images/          # Document page images
│   ├── annotations/     # Layout annotations
│   └── splits/          # Train/val/test splits
│
├── ocr/                 # For OCR model fine-tuning
│   ├── line_crops/      # Cropped line images
│   ├── transcriptions/  # Ground truth text for each line
│   └── splits/          # Train/val/test splits
│
└── detection/           # For detection model fine-tuning
    ├── region_crops/    # Region crops for line detection
    ├── line_annotations/# Line detection annotations
    └── splits/          # Train/val/test splits
```

## Data Preparation

### OCR Model Data

The OCR model fine-tuning requires paired line images and text transcriptions:

1. **Line Images**: Cropped images of text lines from document pages
2. **Transcriptions**: Accurate text content for each line

You can automatically extract this data from PDFs using the `prepare_data.py` script:

```bash
python finetuning/scripts/prepare_data.py --mode ocr --input_dir path/to/pdfs --output_dir finetuning/data/ocr
```

After running the script, you should:

1. **Review the extracted line crops** in `line_crops/` to ensure they're properly cropped
2. **Check and correct the transcriptions** in `transcriptions/` to ensure accurate ground truth
   - The quality of your OCR fine-tuning depends heavily on accurate transcriptions
   - Consider using the correction tool in the `ocr_finetuning.ipynb` notebook

### Data Format Details

#### OCR Data Format

- **Line Crops**: PNG images of individual text lines
  - Filename format: `{document_name}_page_{page_num}_line_{line_num}.png`
  - Resolution should be high enough to clearly show text details

- **Transcriptions**: Plain text files with the exact text content
  - Filename format: `{document_name}_page_{page_num}_line_{line_num}.txt`
  - Must exactly match the corresponding line image
  - Avoid trailing whitespace or extra newlines

- **Splits**: JSON files defining train/val/test splits
  - Contains lists of line image paths and corresponding transcription paths
  - Automatically generated by the preparation script, but can be manually adjusted

## Manual Data Preparation

If you need to prepare data manually:

1. Create the necessary directory structure
2. Place line images in `line_crops/`
3. Create corresponding text files in `transcriptions/`
4. Create JSON split files in `splits/` with the following format:

```json
{
  "lines": [
    {
      "doc_name": "document1",
      "page_id": "0",
      "line_id": "document1_page_0_line_0",
      "image_path": "finetuning/data/ocr/line_crops/document1_page_0_line_0.png",
      "text_path": "finetuning/data/ocr/transcriptions/document1_page_0_line_0.txt",
      "text": "Example text content for this line"
    },
    ...
  ]
}
```

## Data Augmentation

For OCR fine-tuning, consider augmenting your data with:

1. **Character variations**: Include different fonts, styles, and sizes
2. **Background variations**: Include lines with different backgrounds
3. **Domain-specific text**: Include terminology specific to your domain
4. **Edge cases**: Include challenging OCR cases (low contrast, distortion)

The more diverse and representative your training data is, the better your fine-tuned model will perform on your specific documents.

## Next Steps

After preparing your data, use the appropriate fine-tuning script:

```bash
# For OCR model fine-tuning
python finetuning/scripts/finetune_ocr.py --data_dir finetuning/data/ocr --output_dir models/client_name/ocr
```