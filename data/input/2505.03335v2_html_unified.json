{
  "vertices": {
    "documents": [
      {
        "_key": "doc_0f099f71",
        "_id": "documents/doc_0f099f71",
        "title": "1 Absolute Zero Reasoner (AZR) achieves state-of-the-art performance with ZERO DATA. Without relying on any gold labels or human-defined queries, Absolute Zero Reasoner trained using our proposed self-play approach demonstrates impressive general reasoning capabilities improvements in both math and coding, despite operating entirely out-of-distribution. Remarkably, AZR surpasses models trained on tens of thousands of expert-labeled in-domain examples in the combined average score across both domains.",
        "source_file": "/home/graham/workspace/experiments/extractor/data/input/2505.03335v2.html",
        "format": "html",
        "created_at": "2025-06-12T05:27:34.562444"
      }
    ],
    "sections": [
      {
        "_key": "sec_b3c1564c",
        "_id": "sections/sec_b3c1564c",
        "title": "1Introduction",
        "level": 2,
        "content": "Large language models (LLMs) have recently achieved remarkable improvements in reasoning capabilities by employing Reinforcement Learning with Verifiable Rewards (RLVR)(Lambert et\u00a0al.,2024). Unlike methods that explicitly imitate intermediate reasoning steps, RLVR uses only outcome-based feedback, enabling large-scale reinforcement learning over vast task datasets(DeepSeek-AI et\u00a0al.,2025;Team et\u00a0al.,2025;Jaech et\u00a0al.,2024;OpenAI,2025b;a). A particularly compelling variant is the\u201czero\u201dRLVR paradigm(DeepSeek-AI et\u00a0al.,2025), which forgoes any cold-start distillation data, using neither human-generated nor AI-generated reasoning traces, and applies RLVR directly on the base model with task rewards. However, these methods still depend heavily on expertly curated distributions of reasoning question\u2013answer pairs, which raises serious concerns about their long-term scalability(Villalobos et\u00a0al.,2024). As reasoning models continue to advance, the effort required to construct large-scale, high-quality datasets may soon become unsustainable(Yue et\u00a0al.,2025). A similar scalability bottleneck has already been identified in the domain of LLM pretraining(Sutskever et\u00a0al.,2024). Furthermore, as AI systems continue to evolve and potentially exceed human intellect, an exclusive dependence on human-designed tasks risks imposing constraints on their capacity for autonomous learning and growth(Hughes et\u00a0al.,2024). This underscores the need for a new paradigm that begins to explore possibilities beyond the constraints of human-designed tasks and prepares for a future in which AI systems may surpass human intelligence. To this end, we propose\u201cAbsolute Zero\u201d, a new paradigm for reasoning models in which the model simultaneously learns to define tasks that maximize learnability and to solve them effectively, enabling self-evolution through self-play without relying on external data. In contrast to prior self-play methods that are limited to narrow domains, fixed functionalities, or learned reward models that are prone to hacking(Silver et\u00a0al.,2017;Chen et\u00a0al.,2025;2024), theAbsolute Zeroparadigm is designed to operate in open-ended settings while remaining grounded in a real environment. It relies on feedback from the environment as a verifiable source of reward, mirroring how humans learn and reason through interaction with the world, and helps prevent issues such as hacking with neural reward models(Hughes et\u00a0al.,2024). Similar to AlphaZero(Silver et\u00a0al.,2017), which improves through self-play, our proposed paradigm requires no human supervision and learns entirely through self-interaction. We believe the Absolute Zero paradigm represents a promising step toward enabling large language models to autonomously achieve superhuman reasoning capabilities. Building on this new reasoning paradigm, we introduce theAbsolute Zero Reasoner (AZR), which proposes and solves coding tasks. We cast code executor as an open-ended yet grounded environment, sufficient to both validate task integrity and also provide verifiable feedback for stable training. We let AZR construct three types of coding tasks: infer and reason about one particular element in a program, input, output triplet, which corresponds to three complementary modes of reasoning: induction, abduction, and deduction. We train the entire system end-to-end with a newly proposed reinforcement learning advantage estimator tailored to the multitask nature of the proposed approach. Despite being trained entirely without any in-distribution data, AZR demonstrates remarkable capabilities across diverse reasoning tasks in math and coding. In mathematics, AZR achieves competitive performance compared to zero reasoner models explicitly fine-tuned with domain-specific supervision. In coding tasks, AZR establishes a new state-of-the-art performance, surpassing models specifically trained with code datasets using RLVR. Furthermore, AZR outperforms all previous models by an average of 1.8 absolute points compared to models trained in the \u201czero\u201d setting using in-domain data. These surprising results highlight that general reasoning skills can emerge without human-curated domain targeted data, positioning Absolute Zero as an promising research direction and AZR as a first pivotal milestone. Besides the remarkable results AZR achieved with zero human data for reasoning, we also make very interesting findings summarized below:\u2022Code priors amplify reasoning.The baseQwen-Coder-7bmodel started with math performance 3.6 points lower thanQwen-7b. But after AZR training for both models, the coder variant surpassed the base by 0.7 points, suggesting that strong coding capabilities may potentially amplify overall reasoning improvements after AZR training.\u2022Cross domain transfer is more pronounced for AZR.After RLVR, expert code models raise math accuracy by only 0.65 points on average, whereasAZR-Base-7BandAZR-Coder-7Btrained on self-proposed code reasoning tasks improve math average by 10.9 and 15.2, respectively, demonstrating much stronger generalized reasoning capability gains.\u2022Bigger bases yield bigger gains.Performance improvements scale with model size: the 3B, 7B, and 14B coder models gain +5.7, +10.2, and +13.2 points respectively, suggesting continued scaling is advantageous for AZR.\u2022Comments as intermediate plans emerge naturally.When solving code induction tasks, AZR often interleaves step-by-step plans as comments and code (Figure19), resembling the ReAct prompting framework(Yao et\u00a0al.,2023). Similar behavior has been observed in much larger formal-math models such as DeepSeek Prover v2 (671B)(Ren et\u00a0al.,2025). We therefore believe that allowing the model to use intermediate scratch-pads when generating long-form answers may be beneficial in other domains as well.\u2022Cognitive Behaviors and Token length depends on reasoning mode.Distinct cognitive behaviors\u2014such as step-by-step reasoning, enumeration, and trial-and-error all emerged through AZR training, but different behaviors are particularly evident across different types of tasks. Furthermore token counts grow over AZR training, but the magnitude of increase also differs by task types: abduction grows the most because the model performs trial-and-error until output matches, whereas deduction and induction grow modestly.\u2022Safety alarms ringing.We observe AZR withLlama3.1-8boccasionally produces concerning chains of thought, we term the \u201cuh-oh moment\u201d, example shown inFigure32, highlighting the need for future work on safety-aware training(Zhang et\u00a0al.,2025a).",
        "parent": null
      },
      {
        "_key": "sec_f9e77f68",
        "_id": "sections/sec_f9e77f68",
        "title": "2The Absolute Zero Paradigm",
        "level": 2,
        "content": "2.1PreliminariesSupervised Fine-Tuning (SFT).SFT requires the datasets of task-rationale-answer demonstrations\ud835\udc9f={(x,c\u22c6,y\u22c6)}\ud835\udc9f\ud835\udc65superscript\ud835\udc50\u22c6superscript\ud835\udc66\u22c6\\mathcal{D}=\\{(x,c^{\\star},y^{\\star})\\}caligraphic_D = { ( italic_x , italic_c start_POSTSUPERSCRIPT \u22c6 end_POSTSUPERSCRIPT , italic_y start_POSTSUPERSCRIPT \u22c6 end_POSTSUPERSCRIPT ) }, wherex\ud835\udc65xitalic_xis the query,c\u22c6superscript\ud835\udc50\u22c6c^{\\star}italic_c start_POSTSUPERSCRIPT \u22c6 end_POSTSUPERSCRIPTis the gold chain-of-thought (CoT)) andy\u22c6superscript\ud835\udc66\u22c6y^{\\star}italic_y start_POSTSUPERSCRIPT \u22c6 end_POSTSUPERSCRIPTis the gold answer, all provided byhuman expertsorsuperior AI models. The model trains to imitate the reference responses to minimize the conditional negative log-likelihood(Ouyang et\u00a0al.,2022):\u2112SFT\u2062(\u03b8)=\u2212\ud835\udd3c(x,c\u22c6,y\u22c6)\u223c\ud835\udc9f\u2062log\u2061\u03c0\u03b8\u2062(c\u22c6,y\u22c6\u2223x).subscript\u2112SFT\ud835\udf03subscript\ud835\udd3csimilar-to\ud835\udc65superscript\ud835\udc50\u22c6superscript\ud835\udc66\u22c6\ud835\udc9fsubscript\ud835\udf0b\ud835\udf03superscript\ud835\udc50\u22c6conditionalsuperscript\ud835\udc66\u22c6\ud835\udc65\\displaystyle\\mathcal{L}_{\\text{SFT}}(\\theta)\\;=\\;-\\;\\mathbb{E}_{{\\color[rgb]{%\n0.70703125,0.1953125,0.1953125}\\definecolor[named]{pgfstrokecolor}{rgb}{%\n0.70703125,0.1953125,0.1953125}(x,c^{\\star},y^{\\star})\\sim\\mathcal{D}}}\\log\\pi%\n_{\\theta}\\;\\bigl{(}c^{\\star},y^{\\star}\\mid x).caligraphic_L start_POSTSUBSCRIPT SFT end_POSTSUBSCRIPT ( italic_\u03b8 ) = - blackboard_E start_POSTSUBSCRIPT ( italic_x , italic_c start_POSTSUPERSCRIPT \u22c6 end_POSTSUPERSCRIPT , italic_y start_POSTSUPERSCRIPT \u22c6 end_POSTSUPERSCRIPT ) \u223c caligraphic_D end_POSTSUBSCRIPT roman_log italic_\u03c0 start_POSTSUBSCRIPT italic_\u03b8 end_POSTSUBSCRIPT ( italic_c start_POSTSUPERSCRIPT \u22c6 end_POSTSUPERSCRIPT , italic_y start_POSTSUPERSCRIPT \u22c6 end_POSTSUPERSCRIPT \u2223 italic_x ) .(1)However, at the frontier level, there\u2019s no stronger model to distill from, and expert human labeling doesn\u2019t scale well.Reinforcement Learning with Verifiable Rewards (RLVR).To move beyond the limits of pure imitation, RLVR only requires a dataset of task and answer\ud835\udc9f={(x,y\u22c6)}\ud835\udc9f\ud835\udc65superscript\ud835\udc66\u22c6\\mathcal{D}=\\{(x,y^{\\star})\\}caligraphic_D = { ( italic_x , italic_y start_POSTSUPERSCRIPT \u22c6 end_POSTSUPERSCRIPT ) }, without labeled rationale. RLVR allows the model to generate its own CoT and calculate a verifiable reward with the golden answerr\u2062(y,y\u22c6)\ud835\udc5f\ud835\udc66superscript\ud835\udc66\u22c6r(y,y^{\\star})italic_r ( italic_y , italic_y start_POSTSUPERSCRIPT \u22c6 end_POSTSUPERSCRIPT ). However, the learning task distribution\ud835\udc9f\ud835\udc9f\\mathcal{D}caligraphic_D, with its set of queries and gold answers are still labeled byhuman experts.\nThe trainable policy\u03c0\u03b8subscript\ud835\udf0b\ud835\udf03\\pi_{\\theta}italic_\u03c0 start_POSTSUBSCRIPT italic_\u03b8 end_POSTSUBSCRIPTis optimized to maximize expected reward:JRLVR\u2062(\u03b8)=\ud835\udd3c(x,y\u22c6)\u223c\ud835\udc9f,y\u223c\u03c0\u03b8(\u22c5\u2223x)\u2062[r\u2062(y,y\u22c6)].\\displaystyle J_{\\text{RLVR}}(\\theta)\\,=\\;\\mathbb{E}_{{\\color[rgb]{%\n0.70703125,0.1953125,0.1953125}\\definecolor[named]{pgfstrokecolor}{rgb}{%\n0.70703125,0.1953125,0.1953125}(x,y^{\\star})\\sim\\mathcal{D}},\\;y\\sim\\pi_{%\n\\theta}(\\cdot\\ \\mid x)}\\bigl{[}r(y,y^{\\star})\\bigr{]}.italic_J start_POSTSUBSCRIPT RLVR end_POSTSUBSCRIPT ( italic_\u03b8 ) = blackboard_E start_POSTSUBSCRIPT ( italic_x , italic_y start_POSTSUPERSCRIPT \u22c6 end_POSTSUPERSCRIPT ) \u223c caligraphic_D , italic_y \u223c italic_\u03c0 start_POSTSUBSCRIPT italic_\u03b8 end_POSTSUBSCRIPT ( \u22c5 \u2223 italic_x ) end_POSTSUBSCRIPT [ italic_r ( italic_y , italic_y start_POSTSUPERSCRIPT \u22c6 end_POSTSUPERSCRIPT ) ] .(2)In summary, both SFT and RLVR still rely onhuman-curateddatasets of either queries, demonstrations, or verifiers, which ultimately limit scalability. The Absolute Zero paradigm removes this dependency by allowing the model to generate, solve, and learn from its own interactions with the environment entirely through self-play. 2.2Absolute ZeroWe propose the Absolute Zero paradigm, where during training, the model simultaneously proposes tasks, solves them, and learns from both stages. No external data is required and the model learns entirely through self-play and experience, aided by some environment. We illustrate this paradigm inFigure2, which contrasts Absolute Zero with supervised learning and RLVR, highlighting how our approach eliminates the need for any human-curated data by enabling self-improving task proposal and solution through self-play.To make the Absolute Zero setting concrete, we now define how one model can act both as the proposer and solver role. To aid understanding, we include an illustration inFigure3. Let\u03c0\u03b8subscript\ud835\udf0b\ud835\udf03\\pi_{\\theta}italic_\u03c0 start_POSTSUBSCRIPT italic_\u03b8 end_POSTSUBSCRIPTbe our parameterized language model, it is used to play two roles, proposer\u03c0\u03b8proposesuperscriptsubscript\ud835\udf0b\ud835\udf03propose\\pi_{\\theta}^{\\text{propose}}italic_\u03c0 start_POSTSUBSCRIPT italic_\u03b8 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT propose end_POSTSUPERSCRIPTand solver\u03c0\u03b8solvesuperscriptsubscript\ud835\udf0b\ud835\udf03solve\\pi_{\\theta}^{\\text{solve}}italic_\u03c0 start_POSTSUBSCRIPT italic_\u03b8 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT solve end_POSTSUPERSCRIPTduring training.Figure 3:The Absolute Zero Loop.The Absolute Zero loop begins with the agent\u03c0\ud835\udf0b\\piitalic_\u03c0proposing task\u03c4\ud835\udf0f\\tauitalic_\u03c4, which is transformed byf\ud835\udc53fitalic_fwith the environmente\ud835\udc52eitalic_einto a validated problem(x,y\u22c6)\ud835\udc65superscript\ud835\udc66\u22c6(x,y^{\\star})( italic_x , italic_y start_POSTSUPERSCRIPT \u22c6 end_POSTSUPERSCRIPT ), and also emits a rewardrproposesuperscript\ud835\udc5fproposer^{\\text{propose}}italic_r start_POSTSUPERSCRIPT propose end_POSTSUPERSCRIPTfor learnability. Then, a standard RL step follows: the agent solvesx\ud835\udc65xitalic_xby producingy\ud835\udc66yitalic_y, receiving rewardrsolvesuperscript\ud835\udc5fsolver^{\\text{solve}}italic_r start_POSTSUPERSCRIPT solve end_POSTSUPERSCRIPTfrome\ud835\udc52eitalic_eby matching withy\u22c6superscript\ud835\udc66\u22c6y^{\\star}italic_y start_POSTSUPERSCRIPT \u22c6 end_POSTSUPERSCRIPT.\u03c0proposesuperscript\ud835\udf0bpropose\\pi^{\\text{propose}}italic_\u03c0 start_POSTSUPERSCRIPT propose end_POSTSUPERSCRIPTand\u03c0solvesuperscript\ud835\udf0bsolve\\pi^{\\text{solve}}italic_\u03c0 start_POSTSUPERSCRIPT solve end_POSTSUPERSCRIPTare jointly trained and this process can be repeated indefinitely.The proposer first samples a proposed task conditioned on variablez\ud835\udc67zitalic_z:\u03c4\u223c\u03c0\u03b8propose(\u22c5|z)\\tau\\sim\\pi_{\\theta}^{\\text{propose}}(\\cdot|z)italic_\u03c4 \u223c italic_\u03c0 start_POSTSUBSCRIPT italic_\u03b8 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT propose end_POSTSUPERSCRIPT ( \u22c5 | italic_z ), which will then be validated and used to construct a valid reasoning task together with the environmente\ud835\udc52eitalic_e:(x,y\u22c6)\u223cfe(\u22c5|\u03c4)(x,y^{\\star})\\sim f_{e}(\\cdot|\\tau)( italic_x , italic_y start_POSTSUPERSCRIPT \u22c6 end_POSTSUPERSCRIPT ) \u223c italic_f start_POSTSUBSCRIPT italic_e end_POSTSUBSCRIPT ( \u22c5 | italic_\u03c4 ), wherex\ud835\udc65xitalic_xis the task query andy\u22c6superscript\ud835\udc66\u22c6y^{\\star}italic_y start_POSTSUPERSCRIPT \u22c6 end_POSTSUPERSCRIPTis the gold label. Then the solver produces an answery\u223c\u03c0\u03b8solve(\u22c5\u2223x)y\\sim\\pi_{\\theta}^{\\text{solve}}(\\,\\cdot\\mid x)italic_y \u223c italic_\u03c0 start_POSTSUBSCRIPT italic_\u03b8 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT solve end_POSTSUPERSCRIPT ( \u22c5 \u2223 italic_x ). Each proposed task\u03c4\ud835\udf0f\\tauitalic_\u03c4is scored by alearnability rewardrepropose\u2062(\u03c4,\u03c0\u03b8)subscriptsuperscript\ud835\udc5fpropose\ud835\udc52\ud835\udf0fsubscript\ud835\udf0b\ud835\udf03r^{\\text{propose}}_{e}(\\tau,\\pi_{\\theta})italic_r start_POSTSUPERSCRIPT propose end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_e end_POSTSUBSCRIPT ( italic_\u03c4 , italic_\u03c0 start_POSTSUBSCRIPT italic_\u03b8 end_POSTSUBSCRIPT ), which captures the expected improvement in\u03c0\u03b8subscript\ud835\udf0b\ud835\udf03\\pi_{\\theta}italic_\u03c0 start_POSTSUBSCRIPT italic_\u03b8 end_POSTSUBSCRIPTafter training on the task queryx\ud835\udc65xitalic_x. Moreover, the same policy also receives asolution rewardresolve\u2062(y,y\u22c6)subscriptsuperscript\ud835\udc5fsolve\ud835\udc52\ud835\udc66superscript\ud835\udc66\u22c6r^{\\text{solve}}_{e}(y,y^{\\star})italic_r start_POSTSUPERSCRIPT solve end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_e end_POSTSUBSCRIPT ( italic_y , italic_y start_POSTSUPERSCRIPT \u22c6 end_POSTSUPERSCRIPT )for its answer to the task queryx\ud835\udc65xitalic_x, with the environment again serving as the verifier. A nonnegative coefficient\u03bb\ud835\udf06\\lambdaitalic_\u03bbbalances the trade-off between exploring new, learnable tasks and improving the model\u2019s reasoning and problem-solving abilities. We formally define the absolute zero setting\u2019s objective as follows:\ud835\udca5\u2062(\u03b8)\u2254max\u03b8\u2061\ud835\udd3cz\u223cp\u2062(z)\u2062[\ud835\udd3c(x,y\u22c6)\u223cfe(\u22c5|\u03c4),\u03c4\u223c\u03c0\u03b8propose(\u22c5|z)\u2062[repropose\u2062(\u03c4,\u03c0\u03b8)+\u03bb\u2062\ud835\udd3cy\u223c\u03c0\u03b8solve(\u22c5\u2223x)\u2062[resolve\u2062(y,y\u22c6)]]].\\displaystyle\\mathcal{J}(\\theta)\\coloneqq\\max_{\\theta}\\;\\;\\mathbb{E}_{z\\sim p(%\nz)}\\Bigg{[}\\;\\mathbb{E}_{{\\color[rgb]{0.1953125,0.55078125,0.3125}\\definecolor%\n[named]{pgfstrokecolor}{rgb}{0.1953125,0.55078125,0.3125}(x,y^{\\star})\\sim f_{%\ne}(\\cdot|\\tau),\\tau\\sim\\pi_{\\theta}^{\\text{propose}}(\\cdot|z)}}\\bigg{[}r^{%\n\\text{propose}}_{{\\color[rgb]{0.1953125,0.55078125,0.3125}\\definecolor[named]{%\npgfstrokecolor}{rgb}{0.1953125,0.55078125,0.3125}e}}(\\tau,\\pi_{\\theta})+%\n\\lambda\\,\\mathbb{E}_{y\\sim\\pi_{\\theta}^{\\text{solve}}(\\cdot\\mid x)}\\big{[}r^{%\n\\text{solve}}_{{\\color[rgb]{0.1953125,0.55078125,0.3125}\\definecolor[named]{%\npgfstrokecolor}{rgb}{0.1953125,0.55078125,0.3125}e}}(y,y^{\\star})\\big{]}\\bigg{%\n]}\\Bigg{]}.caligraphic_J ( italic_\u03b8 ) \u2254 roman_max start_POSTSUBSCRIPT italic_\u03b8 end_POSTSUBSCRIPT blackboard_E start_POSTSUBSCRIPT italic_z \u223c italic_p ( italic_z ) end_POSTSUBSCRIPT [ blackboard_E start_POSTSUBSCRIPT ( italic_x , italic_y start_POSTSUPERSCRIPT \u22c6 end_POSTSUPERSCRIPT ) \u223c italic_f start_POSTSUBSCRIPT italic_e end_POSTSUBSCRIPT ( \u22c5 | italic_\u03c4 ) , italic_\u03c4 \u223c italic_\u03c0 start_POSTSUBSCRIPT italic_\u03b8 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT propose end_POSTSUPERSCRIPT ( \u22c5 | italic_z ) end_POSTSUBSCRIPT [ italic_r start_POSTSUPERSCRIPT propose end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_e end_POSTSUBSCRIPT ( italic_\u03c4 , italic_\u03c0 start_POSTSUBSCRIPT italic_\u03b8 end_POSTSUBSCRIPT ) + italic_\u03bb blackboard_E start_POSTSUBSCRIPT italic_y \u223c italic_\u03c0 start_POSTSUBSCRIPT italic_\u03b8 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT solve end_POSTSUPERSCRIPT ( \u22c5 \u2223 italic_x ) end_POSTSUBSCRIPT [ italic_r start_POSTSUPERSCRIPT solve end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_e end_POSTSUBSCRIPT ( italic_y , italic_y start_POSTSUPERSCRIPT \u22c6 end_POSTSUPERSCRIPT ) ] ] ] .(3)Notice that we shift the burden of scaling data away fromhuman expertsand onto theproposer policy\u03c0\u03b8proposesuperscriptsubscript\ud835\udf0b\ud835\udf03propose\\pi_{\\theta}^{\\text{propose}}italic_\u03c0 start_POSTSUBSCRIPT italic_\u03b8 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT propose end_POSTSUPERSCRIPTand theenvironmente\ud835\udc52eitalic_e. These two roles are both responsible for defining/evolving the learning task distribution, validating proposed tasks, and providing grounded feedback that supports stable and self-sustainable training. When proposing,z\ud835\udc67zitalic_zacts as a conditional variable that seeds generation of tasks. Practically,z\ud835\udc67zitalic_zcan be instantiated by sampling a small subset of past (task, answer) pairs from a continually updated task memory, yet there is no specific implementation tied to the paradigm. To guide the proposing process, we use a learnability rewardrpropose\u2062(\u03c4,\u03c0\u03b8)superscript\ud835\udc5fpropose\ud835\udf0fsubscript\ud835\udf0b\ud835\udf03r^{\\text{propose}}(\\tau,\\pi_{\\theta})italic_r start_POSTSUPERSCRIPT propose end_POSTSUPERSCRIPT ( italic_\u03c4 , italic_\u03c0 start_POSTSUBSCRIPT italic_\u03b8 end_POSTSUBSCRIPT ), which measures how much the model is expected to improve by solving a proposed task\u03c4\ud835\udf0f\\tauitalic_\u03c4. Moreover, the solver rewardrsolve\u2062(y,y\u2217)superscript\ud835\udc5fsolve\ud835\udc66superscript\ud835\udc66r^{\\text{solve}}(y,y^{*})italic_r start_POSTSUPERSCRIPT solve end_POSTSUPERSCRIPT ( italic_y , italic_y start_POSTSUPERSCRIPT \u2217 end_POSTSUPERSCRIPT )evaluates the correctness of the model\u2019s output. Together, these two signals guide the model to propose tasks that are both challenging and learnable, while also enhancing its reasoning abilities, ultimately enabling continuous improvement through self-play.",
        "parent": null
      },
      {
        "_key": "sec_157180aa",
        "_id": "sections/sec_157180aa",
        "title": "2.1Preliminaries",
        "level": 3,
        "content": "Supervised Fine-Tuning (SFT).SFT requires the datasets of task-rationale-answer demonstrations\ud835\udc9f={(x,c\u22c6,y\u22c6)}\ud835\udc9f\ud835\udc65superscript\ud835\udc50\u22c6superscript\ud835\udc66\u22c6\\mathcal{D}=\\{(x,c^{\\star},y^{\\star})\\}caligraphic_D = { ( italic_x , italic_c start_POSTSUPERSCRIPT \u22c6 end_POSTSUPERSCRIPT , italic_y start_POSTSUPERSCRIPT \u22c6 end_POSTSUPERSCRIPT ) }, wherex\ud835\udc65xitalic_xis the query,c\u22c6superscript\ud835\udc50\u22c6c^{\\star}italic_c start_POSTSUPERSCRIPT \u22c6 end_POSTSUPERSCRIPTis the gold chain-of-thought (CoT)) andy\u22c6superscript\ud835\udc66\u22c6y^{\\star}italic_y start_POSTSUPERSCRIPT \u22c6 end_POSTSUPERSCRIPTis the gold answer, all provided byhuman expertsorsuperior AI models. The model trains to imitate the reference responses to minimize the conditional negative log-likelihood(Ouyang et\u00a0al.,2022):\u2112SFT\u2062(\u03b8)=\u2212\ud835\udd3c(x,c\u22c6,y\u22c6)\u223c\ud835\udc9f\u2062log\u2061\u03c0\u03b8\u2062(c\u22c6,y\u22c6\u2223x).subscript\u2112SFT\ud835\udf03subscript\ud835\udd3csimilar-to\ud835\udc65superscript\ud835\udc50\u22c6superscript\ud835\udc66\u22c6\ud835\udc9fsubscript\ud835\udf0b\ud835\udf03superscript\ud835\udc50\u22c6conditionalsuperscript\ud835\udc66\u22c6\ud835\udc65\\displaystyle\\mathcal{L}_{\\text{SFT}}(\\theta)\\;=\\;-\\;\\mathbb{E}_{{\\color[rgb]{%\n0.70703125,0.1953125,0.1953125}\\definecolor[named]{pgfstrokecolor}{rgb}{%\n0.70703125,0.1953125,0.1953125}(x,c^{\\star},y^{\\star})\\sim\\mathcal{D}}}\\log\\pi%\n_{\\theta}\\;\\bigl{(}c^{\\star},y^{\\star}\\mid x).caligraphic_L start_POSTSUBSCRIPT SFT end_POSTSUBSCRIPT ( italic_\u03b8 ) = - blackboard_E start_POSTSUBSCRIPT ( italic_x , italic_c start_POSTSUPERSCRIPT \u22c6 end_POSTSUPERSCRIPT , italic_y start_POSTSUPERSCRIPT \u22c6 end_POSTSUPERSCRIPT ) \u223c caligraphic_D end_POSTSUBSCRIPT roman_log italic_\u03c0 start_POSTSUBSCRIPT italic_\u03b8 end_POSTSUBSCRIPT ( italic_c start_POSTSUPERSCRIPT \u22c6 end_POSTSUPERSCRIPT , italic_y start_POSTSUPERSCRIPT \u22c6 end_POSTSUPERSCRIPT \u2223 italic_x ) .(1)However, at the frontier level, there\u2019s no stronger model to distill from, and expert human labeling doesn\u2019t scale well. Reinforcement Learning with Verifiable Rewards (RLVR).To move beyond the limits of pure imitation, RLVR only requires a dataset of task and answer\ud835\udc9f={(x,y\u22c6)}\ud835\udc9f\ud835\udc65superscript\ud835\udc66\u22c6\\mathcal{D}=\\{(x,y^{\\star})\\}caligraphic_D = { ( italic_x , italic_y start_POSTSUPERSCRIPT \u22c6 end_POSTSUPERSCRIPT ) }, without labeled rationale. RLVR allows the model to generate its own CoT and calculate a verifiable reward with the golden answerr\u2062(y,y\u22c6)\ud835\udc5f\ud835\udc66superscript\ud835\udc66\u22c6r(y,y^{\\star})italic_r ( italic_y , italic_y start_POSTSUPERSCRIPT \u22c6 end_POSTSUPERSCRIPT ). However, the learning task distribution\ud835\udc9f\ud835\udc9f\\mathcal{D}caligraphic_D, with its set of queries and gold answers are still labeled byhuman experts.\nThe trainable policy\u03c0\u03b8subscript\ud835\udf0b\ud835\udf03\\pi_{\\theta}italic_\u03c0 start_POSTSUBSCRIPT italic_\u03b8 end_POSTSUBSCRIPTis optimized to maximize expected reward:JRLVR\u2062(\u03b8)=\ud835\udd3c(x,y\u22c6)\u223c\ud835\udc9f,y\u223c\u03c0\u03b8(\u22c5\u2223x)\u2062[r\u2062(y,y\u22c6)].\\displaystyle J_{\\text{RLVR}}(\\theta)\\,=\\;\\mathbb{E}_{{\\color[rgb]{%\n0.70703125,0.1953125,0.1953125}\\definecolor[named]{pgfstrokecolor}{rgb}{%\n0.70703125,0.1953125,0.1953125}(x,y^{\\star})\\sim\\mathcal{D}},\\;y\\sim\\pi_{%\n\\theta}(\\cdot\\ \\mid x)}\\bigl{[}r(y,y^{\\star})\\bigr{]}.italic_J start_POSTSUBSCRIPT RLVR end_POSTSUBSCRIPT ( italic_\u03b8 ) = blackboard_E start_POSTSUBSCRIPT ( italic_x , italic_y start_POSTSUPERSCRIPT \u22c6 end_POSTSUPERSCRIPT ) \u223c caligraphic_D , italic_y \u223c italic_\u03c0 start_POSTSUBSCRIPT italic_\u03b8 end_POSTSUBSCRIPT ( \u22c5 \u2223 italic_x ) end_POSTSUBSCRIPT [ italic_r ( italic_y , italic_y start_POSTSUPERSCRIPT \u22c6 end_POSTSUPERSCRIPT ) ] .(2)In summary, both SFT and RLVR still rely onhuman-curateddatasets of either queries, demonstrations, or verifiers, which ultimately limit scalability. The Absolute Zero paradigm removes this dependency by allowing the model to generate, solve, and learn from its own interactions with the environment entirely through self-play.",
        "parent": "sec_f9e77f68"
      },
      {
        "_key": "sec_ef8e3d10",
        "_id": "sections/sec_ef8e3d10",
        "title": "Supervised Fine-Tuning (SFT).",
        "level": 5,
        "content": "SFT requires the datasets of task-rationale-answer demonstrations\ud835\udc9f={(x,c\u22c6,y\u22c6)}\ud835\udc9f\ud835\udc65superscript\ud835\udc50\u22c6superscript\ud835\udc66\u22c6\\mathcal{D}=\\{(x,c^{\\star},y^{\\star})\\}caligraphic_D = { ( italic_x , italic_c start_POSTSUPERSCRIPT \u22c6 end_POSTSUPERSCRIPT , italic_y start_POSTSUPERSCRIPT \u22c6 end_POSTSUPERSCRIPT ) }, wherex\ud835\udc65xitalic_xis the query,c\u22c6superscript\ud835\udc50\u22c6c^{\\star}italic_c start_POSTSUPERSCRIPT \u22c6 end_POSTSUPERSCRIPTis the gold chain-of-thought (CoT)) andy\u22c6superscript\ud835\udc66\u22c6y^{\\star}italic_y start_POSTSUPERSCRIPT \u22c6 end_POSTSUPERSCRIPTis the gold answer, all provided byhuman expertsorsuperior AI models. The model trains to imitate the reference responses to minimize the conditional negative log-likelihood(Ouyang et\u00a0al.,2022): \u2112SFT\u2062(\u03b8)=\u2212\ud835\udd3c(x,c\u22c6,y\u22c6)\u223c\ud835\udc9f\u2062log\u2061\u03c0\u03b8\u2062(c\u22c6,y\u22c6\u2223x).subscript\u2112SFT\ud835\udf03subscript\ud835\udd3csimilar-to\ud835\udc65superscript\ud835\udc50\u22c6superscript\ud835\udc66\u22c6\ud835\udc9fsubscript\ud835\udf0b\ud835\udf03superscript\ud835\udc50\u22c6conditionalsuperscript\ud835\udc66\u22c6\ud835\udc65\\displaystyle\\mathcal{L}_{\\text{SFT}}(\\theta)\\;=\\;-\\;\\mathbb{E}_{{\\color[rgb]{%\n0.70703125,0.1953125,0.1953125}\\definecolor[named]{pgfstrokecolor}{rgb}{%\n0.70703125,0.1953125,0.1953125}(x,c^{\\star},y^{\\star})\\sim\\mathcal{D}}}\\log\\pi%\n_{\\theta}\\;\\bigl{(}c^{\\star},y^{\\star}\\mid x).caligraphic_L start_POSTSUBSCRIPT SFT end_POSTSUBSCRIPT ( italic_\u03b8 ) = - blackboard_E start_POSTSUBSCRIPT ( italic_x , italic_c start_POSTSUPERSCRIPT \u22c6 end_POSTSUPERSCRIPT , italic_y start_POSTSUPERSCRIPT \u22c6 end_POSTSUPERSCRIPT ) \u223c caligraphic_D end_POSTSUBSCRIPT roman_log italic_\u03c0 start_POSTSUBSCRIPT italic_\u03b8 end_POSTSUBSCRIPT ( italic_c start_POSTSUPERSCRIPT \u22c6 end_POSTSUPERSCRIPT , italic_y start_POSTSUPERSCRIPT \u22c6 end_POSTSUPERSCRIPT \u2223 italic_x ) .(1) However, at the frontier level, there\u2019s no stronger model to distill from, and expert human labeling doesn\u2019t scale well.",
        "parent": "sec_157180aa"
      },
      {
        "_key": "sec_90f30199",
        "_id": "sections/sec_90f30199",
        "title": "Reinforcement Learning with Verifiable Rewards (RLVR).",
        "level": 5,
        "content": "To move beyond the limits of pure imitation, RLVR only requires a dataset of task and answer\ud835\udc9f={(x,y\u22c6)}\ud835\udc9f\ud835\udc65superscript\ud835\udc66\u22c6\\mathcal{D}=\\{(x,y^{\\star})\\}caligraphic_D = { ( italic_x , italic_y start_POSTSUPERSCRIPT \u22c6 end_POSTSUPERSCRIPT ) }, without labeled rationale. RLVR allows the model to generate its own CoT and calculate a verifiable reward with the golden answerr\u2062(y,y\u22c6)\ud835\udc5f\ud835\udc66superscript\ud835\udc66\u22c6r(y,y^{\\star})italic_r ( italic_y , italic_y start_POSTSUPERSCRIPT \u22c6 end_POSTSUPERSCRIPT ). However, the learning task distribution\ud835\udc9f\ud835\udc9f\\mathcal{D}caligraphic_D, with its set of queries and gold answers are still labeled byhuman experts.\nThe trainable policy\u03c0\u03b8subscript\ud835\udf0b\ud835\udf03\\pi_{\\theta}italic_\u03c0 start_POSTSUBSCRIPT italic_\u03b8 end_POSTSUBSCRIPTis optimized to maximize expected reward: JRLVR\u2062(\u03b8)=\ud835\udd3c(x,y\u22c6)\u223c\ud835\udc9f,y\u223c\u03c0\u03b8(\u22c5\u2223x)\u2062[r\u2062(y,y\u22c6)].\\displaystyle J_{\\text{RLVR}}(\\theta)\\,=\\;\\mathbb{E}_{{\\color[rgb]{%\n0.70703125,0.1953125,0.1953125}\\definecolor[named]{pgfstrokecolor}{rgb}{%\n0.70703125,0.1953125,0.1953125}(x,y^{\\star})\\sim\\mathcal{D}},\\;y\\sim\\pi_{%\n\\theta}(\\cdot\\ \\mid x)}\\bigl{[}r(y,y^{\\star})\\bigr{]}.italic_J start_POSTSUBSCRIPT RLVR end_POSTSUBSCRIPT ( italic_\u03b8 ) = blackboard_E start_POSTSUBSCRIPT ( italic_x , italic_y start_POSTSUPERSCRIPT \u22c6 end_POSTSUPERSCRIPT ) \u223c caligraphic_D , italic_y \u223c italic_\u03c0 start_POSTSUBSCRIPT italic_\u03b8 end_POSTSUBSCRIPT ( \u22c5 \u2223 italic_x ) end_POSTSUBSCRIPT [ italic_r ( italic_y , italic_y start_POSTSUPERSCRIPT \u22c6 end_POSTSUPERSCRIPT ) ] .(2) In summary, both SFT and RLVR still rely onhuman-curateddatasets of either queries, demonstrations, or verifiers, which ultimately limit scalability. The Absolute Zero paradigm removes this dependency by allowing the model to generate, solve, and learn from its own interactions with the environment entirely through self-play.",
        "parent": "sec_157180aa"
      },
      {
        "_key": "sec_0af4c861",
        "_id": "sections/sec_0af4c861",
        "title": "2.2Absolute Zero",
        "level": 3,
        "content": "We propose the Absolute Zero paradigm, where during training, the model simultaneously proposes tasks, solves them, and learns from both stages. No external data is required and the model learns entirely through self-play and experience, aided by some environment. We illustrate this paradigm inFigure2, which contrasts Absolute Zero with supervised learning and RLVR, highlighting how our approach eliminates the need for any human-curated data by enabling self-improving task proposal and solution through self-play. To make the Absolute Zero setting concrete, we now define how one model can act both as the proposer and solver role. To aid understanding, we include an illustration inFigure3. Let\u03c0\u03b8subscript\ud835\udf0b\ud835\udf03\\pi_{\\theta}italic_\u03c0 start_POSTSUBSCRIPT italic_\u03b8 end_POSTSUBSCRIPTbe our parameterized language model, it is used to play two roles, proposer\u03c0\u03b8proposesuperscriptsubscript\ud835\udf0b\ud835\udf03propose\\pi_{\\theta}^{\\text{propose}}italic_\u03c0 start_POSTSUBSCRIPT italic_\u03b8 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT propose end_POSTSUPERSCRIPTand solver\u03c0\u03b8solvesuperscriptsubscript\ud835\udf0b\ud835\udf03solve\\pi_{\\theta}^{\\text{solve}}italic_\u03c0 start_POSTSUBSCRIPT italic_\u03b8 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT solve end_POSTSUPERSCRIPTduring training. Figure 3:The Absolute Zero Loop.The Absolute Zero loop begins with the agent\u03c0\ud835\udf0b\\piitalic_\u03c0proposing task\u03c4\ud835\udf0f\\tauitalic_\u03c4, which is transformed byf\ud835\udc53fitalic_fwith the environmente\ud835\udc52eitalic_einto a validated problem(x,y\u22c6)\ud835\udc65superscript\ud835\udc66\u22c6(x,y^{\\star})( italic_x , italic_y start_POSTSUPERSCRIPT \u22c6 end_POSTSUPERSCRIPT ), and also emits a rewardrproposesuperscript\ud835\udc5fproposer^{\\text{propose}}italic_r start_POSTSUPERSCRIPT propose end_POSTSUPERSCRIPTfor learnability. Then, a standard RL step follows: the agent solvesx\ud835\udc65xitalic_xby producingy\ud835\udc66yitalic_y, receiving rewardrsolvesuperscript\ud835\udc5fsolver^{\\text{solve}}italic_r start_POSTSUPERSCRIPT solve end_POSTSUPERSCRIPTfrome\ud835\udc52eitalic_eby matching withy\u22c6superscript\ud835\udc66\u22c6y^{\\star}italic_y start_POSTSUPERSCRIPT \u22c6 end_POSTSUPERSCRIPT.\u03c0proposesuperscript\ud835\udf0bpropose\\pi^{\\text{propose}}italic_\u03c0 start_POSTSUPERSCRIPT propose end_POSTSUPERSCRIPTand\u03c0solvesuperscript\ud835\udf0bsolve\\pi^{\\text{solve}}italic_\u03c0 start_POSTSUPERSCRIPT solve end_POSTSUPERSCRIPTare jointly trained and this process can be repeated indefinitely. The proposer first samples a proposed task conditioned on variablez\ud835\udc67zitalic_z:\u03c4\u223c\u03c0\u03b8propose(\u22c5|z)\\tau\\sim\\pi_{\\theta}^{\\text{propose}}(\\cdot|z)italic_\u03c4 \u223c italic_\u03c0 start_POSTSUBSCRIPT italic_\u03b8 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT propose end_POSTSUPERSCRIPT ( \u22c5 | italic_z ), which will then be validated and used to construct a valid reasoning task together with the environmente\ud835\udc52eitalic_e:(x,y\u22c6)\u223cfe(\u22c5|\u03c4)(x,y^{\\star})\\sim f_{e}(\\cdot|\\tau)( italic_x , italic_y start_POSTSUPERSCRIPT \u22c6 end_POSTSUPERSCRIPT ) \u223c italic_f start_POSTSUBSCRIPT italic_e end_POSTSUBSCRIPT ( \u22c5 | italic_\u03c4 ), wherex\ud835\udc65xitalic_xis the task query andy\u22c6superscript\ud835\udc66\u22c6y^{\\star}italic_y start_POSTSUPERSCRIPT \u22c6 end_POSTSUPERSCRIPTis the gold label. Then the solver produces an answery\u223c\u03c0\u03b8solve(\u22c5\u2223x)y\\sim\\pi_{\\theta}^{\\text{solve}}(\\,\\cdot\\mid x)italic_y \u223c italic_\u03c0 start_POSTSUBSCRIPT italic_\u03b8 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT solve end_POSTSUPERSCRIPT ( \u22c5 \u2223 italic_x ). Each proposed task\u03c4\ud835\udf0f\\tauitalic_\u03c4is scored by alearnability rewardrepropose\u2062(\u03c4,\u03c0\u03b8)subscriptsuperscript\ud835\udc5fpropose\ud835\udc52\ud835\udf0fsubscript\ud835\udf0b\ud835\udf03r^{\\text{propose}}_{e}(\\tau,\\pi_{\\theta})italic_r start_POSTSUPERSCRIPT propose end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_e end_POSTSUBSCRIPT ( italic_\u03c4 , italic_\u03c0 start_POSTSUBSCRIPT italic_\u03b8 end_POSTSUBSCRIPT ), which captures the expected improvement in\u03c0\u03b8subscript\ud835\udf0b\ud835\udf03\\pi_{\\theta}italic_\u03c0 start_POSTSUBSCRIPT italic_\u03b8 end_POSTSUBSCRIPTafter training on the task queryx\ud835\udc65xitalic_x. Moreover, the same policy also receives asolution rewardresolve\u2062(y,y\u22c6)subscriptsuperscript\ud835\udc5fsolve\ud835\udc52\ud835\udc66superscript\ud835\udc66\u22c6r^{\\text{solve}}_{e}(y,y^{\\star})italic_r start_POSTSUPERSCRIPT solve end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_e end_POSTSUBSCRIPT ( italic_y , italic_y start_POSTSUPERSCRIPT \u22c6 end_POSTSUPERSCRIPT )for its answer to the task queryx\ud835\udc65xitalic_x, with the environment again serving as the verifier. A nonnegative coefficient\u03bb\ud835\udf06\\lambdaitalic_\u03bbbalances the trade-off between exploring new, learnable tasks and improving the model\u2019s reasoning and problem-solving abilities. We formally define the absolute zero setting\u2019s objective as follows: \ud835\udca5\u2062(\u03b8)\u2254max\u03b8\u2061\ud835\udd3cz\u223cp\u2062(z)\u2062[\ud835\udd3c(x,y\u22c6)\u223cfe(\u22c5|\u03c4),\u03c4\u223c\u03c0\u03b8propose(\u22c5|z)\u2062[repropose\u2062(\u03c4,\u03c0\u03b8)+\u03bb\u2062\ud835\udd3cy\u223c\u03c0\u03b8solve(\u22c5\u2223x)\u2062[resolve\u2062(y,y\u22c6)]]].\\displaystyle\\mathcal{J}(\\theta)\\coloneqq\\max_{\\theta}\\;\\;\\mathbb{E}_{z\\sim p(%\nz)}\\Bigg{[}\\;\\mathbb{E}_{{\\color[rgb]{0.1953125,0.55078125,0.3125}\\definecolor%\n[named]{pgfstrokecolor}{rgb}{0.1953125,0.55078125,0.3125}(x,y^{\\star})\\sim f_{%\ne}(\\cdot|\\tau),\\tau\\sim\\pi_{\\theta}^{\\text{propose}}(\\cdot|z)}}\\bigg{[}r^{%\n\\text{propose}}_{{\\color[rgb]{0.1953125,0.55078125,0.3125}\\definecolor[named]{%\npgfstrokecolor}{rgb}{0.1953125,0.55078125,0.3125}e}}(\\tau,\\pi_{\\theta})+%\n\\lambda\\,\\mathbb{E}_{y\\sim\\pi_{\\theta}^{\\text{solve}}(\\cdot\\mid x)}\\big{[}r^{%\n\\text{solve}}_{{\\color[rgb]{0.1953125,0.55078125,0.3125}\\definecolor[named]{%\npgfstrokecolor}{rgb}{0.1953125,0.55078125,0.3125}e}}(y,y^{\\star})\\big{]}\\bigg{%\n]}\\Bigg{]}.caligraphic_J ( italic_\u03b8 ) \u2254 roman_max start_POSTSUBSCRIPT italic_\u03b8 end_POSTSUBSCRIPT blackboard_E start_POSTSUBSCRIPT italic_z \u223c italic_p ( italic_z ) end_POSTSUBSCRIPT [ blackboard_E start_POSTSUBSCRIPT ( italic_x , italic_y start_POSTSUPERSCRIPT \u22c6 end_POSTSUPERSCRIPT ) \u223c italic_f start_POSTSUBSCRIPT italic_e end_POSTSUBSCRIPT ( \u22c5 | italic_\u03c4 ) , italic_\u03c4 \u223c italic_\u03c0 start_POSTSUBSCRIPT italic_\u03b8 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT propose end_POSTSUPERSCRIPT ( \u22c5 | italic_z ) end_POSTSUBSCRIPT [ italic_r start_POSTSUPERSCRIPT propose end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_e end_POSTSUBSCRIPT ( italic_\u03c4 , italic_\u03c0 start_POSTSUBSCRIPT italic_\u03b8 end_POSTSUBSCRIPT ) + italic_\u03bb blackboard_E start_POSTSUBSCRIPT italic_y \u223c italic_\u03c0 start_POSTSUBSCRIPT italic_\u03b8 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT solve end_POSTSUPERSCRIPT ( \u22c5 \u2223 italic_x ) end_POSTSUBSCRIPT [ italic_r start_POSTSUPERSCRIPT solve end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_e end_POSTSUBSCRIPT ( italic_y , italic_y start_POSTSUPERSCRIPT \u22c6 end_POSTSUPERSCRIPT ) ] ] ] .(3) Notice that we shift the burden of scaling data away fromhuman expertsand onto theproposer policy\u03c0\u03b8proposesuperscriptsubscript\ud835\udf0b\ud835\udf03propose\\pi_{\\theta}^{\\text{propose}}italic_\u03c0 start_POSTSUBSCRIPT italic_\u03b8 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT propose end_POSTSUPERSCRIPTand theenvironmente\ud835\udc52eitalic_e. These two roles are both responsible for defining/evolving the learning task distribution, validating proposed tasks, and providing grounded feedback that supports stable and self-sustainable training. When proposing,z\ud835\udc67zitalic_zacts as a conditional variable that seeds generation of tasks. Practically,z\ud835\udc67zitalic_zcan be instantiated by sampling a small subset of past (task, answer) pairs from a continually updated task memory, yet there is no specific implementation tied to the paradigm. To guide the proposing process, we use a learnability rewardrpropose\u2062(\u03c4,\u03c0\u03b8)superscript\ud835\udc5fpropose\ud835\udf0fsubscript\ud835\udf0b\ud835\udf03r^{\\text{propose}}(\\tau,\\pi_{\\theta})italic_r start_POSTSUPERSCRIPT propose end_POSTSUPERSCRIPT ( italic_\u03c4 , italic_\u03c0 start_POSTSUBSCRIPT italic_\u03b8 end_POSTSUBSCRIPT ), which measures how much the model is expected to improve by solving a proposed task\u03c4\ud835\udf0f\\tauitalic_\u03c4. Moreover, the solver rewardrsolve\u2062(y,y\u2217)superscript\ud835\udc5fsolve\ud835\udc66superscript\ud835\udc66r^{\\text{solve}}(y,y^{*})italic_r start_POSTSUPERSCRIPT solve end_POSTSUPERSCRIPT ( italic_y , italic_y start_POSTSUPERSCRIPT \u2217 end_POSTSUPERSCRIPT )evaluates the correctness of the model\u2019s output. Together, these two signals guide the model to propose tasks that are both challenging and learnable, while also enhancing its reasoning abilities, ultimately enabling continuous improvement through self-play.",
        "parent": "sec_f9e77f68"
      },
      {
        "_key": "sec_1a5d9820",
        "_id": "sections/sec_1a5d9820",
        "title": "3Absolute Zero Reasoner",
        "level": 2,
        "content": "In this section, we presentAbsolute Zero Reasoner(AZR) as the first attempt to embrace the Absolute Zero Paradigm. In AZR, an unified LLM serves as both a proposer and a solver: it generates tasks to evolve its learning curriculum and attempts to solve them to improve its reasoning capabilities. The model is trained jointly with both roles, learning to create tasks that push the boundary of reasoning capacity while enhancing its ability to solve them effectively\u00a0(Section3.1). Within this self-play training paradigm, the model learns from three distinct type of coding tasks, which corresponding to three fundamental modes of reasoning: abduction, deduction and induction\u00a0(Section3.2). Using coding tasks is motivated by the Turing-completeness of programming languages(Stuart,2015)and empirical evidence that code-based training improves reasoning(Aryabumi et\u00a0al.,2024). We adopt code as an open-ended, expressive, and verifiable medium for enabling reliable task construction and verification\u00a0(Section3.3). Finally, the model is updated using a newly proposed advantage estimator designed for multitask learning\u00a0(Section3.3.5). We outline the overall algorithm inAlgorithm1and highlight an illustration of our Absolute Zero Reasoner approach inFigure4. To expedite future exploration in this area, we also present several attempts that did not yield fruitful results but still warrant discussion inAppendixD. 3.1Two Roles in One: Proposer and SolverLarge language models are naturally suited for implementing AZR in a multitask learning context(Radford et\u00a0al.,2019), as both the formulation of reasoning tasks and their solutions occur within a unified language space. To this end, we propose rewarding a single model for both generating high learning potential tasks and solving them effectively, as specified by the Absolute Zero objective inEquation3. At each iteration of the online rollout, AZR proposes new reasoning tasks by conditioning on the task type (as defined inSection3.2) andK\ud835\udc3eKitalic_Kpast self-generated examples. The model is explicitly prompted to generate tasks that differ from these examples, promoting diversity and broader coverage of the task space. These task proposals are filtered and transformed into valid reasoning tasks that can be verified using the environment, outlined later inSection3.3. AZR then attempts to solve these newly proposed tasks, receiving grounded feedback for its model responses. Both task proposal and problem solving are trained using reinforcement learning. We now outline the rewards used for each role.Reward Design.Prior work has shown that setting appropriate task difficulty is critical for promoting effective learning in reasoning systems(Zeng et\u00a0al.,2025b). Motivated by this, we design a reward function for the proposer that encourages generation of tasks with meaningful learning potential\u2014neither too easy nor unsolvable for the current solver. Concretely, we use the same language model in its solver role to estimate thelearnabilityof a proposed task, a similar type of reward used in unsupervised environment design literature(Sukhbaatar et\u00a0al.,2018). We performn\ud835\udc5bnitalic_nMonte Carlo rollouts of the solver and compute the average success rate:r\u00afsolve=1n\u2062\u2211i=1Nrsolve(i)subscript\u00af\ud835\udc5fsolve1\ud835\udc5bsuperscriptsubscript\ud835\udc561\ud835\udc41superscriptsubscript\ud835\udc5fsolve\ud835\udc56\\bar{r}_{\\text{solve}}=\\frac{1}{n}\\sum_{i=1}^{N}r_{\\text{solve}}^{(i)}over\u00af start_ARG italic_r end_ARG start_POSTSUBSCRIPT solve end_POSTSUBSCRIPT = divide start_ARG 1 end_ARG start_ARG italic_n end_ARG \u2211 start_POSTSUBSCRIPT italic_i = 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_N end_POSTSUPERSCRIPT italic_r start_POSTSUBSCRIPT solve end_POSTSUBSCRIPT start_POSTSUPERSCRIPT ( italic_i ) end_POSTSUPERSCRIPT. The proposer\u2019s reward is then defined as:rpropose={0,if\u2062r\u00afsolve=0\u2062or\u2062r\u00afsolve=11\u2212r\u00afsolve,otherwise,subscript\ud835\udc5fproposecases0ifsubscript\u00af\ud835\udc5fsolve0orsubscript\u00af\ud835\udc5fsolve11subscript\u00af\ud835\udc5fsolveotherwise\\displaystyle r_{\\text{propose}}=\\begin{cases}0,&\\text{if }\\bar{r}_{\\text{%\nsolve}}=0\\text{ or }\\bar{r}_{\\text{solve}}=1\\\\\n1-\\bar{r}_{\\text{solve}},&\\text{otherwise},\\end{cases}italic_r start_POSTSUBSCRIPT propose end_POSTSUBSCRIPT = { start_ROW start_CELL 0 , end_CELL start_CELL if over\u00af start_ARG italic_r end_ARG start_POSTSUBSCRIPT solve end_POSTSUBSCRIPT = 0 or over\u00af start_ARG italic_r end_ARG start_POSTSUBSCRIPT solve end_POSTSUBSCRIPT = 1 end_CELL end_ROW start_ROW start_CELL 1 - over\u00af start_ARG italic_r end_ARG start_POSTSUBSCRIPT solve end_POSTSUBSCRIPT , end_CELL start_CELL otherwise , end_CELL end_ROW(4)Figure 4:Absolute Zero Reasoner Training Overview.At every iteration, Absolute Zero Reasoner firstPROPOSESa batch of tasks, conditioned on past self-generated triplets stored in a buffer and a particular task type: abduction, deduction, or induction\u00a0(Section3.2). From these generated tasks, Python is used to filter and construct valid code-based reasoning questions. A learnability rewardrproposesubscript\ud835\udc5fproposer_{\\text{propose}}italic_r start_POSTSUBSCRIPT propose end_POSTSUBSCRIPTis also calculated for each proposed task as defined inEquation4. The Absolute Zero Reasoner thenSOLVESthe batch of reasoning questions. Python is used again to verify the generated responses and compute the accuracy rewardrsolvesubscript\ud835\udc5fsolver_{\\text{solve}}italic_r start_POSTSUBSCRIPT solve end_POSTSUBSCRIPTas described inEquation5. Finally, the Absolute Zero Reasoner is jointly updated using bothrproposesubscript\ud835\udc5fproposer_{\\text{propose}}italic_r start_POSTSUBSCRIPT propose end_POSTSUBSCRIPTandrsolvesubscript\ud835\udc5fsolver_{\\text{solve}}italic_r start_POSTSUBSCRIPT solve end_POSTSUBSCRIPTacross all three task types, using TRR++\u00a0(Section3.3.5).The intuition is that if a task is either trivial to solve (r\u00afsolve=1subscript\u00af\ud835\udc5fsolve1\\bar{r}_{\\text{solve}}=1over\u00af start_ARG italic_r end_ARG start_POSTSUBSCRIPT solve end_POSTSUBSCRIPT = 1) or unsolvable (r\u00afsolve=0subscript\u00af\ud835\udc5fsolve0\\bar{r}_{\\text{solve}}=0over\u00af start_ARG italic_r end_ARG start_POSTSUBSCRIPT solve end_POSTSUBSCRIPT = 0), the task provides little to no learning signal for the proposer. In contrast, tasks of moderate difficulty, where the solver occasionally succeeds are rewarded the most, as they offer the richest feedback and greatest potential for learning.For the solver, we assign a simple binary reward based on the correctness of its final output,rsolve=\ud835\udd40(y=y\u22c6),subscript\ud835\udc5fsolvesubscript\ud835\udd40\ud835\udc66superscript\ud835\udc66\u22c6\\displaystyle r_{\\text{solve}}=\\mathbb{I}_{(y=y^{\\star})},italic_r start_POSTSUBSCRIPT solve end_POSTSUBSCRIPT = blackboard_I start_POSTSUBSCRIPT ( italic_y = italic_y start_POSTSUPERSCRIPT \u22c6 end_POSTSUPERSCRIPT ) end_POSTSUBSCRIPT ,(5)wherey\u22c6superscript\ud835\udc66\u22c6y^{\\star}italic_y start_POSTSUPERSCRIPT \u22c6 end_POSTSUPERSCRIPTis the ground-truth answer, and equality is evaluated based on value equality in Python.With the primary rewards for the proposing and solving roles defined, we adopt the following composite reward structure, which integratesrproposesubscript\ud835\udc5fproposer_{\\text{propose}}italic_r start_POSTSUBSCRIPT propose end_POSTSUBSCRIPTandrsolvesubscript\ud835\udc5fsolver_{\\text{solve}}italic_r start_POSTSUBSCRIPT solve end_POSTSUBSCRIPTwith a format-aware penalty inspired byDeepSeek-AI et\u00a0al.(2025):R\u2062(y\u03c0)={rroleif the response is passable,\u2062role\u2208{propose,solve}\u22120.5if the response is wrong but well-formatted,\u22121if the answer has formatting errors,\ud835\udc45subscript\ud835\udc66\ud835\udf0bcasessubscript\ud835\udc5froleif the response is passable,rolepropose,solve0.5if the response is wrong but well-formatted,1if the answer has formatting errors,\\displaystyle R(y_{\\pi})=\\begin{cases}r_{\\text{role}}&\\text{if the response is%\n passable,}~{}\\text{role}\\in\\{\\text{propose,solve}\\}\\\\\n-0.5&\\text{if the response is wrong but well-formatted,}\\\\\n-1&\\text{if the answer has formatting errors,}\\end{cases}italic_R ( italic_y start_POSTSUBSCRIPT italic_\u03c0 end_POSTSUBSCRIPT ) = { start_ROW start_CELL italic_r start_POSTSUBSCRIPT role end_POSTSUBSCRIPT end_CELL start_CELL if the response is passable, role \u2208 { propose,solve } end_CELL end_ROW start_ROW start_CELL - 0.5 end_CELL start_CELL if the response is wrong but well-formatted, end_CELL end_ROW start_ROW start_CELL - 1 end_CELL start_CELL if the answer has formatting errors, end_CELL end_ROW(6)wherey\u03c0subscript\ud835\udc66\ud835\udf0by_{\\pi}italic_y start_POSTSUBSCRIPT italic_\u03c0 end_POSTSUBSCRIPTis the response of the language model. The main format that the proposing and solving tasks need to follow is the DeepSeek R1<think>and<answer>format, as shown inFigure33. Moreover, for the proposer, the reward criterion for format goes beyond simply following the XML structure. As detailed inSection3.3.3, only responses that produce valid triplets and pass the filtering stage are considered to be correctly formatted. 3.2Learning Different Modes of Reasoning: Deduction, Induction, and AbductionAZR uses code executor as both a flexible interface and a verifiable environment. This setup enables automatic construction, execution, and validation of code reasoning tasks(Stuart,2015;Aryabumi et\u00a0al.,2024). Give program space\ud835\udcab\ud835\udcab\\mathscr{P}script_P, input space\u2110\u2110\\mathscr{I}script_Iand output space\ud835\udcaa\ud835\udcaa\\mathscr{O}script_Oof a coding language, we define an AZR reasoning task as a triplet(p,i,o)\ud835\udc5d\ud835\udc56\ud835\udc5c(p,i,o)( italic_p , italic_i , italic_o ), wherep\u2208\ud835\udcab\ud835\udc5d\ud835\udcabp\\in\\mathscr{P}italic_p \u2208 script_Pis a program,i\u2208\u2110\ud835\udc56\u2110i\\in\\mathscr{I}italic_i \u2208 script_Iis an input, ando\u2208\ud835\udcaa\ud835\udc5c\ud835\udcaao\\in\\mathscr{O}italic_o \u2208 script_Ois the corresponding output produced by running program on input,o=p\u2062(i)\ud835\udc5c\ud835\udc5d\ud835\udc56o=p(i)italic_o = italic_p ( italic_i ). AZR learns by reasoning about different parts of this task triplet, using three distinct core reasoning modes, each of which focuses on inferring one part of the triplet given the others:1.Deduction: predicting the outputo\ud835\udc5coitalic_ogiven a programp\ud835\udc5dpitalic_pand inputi\ud835\udc56iitalic_i, capturing step-by-step logical reasoning.\u2022As aproposer, AZR is conditioned on the task type\u03b1=deduction\ud835\udefcdeduction\\alpha=\\text{deduction}italic_\u03b1 = deductionandK\ud835\udc3eKitalic_Kreference examples from the deduction buffer\ud835\udc9fdeductionsubscript\ud835\udc9fdeduction\\mathcal{D}_{\\text{deduction}}caligraphic_D start_POSTSUBSCRIPT deduction end_POSTSUBSCRIPT(all task buffers are outlined inSection3.3), and generates a pair(p,i)\ud835\udc5d\ud835\udc56(p,i)( italic_p , italic_i ). The environmente\ud835\udc52eitalic_ethen executesp\u2062(i)\ud835\udc5d\ud835\udc56p(i)italic_p ( italic_i )to computeo\ud835\udc5coitalic_o, completing the triplet(p,i,o)\ud835\udc5d\ud835\udc56\ud835\udc5c(p,i,o)( italic_p , italic_i , italic_o ), which is added to the buffer if non-error output was produced.\u2022As asolver, the model receives(p,i)\ud835\udc5d\ud835\udc56(p,i)( italic_p , italic_i )and predicts the outputo\u03c0subscript\ud835\udc5c\ud835\udf0bo_{\\pi}italic_o start_POSTSUBSCRIPT italic_\u03c0 end_POSTSUBSCRIPT. The predicted output is verified using type-aware value equality in python to account for possible variations (such as set ordering or fractions).2.Abduction: inferring a plausible inputi\ud835\udc56iitalic_igiven the programp\ud835\udc5dpitalic_pand an outputo\ud835\udc5coitalic_o, resembling trial-and-error or online search.\u2022As aproposer, the policy\u03c0proposesuperscript\ud835\udf0bpropose\\pi^{\\text{propose}}italic_\u03c0 start_POSTSUPERSCRIPT propose end_POSTSUPERSCRIPT\u2019s input and output is almost the same as the proposer for the deduction task, except that the task type\u03b1=abduction\ud835\udefcabduction\\alpha=\\text{abduction}italic_\u03b1 = abductionis changed as an input. The model generates a pair(p,i)\ud835\udc5d\ud835\udc56(p,i)( italic_p , italic_i )conditioned on\u03b1\ud835\udefc\\alphaitalic_\u03b1and reference examples. Then we executesp\u2062(i)\ud835\udc5d\ud835\udc56p(i)italic_p ( italic_i )and get the triplet(p,i,o)\ud835\udc5d\ud835\udc56\ud835\udc5c(p,i,o)( italic_p , italic_i , italic_o ).\u2022As asolver, the model receives(p,o)\ud835\udc5d\ud835\udc5c(p,o)( italic_p , italic_o )and predictsi\u03c0subscript\ud835\udc56\ud835\udf0bi_{\\pi}italic_i start_POSTSUBSCRIPT italic_\u03c0 end_POSTSUBSCRIPT. The solution is verified by checking whetherp\u2062(i\u03c0)=o\ud835\udc5dsubscript\ud835\udc56\ud835\udf0b\ud835\udc5cp(i_{\\pi})=oitalic_p ( italic_i start_POSTSUBSCRIPT italic_\u03c0 end_POSTSUBSCRIPT ) = italic_o. Since programs may not be bijective, we useoutputvalue equivalence rather than requiring exact input matches.3.Induction:synthesizing a programp\ud835\udc5dpitalic_pfrom a set of in-out examples{(in,on)}superscript\ud835\udc56\ud835\udc5bsuperscript\ud835\udc5c\ud835\udc5b\\{(i^{n},o^{n})\\}{ ( italic_i start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT , italic_o start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT ) }, requiring generalization from partial information.\u2022As aproposer, AZR samples a valid programp\ud835\udc5dpitalic_pfrom\ud835\udc9fabduction\u222a\ud835\udc9fdeductionsubscript\ud835\udc9fabductionsubscript\ud835\udc9fdeduction\\mathcal{D}_{\\text{abduction}}\\cup\\mathcal{D}_{\\text{deduction}}caligraphic_D start_POSTSUBSCRIPT abduction end_POSTSUBSCRIPT \u222a caligraphic_D start_POSTSUBSCRIPT deduction end_POSTSUBSCRIPT, generatesN\ud835\udc41Nitalic_Nnew inputs and a messagem\ud835\udc5amitalic_m, and uses the environment to compute corresponding outputs. This forms an extended task representation(p,{(in,on)},m)\ud835\udc5dsuperscript\ud835\udc56\ud835\udc5bsuperscript\ud835\udc5c\ud835\udc5b\ud835\udc5a(p,\\{(i^{n},o^{n})\\},m)( italic_p , { ( italic_i start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT , italic_o start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT ) } , italic_m ), which is stored in the induction buffer\ud835\udc9finductionsubscript\ud835\udc9finduction\\mathcal{D}_{\\text{induction}}caligraphic_D start_POSTSUBSCRIPT induction end_POSTSUBSCRIPT. Since infinitely many functions can map the inputs to the outputs, making the induction task under-constrained, the messagem\ud835\udc5amitalic_mhelps properly condition the problem for the solver.\u2022As asolver, the model is shown the first half of the input-output pairs and the messagem\ud835\udc5amitalic_m, and must synthesize a programp\u03c0subscript\ud835\udc5d\ud835\udf0bp_{\\pi}italic_p start_POSTSUBSCRIPT italic_\u03c0 end_POSTSUBSCRIPTthat correctly maps the remaining hidden inputs to their outputs. The use of held-out examples discourages overfitting through if-else logic and promotes generalized induction.Figure 5:The Seed AZR Zero Triplet.The above identity function triplet was the only triplet provided to AZR to initiate its self-bootstrap propose-and-solve RLVR loop. We note that the base LLM is fully capable of initiating the AZR loop without any seed program; its inclusion illustrates our approach\u2019s flexibility: we can optionally initialize seed programs with existing datasets of varying complexity, and we initialized ours with the simplest program.Each reasoning task type leverages code as an expressive and verifiable medium, aligning with the Absolute Zero Paradigm\u2019s goals of fully self-improving systems in open-ended domains(DeepSeek-AI et\u00a0al.,2025;Lambert et\u00a0al.,2024). All prompts used by three different task types and two types of roles within a task type are shown inFigures36,34,35,39,37and38. Next, we outline exact details of our algorithm. 3.3Absolute Zero Reasoner Learning AlgorithmIn this section, we will discuss details of our AZR self-play algorithm, including initialization of buffers3.3.1, usage of thse buffers3.3.2, construction of valid tasks3.3.3, validating solutions3.3.4, and finally advantage estimator calculation3.3.5. We outline the overall recipe of the self-play procedure of AZR inAlgorithm1.3.3.1Buffer InitializationTo initialize AZR self-play, we first generate a seed set of valid triplets using the base language model. Each prompt samples up toK\ud835\udc3eKitalic_Ktriplets from the current seed buffer\ud835\udc9fseedsubscript\ud835\udc9fseed\\mathcal{D}_{\\text{seed}}caligraphic_D start_POSTSUBSCRIPT seed end_POSTSUBSCRIPTas references. When\ud835\udc9fseedsubscript\ud835\udc9fseed\\mathcal{D}_{\\text{seed}}caligraphic_D start_POSTSUBSCRIPT seed end_POSTSUBSCRIPTis empty at time 0, we fall back to the zero triplet show inFigure5. During the seeding stage, we use the same proposer prompts detailed inFigures34,35and36.First, for deduction and abduction tasks, the LLM is prompted to generate(p,i)\ud835\udc5d\ud835\udc56(p,i)( italic_p , italic_i )pairs, which are filtered, executed, and stored as valid triplets. We initialize\ud835\udc9fabduction0=\ud835\udc9fdeduction0=\ud835\udc9fseedsubscriptsuperscript\ud835\udc9f0abductionsubscriptsuperscript\ud835\udc9f0deductionsubscript\ud835\udc9fseed\\mathcal{D}^{0}_{\\text{abduction}}=\\mathcal{D}^{0}_{\\text{deduction}}=\\mathcal%\n{D}_{\\text{seed}}caligraphic_D start_POSTSUPERSCRIPT 0 end_POSTSUPERSCRIPT start_POSTSUBSCRIPT abduction end_POSTSUBSCRIPT = caligraphic_D start_POSTSUPERSCRIPT 0 end_POSTSUPERSCRIPT start_POSTSUBSCRIPT deduction end_POSTSUBSCRIPT = caligraphic_D start_POSTSUBSCRIPT seed end_POSTSUBSCRIPT, where|\ud835\udc9fseed|=B\u00d7Ssubscript\ud835\udc9fseed\ud835\udc35\ud835\udc46|\\mathcal{D}_{\\text{seed}}|=B\\times S| caligraphic_D start_POSTSUBSCRIPT seed end_POSTSUBSCRIPT | = italic_B \u00d7 italic_S, whereB\ud835\udc35Bitalic_Bis the batch size, andS=4\ud835\udc464S=4italic_S = 4is a factor we fix in all experiments. All seed triplet\u2019s program are stripped of global variables and comments (AppendixD), but subsequent iterations of adding new triplets to the buffers are unaltered. No model updates occur during this phase. Similarly, to initialize the induction buffer, we sample programs from\ud835\udc9fseedsubscript\ud835\udc9fseed\\mathcal{D}_{\\text{seed}}caligraphic_D start_POSTSUBSCRIPT seed end_POSTSUBSCRIPT, generate matching input sets and messages, and collect valid examples until|\ud835\udc9finduction0|=B\u00d7Ssubscriptsuperscript\ud835\udc9f0induction\ud835\udc35\ud835\udc46|\\mathcal{D}^{0}_{\\text{induction}}|=B\\times S| caligraphic_D start_POSTSUPERSCRIPT 0 end_POSTSUPERSCRIPT start_POSTSUBSCRIPT induction end_POSTSUBSCRIPT | = italic_B \u00d7 italic_S.3.3.2Task Proposal Inputs and Buffer ManagementDuring the actual self-play stage of AZR, we use the task buffer in three ways.First, for the proposer of abduction and deduction tasks, we uniformly sampleK\ud835\udc3eKitalic_Kpast triplets from the buffer, present them as in-context examples to the proposer and let it generate a new task. The design is to show it past examples, and prompt it to generate a different one to promote diversity(Zhao et\u00a0al.,2025a).Second, we sample one triplet from the union of abduction and deduction buffers\ud835\udc9fabd\u2062\u22c3\ud835\udc9fdedsubscript\ud835\udc9fabdsubscript\ud835\udc9fded\\mathcal{D}_{\\text{abd}}\\bigcup\\mathcal{D}_{\\text{ded}}caligraphic_D start_POSTSUBSCRIPT abd end_POSTSUBSCRIPT \u22c3 caligraphic_D start_POSTSUBSCRIPT ded end_POSTSUBSCRIPT, and present the programp\ud835\udc5dpitalic_pfrom that triplet to the induction proposer to generate a set ofN\ud835\udc41Nitalic_Nmatching inputs{in}superscript\ud835\udc56\ud835\udc5b\\{i^{n}\\}{ italic_i start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT }and a natural language messagem\ud835\udc5amitalic_m.Lastly, to maintain stable training, if a batch of solver problems contains fewer thanB\ud835\udc35Bitalic_Bvalid proposed tasks (proposer not adhering to formatting), we fill the remainder by uniformly sampling from the corresponding task buffer of previously validated triplets.The buffer grows for abduction and deduction tasks whenever\u03c0\ud835\udf0b\\piitalic_\u03c0propose a valid triplet(p,i,o)\ud835\udc5d\ud835\udc56\ud835\udc5c(p,i,o)( italic_p , italic_i , italic_o ), regardless if it gets any task reward. Similarly, for induction tasks, all valid triplets(p,{in,on}),m\ud835\udc5dsuperscript\ud835\udc56\ud835\udc5bsuperscript\ud835\udc5c\ud835\udc5b\ud835\udc5a(p,\\{i^{n},o^{n}\\}),m( italic_p , { italic_i start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT , italic_o start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT } ) , italic_mare added to the buffer.Algorithm 1Self-Play Training of Absolute Zero Reasoner (AZR)1:Pretrained base LLM\u03c0\u03b8subscript\ud835\udf0b\ud835\udf03\\pi_{\\theta}italic_\u03c0 start_POSTSUBSCRIPT italic_\u03b8 end_POSTSUBSCRIPT; batch sizeB\ud835\udc35Bitalic_B; #referencesK\ud835\udc3eKitalic_K; iterationsT\ud835\udc47Titalic_T2:\ud835\udc9fded,\ud835\udc9fabd,\ud835\udc9find\u2190InitSeeding\u2062(\u03c0\u03b8)\u2190subscript\ud835\udc9fdedsubscript\ud835\udc9fabdsubscript\ud835\udc9findInitSeedingsubscript\ud835\udf0b\ud835\udf03\\mathcal{D}_{\\text{ded}},\\mathcal{D}_{\\text{abd}},\\mathcal{D}_{\\text{ind}}%\n\\leftarrow\\textsc{InitSeeding}(\\pi_{\\theta})caligraphic_D start_POSTSUBSCRIPT ded end_POSTSUBSCRIPT , caligraphic_D start_POSTSUBSCRIPT abd end_POSTSUBSCRIPT , caligraphic_D start_POSTSUBSCRIPT ind end_POSTSUBSCRIPT \u2190 InitSeeding ( italic_\u03c0 start_POSTSUBSCRIPT italic_\u03b8 end_POSTSUBSCRIPT )\u25b7\u25b7\\triangleright\u25b7see \u00a73.3.13:fort\u21901\u2190\ud835\udc611t\\leftarrow 1italic_t \u2190 1toT\ud835\udc47Titalic_Tdo4:forb\u21901\u2190\ud835\udc4f1b\\leftarrow 1italic_b \u2190 1toB\ud835\udc35Bitalic_Bdo\u25b7\u25b7\\triangleright\u25b7PROPOSE PHASE5:p\u223c\ud835\udc9fabd\u222a\ud835\udc9fdedsimilar-to\ud835\udc5dsubscript\ud835\udc9fabdsubscript\ud835\udc9fdedp\\sim\\mathcal{D}_{\\text{abd}}\\cup\\mathcal{D}_{\\text{ded}}italic_p \u223c caligraphic_D start_POSTSUBSCRIPT abd end_POSTSUBSCRIPT \u222a caligraphic_D start_POSTSUBSCRIPT ded end_POSTSUBSCRIPT\u25b7\u25b7\\triangleright\u25b7sample a program for induction task proposal6:{i\u03c0n}n=1N,m\u03c0\u2190\u03c0\u03b8propose\u2062(ind,p)\u2190superscriptsubscriptsubscriptsuperscript\ud835\udc56\ud835\udc5b\ud835\udf0b\ud835\udc5b1\ud835\udc41subscript\ud835\udc5a\ud835\udf0bsuperscriptsubscript\ud835\udf0b\ud835\udf03proposeind\ud835\udc5d\\bigl{\\{}i^{n}_{\\pi}\\bigr{\\}}_{n=1}^{N},\\;m_{\\pi}\\leftarrow\\pi_{\\theta}^{\\text%\n{propose}}(\\text{ind},p){ italic_i start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_\u03c0 end_POSTSUBSCRIPT } start_POSTSUBSCRIPT italic_n = 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_N end_POSTSUPERSCRIPT , italic_m start_POSTSUBSCRIPT italic_\u03c0 end_POSTSUBSCRIPT \u2190 italic_\u03c0 start_POSTSUBSCRIPT italic_\u03b8 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT propose end_POSTSUPERSCRIPT ( ind , italic_p )\u25b7\u25b7\\triangleright\u25b7generateN\ud835\udc41Nitalic_Ninputs and a description7:if{(i\u03c0n,o\u03c0n)}n=1N\u2190ValidateByExecuting\u2062(p,{i\u03c0n},syntax)\u2190superscriptsubscriptsubscriptsuperscript\ud835\udc56\ud835\udc5b\ud835\udf0bsubscriptsuperscript\ud835\udc5c\ud835\udc5b\ud835\udf0b\ud835\udc5b1\ud835\udc41ValidateByExecuting\ud835\udc5dsubscriptsuperscript\ud835\udc56\ud835\udc5b\ud835\udf0bsyntax\\bigl{\\{}(i^{n}_{\\pi},o^{n}_{\\pi})\\bigr{\\}}_{n=1}^{N}\\leftarrow\\textsc{%\nValidateByExecuting}\\bigl{(}p,\\{i^{n}_{\\pi}\\},\\textsc{syntax}\\bigr{)}{ ( italic_i start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_\u03c0 end_POSTSUBSCRIPT , italic_o start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_\u03c0 end_POSTSUBSCRIPT ) } start_POSTSUBSCRIPT italic_n = 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_N end_POSTSUPERSCRIPT \u2190 ValidateByExecuting ( italic_p , { italic_i start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_\u03c0 end_POSTSUBSCRIPT } , syntax )then\u25b7\u25b7\\triangleright\u25b7validate I/Os, see \u00a73.3.38:\ud835\udc9find\u2190\ud835\udc9find\u222a{(p,{(i\u03c0n,o\u03c0n)},m\u03c0)}\u2190subscript\ud835\udc9findsubscript\ud835\udc9find\ud835\udc5dsubscriptsuperscript\ud835\udc56\ud835\udc5b\ud835\udf0bsubscriptsuperscript\ud835\udc5c\ud835\udc5b\ud835\udf0bsubscript\ud835\udc5a\ud835\udf0b\\mathcal{D}_{\\text{ind}}\\leftarrow\\mathcal{D}_{\\text{ind}}\\cup\\bigl{\\{}(p,\\{(i%\n^{n}_{\\pi},o^{n}_{\\pi})\\},m_{\\pi})\\bigr{\\}}caligraphic_D start_POSTSUBSCRIPT ind end_POSTSUBSCRIPT \u2190 caligraphic_D start_POSTSUBSCRIPT ind end_POSTSUBSCRIPT \u222a { ( italic_p , { ( italic_i start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_\u03c0 end_POSTSUBSCRIPT , italic_o start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_\u03c0 end_POSTSUBSCRIPT ) } , italic_m start_POSTSUBSCRIPT italic_\u03c0 end_POSTSUBSCRIPT ) }\u25b7\u25b7\\triangleright\u25b7update induction buffer9:for\u03b1\u2208{ded,abd}\ud835\udefcdedabd\\alpha\\in\\{\\text{ded},\\text{abd}\\}italic_\u03b1 \u2208 { ded , abd }do10:(pk,ik,ok)k=1K\u223c\ud835\udc9f\u03b1similar-tosuperscriptsubscriptsubscript\ud835\udc5d\ud835\udc58subscript\ud835\udc56\ud835\udc58subscript\ud835\udc5c\ud835\udc58\ud835\udc581\ud835\udc3esubscript\ud835\udc9f\ud835\udefc\\bigl{(}p_{k},i_{k},o_{k}\\bigr{)}_{k=1}^{K}\\sim\\mathcal{D}_{\\alpha}( italic_p start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT , italic_i start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT , italic_o start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT ) start_POSTSUBSCRIPT italic_k = 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_K end_POSTSUPERSCRIPT \u223c caligraphic_D start_POSTSUBSCRIPT italic_\u03b1 end_POSTSUBSCRIPT\u25b7\u25b7\\triangleright\u25b7sampleK\ud835\udc3eKitalic_Kreference examples11:(p\u03c0,i\u03c0)\u2190\u03c0\u03b8propose\u2062(\u03b1,{(pk,ik,ok)})\u2190subscript\ud835\udc5d\ud835\udf0bsubscript\ud835\udc56\ud835\udf0bsuperscriptsubscript\ud835\udf0b\ud835\udf03propose\ud835\udefcsubscript\ud835\udc5d\ud835\udc58subscript\ud835\udc56\ud835\udc58subscript\ud835\udc5c\ud835\udc58(p_{\\pi},i_{\\pi})\\leftarrow\\pi_{\\theta}^{\\text{propose}}\\!\\bigl{(}\\alpha,\\{(p_%\n{k},i_{k},o_{k})\\}\\bigr{)}( italic_p start_POSTSUBSCRIPT italic_\u03c0 end_POSTSUBSCRIPT , italic_i start_POSTSUBSCRIPT italic_\u03c0 end_POSTSUBSCRIPT ) \u2190 italic_\u03c0 start_POSTSUBSCRIPT italic_\u03b8 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT propose end_POSTSUPERSCRIPT ( italic_\u03b1 , { ( italic_p start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT , italic_i start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT , italic_o start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT ) } )\u25b7\u25b7\\triangleright\u25b7propose new task12:ifo\u03c0\u2190ValidateByExecuting\u2062(p\u03c0,i\u03c0,syntax,safety,determinism)\u2190subscript\ud835\udc5c\ud835\udf0bValidateByExecutingsubscript\ud835\udc5d\ud835\udf0bsubscript\ud835\udc56\ud835\udf0bsyntax,safety,determinismo_{\\pi}\\leftarrow\\textsc{ValidateByExecuting}\\bigl{(}p_{\\pi},i_{\\pi},\\textsc{%\nsyntax,safety,determinism}\\bigr{)}italic_o start_POSTSUBSCRIPT italic_\u03c0 end_POSTSUBSCRIPT \u2190 ValidateByExecuting ( italic_p start_POSTSUBSCRIPT italic_\u03c0 end_POSTSUBSCRIPT , italic_i start_POSTSUBSCRIPT italic_\u03c0 end_POSTSUBSCRIPT , syntax,safety,determinism )then\u25b7\u25b7\\triangleright\u25b7see \u00a73.3.313:\ud835\udc9f\u03b1\u2190\ud835\udc9f\u03b1\u222a{(p\u03c0,i\u03c0,o\u03c0)}\u2190subscript\ud835\udc9f\ud835\udefcsubscript\ud835\udc9f\ud835\udefcsubscript\ud835\udc5d\ud835\udf0bsubscript\ud835\udc56\ud835\udf0bsubscript\ud835\udc5c\ud835\udf0b\\mathcal{D}_{\\alpha}\\leftarrow\\mathcal{D}_{\\alpha}\\cup\\bigl{\\{}(p_{\\pi},i_{\\pi%\n},o_{\\pi})\\bigr{\\}}caligraphic_D start_POSTSUBSCRIPT italic_\u03b1 end_POSTSUBSCRIPT \u2190 caligraphic_D start_POSTSUBSCRIPT italic_\u03b1 end_POSTSUBSCRIPT \u222a { ( italic_p start_POSTSUBSCRIPT italic_\u03c0 end_POSTSUBSCRIPT , italic_i start_POSTSUBSCRIPT italic_\u03c0 end_POSTSUBSCRIPT , italic_o start_POSTSUBSCRIPT italic_\u03c0 end_POSTSUBSCRIPT ) }\u25b7\u25b7\\triangleright\u25b7if valid, update deduction or abduction buffers14:for all\u03b1\u2208{ded,abd,ind}\ud835\udefcdedabdind\\alpha\\in\\{\\text{ded},\\text{abd},\\text{ind}\\}italic_\u03b1 \u2208 { ded , abd , ind }do\u25b7\u25b7\\triangleright\u25b7SOLVE PHASE15:(x,y\u22c6)\u2190SamplePrepareTasks\u2062(\ud835\udc9f\u03b1,B,t)\u2190\ud835\udc65superscript\ud835\udc66\u22c6SamplePrepareTaskssubscript\ud835\udc9f\ud835\udefc\ud835\udc35\ud835\udc61(x,y^{\\star})\\leftarrow\\textsc{SamplePrepareTasks}\\bigl{(}\\mathcal{D}_{\\alpha}%\n,B,t\\bigr{)}( italic_x , italic_y start_POSTSUPERSCRIPT \u22c6 end_POSTSUPERSCRIPT ) \u2190 SamplePrepareTasks ( caligraphic_D start_POSTSUBSCRIPT italic_\u03b1 end_POSTSUBSCRIPT , italic_B , italic_t )\u25b7\u25b7\\triangleright\u25b7x,y\u22c6\ud835\udc65superscript\ud835\udc66\u22c6x,y^{\\star}italic_x , italic_y start_POSTSUPERSCRIPT \u22c6 end_POSTSUPERSCRIPTprepared based on\u03b1\ud835\udefc\\alphaitalic_\u03b1, see \u00a73.3.3&3.3.416:y\u03c0\u223c\u03c0\u03b8solve\u2062(x)similar-tosubscript\ud835\udc66\ud835\udf0bsuperscriptsubscript\ud835\udf0b\ud835\udf03solve\ud835\udc65y_{\\pi}\\sim\\pi_{\\theta}^{\\text{solve}}(x)italic_y start_POSTSUBSCRIPT italic_\u03c0 end_POSTSUBSCRIPT \u223c italic_\u03c0 start_POSTSUBSCRIPT italic_\u03b8 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT solve end_POSTSUPERSCRIPT ( italic_x )17:Reward:Use proposed task triplets and solved answers to getrp\u2062r\u2062o\u2062p\u2062o\u2062s\u2062esubscript\ud835\udc5f\ud835\udc5d\ud835\udc5f\ud835\udc5c\ud835\udc5d\ud835\udc5c\ud835\udc60\ud835\udc52r_{propose}italic_r start_POSTSUBSCRIPT italic_p italic_r italic_o italic_p italic_o italic_s italic_e end_POSTSUBSCRIPT&rs\u2062o\u2062l\u2062v\u2062esubscript\ud835\udc5f\ud835\udc60\ud835\udc5c\ud835\udc59\ud835\udc63\ud835\udc52r_{solve}italic_r start_POSTSUBSCRIPT italic_s italic_o italic_l italic_v italic_e end_POSTSUBSCRIPT\u25b7\u25b7\\triangleright\u25b7see \u00a73.118:RL update:use Task Relative REINFORCE++ to update\u03c0\u03b8subscript\ud835\udf0b\ud835\udf03\\pi_{\\theta}italic_\u03c0 start_POSTSUBSCRIPT italic_\u03b8 end_POSTSUBSCRIPT\u25b7\u25b7\\triangleright\u25b7see \u00a73.3.53.3.3Constructing Valid TasksProposal Task Validation.We first describe how we construct valid tasks from the proposals generated by the policy\u03c0\ud835\udf0b\\piitalic_\u03c0. Fordeduction and abductiontasks, each proposal consists of a program and an input(p,i)\ud835\udc5d\ud835\udc56(p,i)( italic_p , italic_i ). To validate the task, we use the task validation procedure (steps shown below) on the input to obtain the correct outputo\ud835\udc5coitalic_o, resulting in a complete triplet(p,i,o)\ud835\udc5d\ud835\udc56\ud835\udc5c(p,i,o)( italic_p , italic_i , italic_o ). Forinductiontasks, given a programp\ud835\udc5dpitalic_pthe policy proposes a set of inputs{in}superscript\ud835\udc56\ud835\udc5b\\{i^{n}\\}{ italic_i start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT }and messagem\ud835\udc5amitalic_m. We also use the task validation procedure on each of the inputinsuperscript\ud835\udc56\ud835\udc5bi^{n}italic_i start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPTin the set to obtain a corresponding outputonsuperscript\ud835\udc5c\ud835\udc5bo^{n}italic_o start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT, forming a set of input-output pairs{in,on}superscript\ud835\udc56\ud835\udc5bsuperscript\ud835\udc5c\ud835\udc5b\\{i^{n},o^{n}\\}{ italic_i start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT , italic_o start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT }. We do not impose any constraints onm\ud835\udc5amitalic_m. The resulting task is considered valid only when all inputs yield valid outputs and the formatting requirements are satisfied. Thetask validation procedureentails:1.Program Integrity.We first use Python to run the programp\ud835\udc5dpitalic_pwith the inputi\ud835\udc56iitalic_i. If no errors are raised and something is returned, we then gather the outputo\ud835\udc5coitalic_oof that(p,i)\ud835\udc5d\ud835\udc56(p,i)( italic_p , italic_i )pair and determine that the program at least has valid syntax.2.Program Safety.We also check whether a program is safe for execution by restricting the use of certain sensitive packages that might cause harm to the Python environment,i.e.,os.sys, sys, shutil. The list of packages used to filter out invalid programs is provided inFigure8. This list is also included in the instructions when prompting the language model to generate questions. SeeFigures34,35and36.3.Check for Determinism.In our setting, we only considerdeterministic programs,i.e.,p\u2208\ud835\udcabdeterministic\u2282\ud835\udcab\ud835\udc5dsubscript\ud835\udcabdeterministic\ud835\udcabp\\in\\mathscr{P}_{\\text{deterministic}}\\subset\\mathscr{P}italic_p \u2208 script_P start_POSTSUBSCRIPT deterministic end_POSTSUBSCRIPT \u2282 script_P, where\ud835\udcab\ud835\udcab\\mathscr{P}script_Pis the space of all valid programs and\u2110\u2110\\mathscr{I}script_Iis the space of all valid inputs:\u2200p\u2208\ud835\udcabdeterministic,\u2200i\u2208\u2110,(limj\u2192\u221ep\u2062(i)(1)=p\u2062(i)(2)=\u22ef=p\u2062(i)(j)),formulae-sequencefor-all\ud835\udc5dsubscript\ud835\udcabdeterministicfor-all\ud835\udc56\u2110subscript\u2192\ud835\udc57\ud835\udc5dsuperscript\ud835\udc561\ud835\udc5dsuperscript\ud835\udc562\u22ef\ud835\udc5dsuperscript\ud835\udc56\ud835\udc57\\forall p\\in\\mathscr{P}_{\\text{deterministic}},\\ \\forall i\\in\\mathscr{I},\\ %\n\\left(\\lim_{j\\to\\infty}p(i)^{(1)}=p(i)^{(2)}=\\dots=p(i)^{(j)}\\right),\u2200 italic_p \u2208 script_P start_POSTSUBSCRIPT deterministic end_POSTSUBSCRIPT , \u2200 italic_i \u2208 script_I , ( roman_lim start_POSTSUBSCRIPT italic_j \u2192 \u221e end_POSTSUBSCRIPT italic_p ( italic_i ) start_POSTSUPERSCRIPT ( 1 ) end_POSTSUPERSCRIPT = italic_p ( italic_i ) start_POSTSUPERSCRIPT ( 2 ) end_POSTSUPERSCRIPT = \u22ef = italic_p ( italic_i ) start_POSTSUPERSCRIPT ( italic_j ) end_POSTSUPERSCRIPT ) ,(7)where(j)\ud835\udc57(j)( italic_j )indexes repeated independent executions of the program. That is, for all inputsi\ud835\udc56iitalic_i, the output ofp\u2062(i)\ud835\udc5d\ud835\udc56p(i)italic_p ( italic_i )remains identical with any independent execution of the program. Avalid program/input/output triplet(p,i,o)\ud835\udc5d\ud835\udc56\ud835\udc5c(p,i,o)( italic_p , italic_i , italic_o )is defined such thato=p\u2062(i)\ud835\udc5c\ud835\udc5d\ud835\udc56o=p(i)italic_o = italic_p ( italic_i ), wherep\u2208\ud835\udcabdeterministic\ud835\udc5dsubscript\ud835\udcabdeterministicp\\in\\mathscr{P}_{\\text{deterministic}}italic_p \u2208 script_P start_POSTSUBSCRIPT deterministic end_POSTSUBSCRIPT.Since the output of probabilistic programs can vary on every individual run, it is non-trivial to use verifiable functions to evaluate the correctness of an answer. Therefore, to keep the verifier simple, we restrict the valid programs generated by the learner to the class of deterministic programs. We believe that stochastic programs can encompass a larger class of behaviors and are important and promising to include in future versions of AZR.To implement the filtering of invalid probabilistic programs, and following the definition of a deterministic program highlighted inEquation7, we approximate this procedure by independently running the programj\ud835\udc57jitalic_jfinite times and checking that all the outputs are equal. For computational budget reasons, we fixedj=2\ud835\udc572j=2italic_j = 2for all experiments.Solving Task Construction.If a task proposal passes these three checks, we deem it a valid task and apply appropriate procedures to present part of the triplet to the solver. Specifically, we setx=(p,i)\ud835\udc65\ud835\udc5d\ud835\udc56x=(p,i)italic_x = ( italic_p , italic_i )for deduction;x=(p,o)\ud835\udc65\ud835\udc5d\ud835\udc5cx=(p,o)italic_x = ( italic_p , italic_o )for abduction; andx=({in,on}n=1N\u2063/\u2063/2,m)\ud835\udc65subscriptsuperscriptsuperscript\ud835\udc56\ud835\udc5bsuperscript\ud835\udc5c\ud835\udc5b\ud835\udc41absent2\ud835\udc5b1\ud835\udc5ax=(\\{i^{n},o^{n}\\}^{N//2}_{n=1},m)italic_x = ( { italic_i start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT , italic_o start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT } start_POSTSUPERSCRIPT italic_N / / 2 end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_n = 1 end_POSTSUBSCRIPT , italic_m )for induction, where half of the tests cases and a program descriptionm\ud835\udc5amitalic_mis used. We use all valid tasks from timestept\ud835\udc61titalic_t; if the batchB\ud835\udc35Bitalic_Bis not full, we uniformly sample from previously validated tasks to fill the batch.3.3.4Answer VerificationFor abduction task, we receivei\u03c0subscript\ud835\udc56\ud835\udf0bi_{\\pi}italic_i start_POSTSUBSCRIPT italic_\u03c0 end_POSTSUBSCRIPTfrom the solver policy, then we equivalence match usingp\u2062(i\u03c0)=p\u2062(i\u22c6)\ud835\udc5dsubscript\ud835\udc56\ud835\udf0b\ud835\udc5dsuperscript\ud835\udc56\u22c6p(i_{\\pi})=p(i^{\\star})italic_p ( italic_i start_POSTSUBSCRIPT italic_\u03c0 end_POSTSUBSCRIPT ) = italic_p ( italic_i start_POSTSUPERSCRIPT \u22c6 end_POSTSUPERSCRIPT ), where\u2217*\u2217refers to the privileged gold information. The reason we do not just matchi\u03c0subscript\ud835\udc56\ud835\udf0bi_{\\pi}italic_i start_POSTSUBSCRIPT italic_\u03c0 end_POSTSUBSCRIPTandi\u22c6superscript\ud835\udc56\u22c6i^{\\star}italic_i start_POSTSUPERSCRIPT \u22c6 end_POSTSUPERSCRIPTis becausep\ud835\udc5dpitalic_pis not necessarily bijective. For deduction task, we matcho\u03c0=o\u22c6subscript\ud835\udc5c\ud835\udf0bsuperscript\ud835\udc5c\u22c6o_{\\pi}=o^{\\star}italic_o start_POSTSUBSCRIPT italic_\u03c0 end_POSTSUBSCRIPT = italic_o start_POSTSUPERSCRIPT \u22c6 end_POSTSUPERSCRIPT. For induction, we matchall\u2061({p\u03c0\u2062(in\u22c6)=on\u22c6}N)allsuperscriptsubscript\ud835\udc5d\ud835\udf0bsuperscriptsubscript\ud835\udc56\ud835\udc5b\u22c6superscriptsubscript\ud835\udc5c\ud835\udc5b\u22c6\ud835\udc41\\operatorname{all}(\\{p_{\\pi}(i_{n}^{\\star})=o_{n}^{\\star}\\}^{N})roman_all ( { italic_p start_POSTSUBSCRIPT italic_\u03c0 end_POSTSUBSCRIPT ( italic_i start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT start_POSTSUPERSCRIPT \u22c6 end_POSTSUPERSCRIPT ) = italic_o start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT start_POSTSUPERSCRIPT \u22c6 end_POSTSUPERSCRIPT } start_POSTSUPERSCRIPT italic_N end_POSTSUPERSCRIPT ). This part might be convoluted to explain in language, therefore we recommend the reader to see how we did abduction, deduction and induction verification in code inFigures10,11and12, respectively.3.3.5Task-Relative REINFORCE++Since AZR trains the combination of roles and task types, it operates in a multitask reinforcement learning setup(Zhang & Yang,2021;Zhao et\u00a0al.,2022;Wang et\u00a0al.,2023;Yue et\u00a0al.,2023). Instead of computing a single global baseline as in REINFORCE++(Hu,2025)(AppendixA), we compute separate baselines for each of the six task-role configurations. This can be viewed as an interpolation between per-question baselines, as in GRPO(Shao et\u00a0al.,2024), and a global baseline, allowing for more structured variance reduction tailored to each task setup. We refer to this variant asTask-Relative REINFORCE++ (TRR++). The normalized advantageAnormsuperscript\ud835\udc34normA^{\\text{norm}}italic_A start_POSTSUPERSCRIPT norm end_POSTSUPERSCRIPTis computed as:Atask,rolenorm=r\u2212\u03bctask,role\u03c3task,role,task\u2208{ind,ded,abd},role\u2208{propose,solve},formulae-sequencesubscriptsuperscript\ud835\udc34normtask,role\ud835\udc5fsubscript\ud835\udf07task,rolesubscript\ud835\udf0etask,roleformulae-sequencetaskind,ded,abdrolepropose,solveA^{\\text{norm}}_{\\text{task,role}}=\\frac{r-\\mu_{\\text{task,role}}}{\\sigma_{%\n\\text{task,role}}},\\quad\\text{task}\\in\\{\\text{ind,ded,abd}\\},\\text{role}\\in\\{%\n\\text{propose,solve}\\},italic_A start_POSTSUPERSCRIPT norm end_POSTSUPERSCRIPT start_POSTSUBSCRIPT task,role end_POSTSUBSCRIPT = divide start_ARG italic_r - italic_\u03bc start_POSTSUBSCRIPT task,role end_POSTSUBSCRIPT end_ARG start_ARG italic_\u03c3 start_POSTSUBSCRIPT task,role end_POSTSUBSCRIPT end_ARG , task \u2208 { ind,ded,abd } , role \u2208 { propose,solve } ,(8)where the mean and standard deviation are computedwithin each task type and role, yielding six baselines.",
        "parent": null
      },
      {
        "_key": "sec_6d8d3b93",
        "_id": "sections/sec_6d8d3b93",
        "title": "3.1Two Roles in One: Proposer and Solver",
        "level": 3,
        "content": "Large language models are naturally suited for implementing AZR in a multitask learning context(Radford et\u00a0al.,2019), as both the formulation of reasoning tasks and their solutions occur within a unified language space. To this end, we propose rewarding a single model for both generating high learning potential tasks and solving them effectively, as specified by the Absolute Zero objective inEquation3. At each iteration of the online rollout, AZR proposes new reasoning tasks by conditioning on the task type (as defined inSection3.2) andK\ud835\udc3eKitalic_Kpast self-generated examples. The model is explicitly prompted to generate tasks that differ from these examples, promoting diversity and broader coverage of the task space. These task proposals are filtered and transformed into valid reasoning tasks that can be verified using the environment, outlined later inSection3.3. AZR then attempts to solve these newly proposed tasks, receiving grounded feedback for its model responses. Both task proposal and problem solving are trained using reinforcement learning. We now outline the rewards used for each role. Reward Design.Prior work has shown that setting appropriate task difficulty is critical for promoting effective learning in reasoning systems(Zeng et\u00a0al.,2025b). Motivated by this, we design a reward function for the proposer that encourages generation of tasks with meaningful learning potential\u2014neither too easy nor unsolvable for the current solver. Concretely, we use the same language model in its solver role to estimate thelearnabilityof a proposed task, a similar type of reward used in unsupervised environment design literature(Sukhbaatar et\u00a0al.,2018). We performn\ud835\udc5bnitalic_nMonte Carlo rollouts of the solver and compute the average success rate:r\u00afsolve=1n\u2062\u2211i=1Nrsolve(i)subscript\u00af\ud835\udc5fsolve1\ud835\udc5bsuperscriptsubscript\ud835\udc561\ud835\udc41superscriptsubscript\ud835\udc5fsolve\ud835\udc56\\bar{r}_{\\text{solve}}=\\frac{1}{n}\\sum_{i=1}^{N}r_{\\text{solve}}^{(i)}over\u00af start_ARG italic_r end_ARG start_POSTSUBSCRIPT solve end_POSTSUBSCRIPT = divide start_ARG 1 end_ARG start_ARG italic_n end_ARG \u2211 start_POSTSUBSCRIPT italic_i = 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_N end_POSTSUPERSCRIPT italic_r start_POSTSUBSCRIPT solve end_POSTSUBSCRIPT start_POSTSUPERSCRIPT ( italic_i ) end_POSTSUPERSCRIPT. The proposer\u2019s reward is then defined as:rpropose={0,if\u2062r\u00afsolve=0\u2062or\u2062r\u00afsolve=11\u2212r\u00afsolve,otherwise,subscript\ud835\udc5fproposecases0ifsubscript\u00af\ud835\udc5fsolve0orsubscript\u00af\ud835\udc5fsolve11subscript\u00af\ud835\udc5fsolveotherwise\\displaystyle r_{\\text{propose}}=\\begin{cases}0,&\\text{if }\\bar{r}_{\\text{%\nsolve}}=0\\text{ or }\\bar{r}_{\\text{solve}}=1\\\\\n1-\\bar{r}_{\\text{solve}},&\\text{otherwise},\\end{cases}italic_r start_POSTSUBSCRIPT propose end_POSTSUBSCRIPT = { start_ROW start_CELL 0 , end_CELL start_CELL if over\u00af start_ARG italic_r end_ARG start_POSTSUBSCRIPT solve end_POSTSUBSCRIPT = 0 or over\u00af start_ARG italic_r end_ARG start_POSTSUBSCRIPT solve end_POSTSUBSCRIPT = 1 end_CELL end_ROW start_ROW start_CELL 1 - over\u00af start_ARG italic_r end_ARG start_POSTSUBSCRIPT solve end_POSTSUBSCRIPT , end_CELL start_CELL otherwise , end_CELL end_ROW(4)Figure 4:Absolute Zero Reasoner Training Overview.At every iteration, Absolute Zero Reasoner firstPROPOSESa batch of tasks, conditioned on past self-generated triplets stored in a buffer and a particular task type: abduction, deduction, or induction\u00a0(Section3.2). From these generated tasks, Python is used to filter and construct valid code-based reasoning questions. A learnability rewardrproposesubscript\ud835\udc5fproposer_{\\text{propose}}italic_r start_POSTSUBSCRIPT propose end_POSTSUBSCRIPTis also calculated for each proposed task as defined inEquation4. The Absolute Zero Reasoner thenSOLVESthe batch of reasoning questions. Python is used again to verify the generated responses and compute the accuracy rewardrsolvesubscript\ud835\udc5fsolver_{\\text{solve}}italic_r start_POSTSUBSCRIPT solve end_POSTSUBSCRIPTas described inEquation5. Finally, the Absolute Zero Reasoner is jointly updated using bothrproposesubscript\ud835\udc5fproposer_{\\text{propose}}italic_r start_POSTSUBSCRIPT propose end_POSTSUBSCRIPTandrsolvesubscript\ud835\udc5fsolver_{\\text{solve}}italic_r start_POSTSUBSCRIPT solve end_POSTSUBSCRIPTacross all three task types, using TRR++\u00a0(Section3.3.5).The intuition is that if a task is either trivial to solve (r\u00afsolve=1subscript\u00af\ud835\udc5fsolve1\\bar{r}_{\\text{solve}}=1over\u00af start_ARG italic_r end_ARG start_POSTSUBSCRIPT solve end_POSTSUBSCRIPT = 1) or unsolvable (r\u00afsolve=0subscript\u00af\ud835\udc5fsolve0\\bar{r}_{\\text{solve}}=0over\u00af start_ARG italic_r end_ARG start_POSTSUBSCRIPT solve end_POSTSUBSCRIPT = 0), the task provides little to no learning signal for the proposer. In contrast, tasks of moderate difficulty, where the solver occasionally succeeds are rewarded the most, as they offer the richest feedback and greatest potential for learning.For the solver, we assign a simple binary reward based on the correctness of its final output,rsolve=\ud835\udd40(y=y\u22c6),subscript\ud835\udc5fsolvesubscript\ud835\udd40\ud835\udc66superscript\ud835\udc66\u22c6\\displaystyle r_{\\text{solve}}=\\mathbb{I}_{(y=y^{\\star})},italic_r start_POSTSUBSCRIPT solve end_POSTSUBSCRIPT = blackboard_I start_POSTSUBSCRIPT ( italic_y = italic_y start_POSTSUPERSCRIPT \u22c6 end_POSTSUPERSCRIPT ) end_POSTSUBSCRIPT ,(5)wherey\u22c6superscript\ud835\udc66\u22c6y^{\\star}italic_y start_POSTSUPERSCRIPT \u22c6 end_POSTSUPERSCRIPTis the ground-truth answer, and equality is evaluated based on value equality in Python.With the primary rewards for the proposing and solving roles defined, we adopt the following composite reward structure, which integratesrproposesubscript\ud835\udc5fproposer_{\\text{propose}}italic_r start_POSTSUBSCRIPT propose end_POSTSUBSCRIPTandrsolvesubscript\ud835\udc5fsolver_{\\text{solve}}italic_r start_POSTSUBSCRIPT solve end_POSTSUBSCRIPTwith a format-aware penalty inspired byDeepSeek-AI et\u00a0al.(2025):R\u2062(y\u03c0)={rroleif the response is passable,\u2062role\u2208{propose,solve}\u22120.5if the response is wrong but well-formatted,\u22121if the answer has formatting errors,\ud835\udc45subscript\ud835\udc66\ud835\udf0bcasessubscript\ud835\udc5froleif the response is passable,rolepropose,solve0.5if the response is wrong but well-formatted,1if the answer has formatting errors,\\displaystyle R(y_{\\pi})=\\begin{cases}r_{\\text{role}}&\\text{if the response is%\n passable,}~{}\\text{role}\\in\\{\\text{propose,solve}\\}\\\\\n-0.5&\\text{if the response is wrong but well-formatted,}\\\\\n-1&\\text{if the answer has formatting errors,}\\end{cases}italic_R ( italic_y start_POSTSUBSCRIPT italic_\u03c0 end_POSTSUBSCRIPT ) = { start_ROW start_CELL italic_r start_POSTSUBSCRIPT role end_POSTSUBSCRIPT end_CELL start_CELL if the response is passable, role \u2208 { propose,solve } end_CELL end_ROW start_ROW start_CELL - 0.5 end_CELL start_CELL if the response is wrong but well-formatted, end_CELL end_ROW start_ROW start_CELL - 1 end_CELL start_CELL if the answer has formatting errors, end_CELL end_ROW(6)wherey\u03c0subscript\ud835\udc66\ud835\udf0by_{\\pi}italic_y start_POSTSUBSCRIPT italic_\u03c0 end_POSTSUBSCRIPTis the response of the language model. The main format that the proposing and solving tasks need to follow is the DeepSeek R1<think>and<answer>format, as shown inFigure33. Moreover, for the proposer, the reward criterion for format goes beyond simply following the XML structure. As detailed inSection3.3.3, only responses that produce valid triplets and pass the filtering stage are considered to be correctly formatted.",
        "parent": "sec_1a5d9820"
      },
      {
        "_key": "sec_2f0cfe08",
        "_id": "sections/sec_2f0cfe08",
        "title": "Reward Design.",
        "level": 5,
        "content": "Prior work has shown that setting appropriate task difficulty is critical for promoting effective learning in reasoning systems(Zeng et\u00a0al.,2025b). Motivated by this, we design a reward function for the proposer that encourages generation of tasks with meaningful learning potential\u2014neither too easy nor unsolvable for the current solver. Concretely, we use the same language model in its solver role to estimate thelearnabilityof a proposed task, a similar type of reward used in unsupervised environment design literature(Sukhbaatar et\u00a0al.,2018). We performn\ud835\udc5bnitalic_nMonte Carlo rollouts of the solver and compute the average success rate:r\u00afsolve=1n\u2062\u2211i=1Nrsolve(i)subscript\u00af\ud835\udc5fsolve1\ud835\udc5bsuperscriptsubscript\ud835\udc561\ud835\udc41superscriptsubscript\ud835\udc5fsolve\ud835\udc56\\bar{r}_{\\text{solve}}=\\frac{1}{n}\\sum_{i=1}^{N}r_{\\text{solve}}^{(i)}over\u00af start_ARG italic_r end_ARG start_POSTSUBSCRIPT solve end_POSTSUBSCRIPT = divide start_ARG 1 end_ARG start_ARG italic_n end_ARG \u2211 start_POSTSUBSCRIPT italic_i = 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_N end_POSTSUPERSCRIPT italic_r start_POSTSUBSCRIPT solve end_POSTSUBSCRIPT start_POSTSUPERSCRIPT ( italic_i ) end_POSTSUPERSCRIPT. The proposer\u2019s reward is then defined as: rpropose={0,if\u2062r\u00afsolve=0\u2062or\u2062r\u00afsolve=11\u2212r\u00afsolve,otherwise,subscript\ud835\udc5fproposecases0ifsubscript\u00af\ud835\udc5fsolve0orsubscript\u00af\ud835\udc5fsolve11subscript\u00af\ud835\udc5fsolveotherwise\\displaystyle r_{\\text{propose}}=\\begin{cases}0,&\\text{if }\\bar{r}_{\\text{%\nsolve}}=0\\text{ or }\\bar{r}_{\\text{solve}}=1\\\\\n1-\\bar{r}_{\\text{solve}},&\\text{otherwise},\\end{cases}italic_r start_POSTSUBSCRIPT propose end_POSTSUBSCRIPT = { start_ROW start_CELL 0 , end_CELL start_CELL if over\u00af start_ARG italic_r end_ARG start_POSTSUBSCRIPT solve end_POSTSUBSCRIPT = 0 or over\u00af start_ARG italic_r end_ARG start_POSTSUBSCRIPT solve end_POSTSUBSCRIPT = 1 end_CELL end_ROW start_ROW start_CELL 1 - over\u00af start_ARG italic_r end_ARG start_POSTSUBSCRIPT solve end_POSTSUBSCRIPT , end_CELL start_CELL otherwise , end_CELL end_ROW(4) Figure 4:Absolute Zero Reasoner Training Overview.At every iteration, Absolute Zero Reasoner firstPROPOSESa batch of tasks, conditioned on past self-generated triplets stored in a buffer and a particular task type: abduction, deduction, or induction\u00a0(Section3.2). From these generated tasks, Python is used to filter and construct valid code-based reasoning questions. A learnability rewardrproposesubscript\ud835\udc5fproposer_{\\text{propose}}italic_r start_POSTSUBSCRIPT propose end_POSTSUBSCRIPTis also calculated for each proposed task as defined inEquation4. The Absolute Zero Reasoner thenSOLVESthe batch of reasoning questions. Python is used again to verify the generated responses and compute the accuracy rewardrsolvesubscript\ud835\udc5fsolver_{\\text{solve}}italic_r start_POSTSUBSCRIPT solve end_POSTSUBSCRIPTas described inEquation5. Finally, the Absolute Zero Reasoner is jointly updated using bothrproposesubscript\ud835\udc5fproposer_{\\text{propose}}italic_r start_POSTSUBSCRIPT propose end_POSTSUBSCRIPTandrsolvesubscript\ud835\udc5fsolver_{\\text{solve}}italic_r start_POSTSUBSCRIPT solve end_POSTSUBSCRIPTacross all three task types, using TRR++\u00a0(Section3.3.5). The intuition is that if a task is either trivial to solve (r\u00afsolve=1subscript\u00af\ud835\udc5fsolve1\\bar{r}_{\\text{solve}}=1over\u00af start_ARG italic_r end_ARG start_POSTSUBSCRIPT solve end_POSTSUBSCRIPT = 1) or unsolvable (r\u00afsolve=0subscript\u00af\ud835\udc5fsolve0\\bar{r}_{\\text{solve}}=0over\u00af start_ARG italic_r end_ARG start_POSTSUBSCRIPT solve end_POSTSUBSCRIPT = 0), the task provides little to no learning signal for the proposer. In contrast, tasks of moderate difficulty, where the solver occasionally succeeds are rewarded the most, as they offer the richest feedback and greatest potential for learning. For the solver, we assign a simple binary reward based on the correctness of its final output, rsolve=\ud835\udd40(y=y\u22c6),subscript\ud835\udc5fsolvesubscript\ud835\udd40\ud835\udc66superscript\ud835\udc66\u22c6\\displaystyle r_{\\text{solve}}=\\mathbb{I}_{(y=y^{\\star})},italic_r start_POSTSUBSCRIPT solve end_POSTSUBSCRIPT = blackboard_I start_POSTSUBSCRIPT ( italic_y = italic_y start_POSTSUPERSCRIPT \u22c6 end_POSTSUPERSCRIPT ) end_POSTSUBSCRIPT ,(5) wherey\u22c6superscript\ud835\udc66\u22c6y^{\\star}italic_y start_POSTSUPERSCRIPT \u22c6 end_POSTSUPERSCRIPTis the ground-truth answer, and equality is evaluated based on value equality in Python. With the primary rewards for the proposing and solving roles defined, we adopt the following composite reward structure, which integratesrproposesubscript\ud835\udc5fproposer_{\\text{propose}}italic_r start_POSTSUBSCRIPT propose end_POSTSUBSCRIPTandrsolvesubscript\ud835\udc5fsolver_{\\text{solve}}italic_r start_POSTSUBSCRIPT solve end_POSTSUBSCRIPTwith a format-aware penalty inspired byDeepSeek-AI et\u00a0al.(2025): R\u2062(y\u03c0)={rroleif the response is passable,\u2062role\u2208{propose,solve}\u22120.5if the response is wrong but well-formatted,\u22121if the answer has formatting errors,\ud835\udc45subscript\ud835\udc66\ud835\udf0bcasessubscript\ud835\udc5froleif the response is passable,rolepropose,solve0.5if the response is wrong but well-formatted,1if the answer has formatting errors,\\displaystyle R(y_{\\pi})=\\begin{cases}r_{\\text{role}}&\\text{if the response is%\n passable,}~{}\\text{role}\\in\\{\\text{propose,solve}\\}\\\\\n-0.5&\\text{if the response is wrong but well-formatted,}\\\\\n-1&\\text{if the answer has formatting errors,}\\end{cases}italic_R ( italic_y start_POSTSUBSCRIPT italic_\u03c0 end_POSTSUBSCRIPT ) = { start_ROW start_CELL italic_r start_POSTSUBSCRIPT role end_POSTSUBSCRIPT end_CELL start_CELL if the response is passable, role \u2208 { propose,solve } end_CELL end_ROW start_ROW start_CELL - 0.5 end_CELL start_CELL if the response is wrong but well-formatted, end_CELL end_ROW start_ROW start_CELL - 1 end_CELL start_CELL if the answer has formatting errors, end_CELL end_ROW(6) wherey\u03c0subscript\ud835\udc66\ud835\udf0by_{\\pi}italic_y start_POSTSUBSCRIPT italic_\u03c0 end_POSTSUBSCRIPTis the response of the language model. The main format that the proposing and solving tasks need to follow is the DeepSeek R1<think>and<answer>format, as shown inFigure33. Moreover, for the proposer, the reward criterion for format goes beyond simply following the XML structure. As detailed inSection3.3.3, only responses that produce valid triplets and pass the filtering stage are considered to be correctly formatted.",
        "parent": "sec_6d8d3b93"
      },
      {
        "_key": "sec_0d24aa19",
        "_id": "sections/sec_0d24aa19",
        "title": "3.2Learning Different Modes of Reasoning: Deduction, Induction, and Abduction",
        "level": 3,
        "content": "AZR uses code executor as both a flexible interface and a verifiable environment. This setup enables automatic construction, execution, and validation of code reasoning tasks(Stuart,2015;Aryabumi et\u00a0al.,2024). Give program space\ud835\udcab\ud835\udcab\\mathscr{P}script_P, input space\u2110\u2110\\mathscr{I}script_Iand output space\ud835\udcaa\ud835\udcaa\\mathscr{O}script_Oof a coding language, we define an AZR reasoning task as a triplet(p,i,o)\ud835\udc5d\ud835\udc56\ud835\udc5c(p,i,o)( italic_p , italic_i , italic_o ), wherep\u2208\ud835\udcab\ud835\udc5d\ud835\udcabp\\in\\mathscr{P}italic_p \u2208 script_Pis a program,i\u2208\u2110\ud835\udc56\u2110i\\in\\mathscr{I}italic_i \u2208 script_Iis an input, ando\u2208\ud835\udcaa\ud835\udc5c\ud835\udcaao\\in\\mathscr{O}italic_o \u2208 script_Ois the corresponding output produced by running program on input,o=p\u2062(i)\ud835\udc5c\ud835\udc5d\ud835\udc56o=p(i)italic_o = italic_p ( italic_i ). AZR learns by reasoning about different parts of this task triplet, using three distinct core reasoning modes, each of which focuses on inferring one part of the triplet given the others: 1.Deduction: predicting the outputo\ud835\udc5coitalic_ogiven a programp\ud835\udc5dpitalic_pand inputi\ud835\udc56iitalic_i, capturing step-by-step logical reasoning.\u2022As aproposer, AZR is conditioned on the task type\u03b1=deduction\ud835\udefcdeduction\\alpha=\\text{deduction}italic_\u03b1 = deductionandK\ud835\udc3eKitalic_Kreference examples from the deduction buffer\ud835\udc9fdeductionsubscript\ud835\udc9fdeduction\\mathcal{D}_{\\text{deduction}}caligraphic_D start_POSTSUBSCRIPT deduction end_POSTSUBSCRIPT(all task buffers are outlined inSection3.3), and generates a pair(p,i)\ud835\udc5d\ud835\udc56(p,i)( italic_p , italic_i ). The environmente\ud835\udc52eitalic_ethen executesp\u2062(i)\ud835\udc5d\ud835\udc56p(i)italic_p ( italic_i )to computeo\ud835\udc5coitalic_o, completing the triplet(p,i,o)\ud835\udc5d\ud835\udc56\ud835\udc5c(p,i,o)( italic_p , italic_i , italic_o ), which is added to the buffer if non-error output was produced.\u2022As asolver, the model receives(p,i)\ud835\udc5d\ud835\udc56(p,i)( italic_p , italic_i )and predicts the outputo\u03c0subscript\ud835\udc5c\ud835\udf0bo_{\\pi}italic_o start_POSTSUBSCRIPT italic_\u03c0 end_POSTSUBSCRIPT. The predicted output is verified using type-aware value equality in python to account for possible variations (such as set ordering or fractions).2.Abduction: inferring a plausible inputi\ud835\udc56iitalic_igiven the programp\ud835\udc5dpitalic_pand an outputo\ud835\udc5coitalic_o, resembling trial-and-error or online search.\u2022As aproposer, the policy\u03c0proposesuperscript\ud835\udf0bpropose\\pi^{\\text{propose}}italic_\u03c0 start_POSTSUPERSCRIPT propose end_POSTSUPERSCRIPT\u2019s input and output is almost the same as the proposer for the deduction task, except that the task type\u03b1=abduction\ud835\udefcabduction\\alpha=\\text{abduction}italic_\u03b1 = abductionis changed as an input. The model generates a pair(p,i)\ud835\udc5d\ud835\udc56(p,i)( italic_p , italic_i )conditioned on\u03b1\ud835\udefc\\alphaitalic_\u03b1and reference examples. Then we executesp\u2062(i)\ud835\udc5d\ud835\udc56p(i)italic_p ( italic_i )and get the triplet(p,i,o)\ud835\udc5d\ud835\udc56\ud835\udc5c(p,i,o)( italic_p , italic_i , italic_o ).\u2022As asolver, the model receives(p,o)\ud835\udc5d\ud835\udc5c(p,o)( italic_p , italic_o )and predictsi\u03c0subscript\ud835\udc56\ud835\udf0bi_{\\pi}italic_i start_POSTSUBSCRIPT italic_\u03c0 end_POSTSUBSCRIPT. The solution is verified by checking whetherp\u2062(i\u03c0)=o\ud835\udc5dsubscript\ud835\udc56\ud835\udf0b\ud835\udc5cp(i_{\\pi})=oitalic_p ( italic_i start_POSTSUBSCRIPT italic_\u03c0 end_POSTSUBSCRIPT ) = italic_o. Since programs may not be bijective, we useoutputvalue equivalence rather than requiring exact input matches.3.Induction:synthesizing a programp\ud835\udc5dpitalic_pfrom a set of in-out examples{(in,on)}superscript\ud835\udc56\ud835\udc5bsuperscript\ud835\udc5c\ud835\udc5b\\{(i^{n},o^{n})\\}{ ( italic_i start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT , italic_o start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT ) }, requiring generalization from partial information.\u2022As aproposer, AZR samples a valid programp\ud835\udc5dpitalic_pfrom\ud835\udc9fabduction\u222a\ud835\udc9fdeductionsubscript\ud835\udc9fabductionsubscript\ud835\udc9fdeduction\\mathcal{D}_{\\text{abduction}}\\cup\\mathcal{D}_{\\text{deduction}}caligraphic_D start_POSTSUBSCRIPT abduction end_POSTSUBSCRIPT \u222a caligraphic_D start_POSTSUBSCRIPT deduction end_POSTSUBSCRIPT, generatesN\ud835\udc41Nitalic_Nnew inputs and a messagem\ud835\udc5amitalic_m, and uses the environment to compute corresponding outputs. This forms an extended task representation(p,{(in,on)},m)\ud835\udc5dsuperscript\ud835\udc56\ud835\udc5bsuperscript\ud835\udc5c\ud835\udc5b\ud835\udc5a(p,\\{(i^{n},o^{n})\\},m)( italic_p , { ( italic_i start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT , italic_o start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT ) } , italic_m ), which is stored in the induction buffer\ud835\udc9finductionsubscript\ud835\udc9finduction\\mathcal{D}_{\\text{induction}}caligraphic_D start_POSTSUBSCRIPT induction end_POSTSUBSCRIPT. Since infinitely many functions can map the inputs to the outputs, making the induction task under-constrained, the messagem\ud835\udc5amitalic_mhelps properly condition the problem for the solver.\u2022As asolver, the model is shown the first half of the input-output pairs and the messagem\ud835\udc5amitalic_m, and must synthesize a programp\u03c0subscript\ud835\udc5d\ud835\udf0bp_{\\pi}italic_p start_POSTSUBSCRIPT italic_\u03c0 end_POSTSUBSCRIPTthat correctly maps the remaining hidden inputs to their outputs. The use of held-out examples discourages overfitting through if-else logic and promotes generalized induction. Figure 5:The Seed AZR Zero Triplet.The above identity function triplet was the only triplet provided to AZR to initiate its self-bootstrap propose-and-solve RLVR loop. We note that the base LLM is fully capable of initiating the AZR loop without any seed program; its inclusion illustrates our approach\u2019s flexibility: we can optionally initialize seed programs with existing datasets of varying complexity, and we initialized ours with the simplest program. Each reasoning task type leverages code as an expressive and verifiable medium, aligning with the Absolute Zero Paradigm\u2019s goals of fully self-improving systems in open-ended domains(DeepSeek-AI et\u00a0al.,2025;Lambert et\u00a0al.,2024). All prompts used by three different task types and two types of roles within a task type are shown inFigures36,34,35,39,37and38. Next, we outline exact details of our algorithm.",
        "parent": "sec_1a5d9820"
      },
      {
        "_key": "sec_3d319639",
        "_id": "sections/sec_3d319639",
        "title": "3.3Absolute Zero Reasoner Learning Algorithm",
        "level": 3,
        "content": "In this section, we will discuss details of our AZR self-play algorithm, including initialization of buffers3.3.1, usage of thse buffers3.3.2, construction of valid tasks3.3.3, validating solutions3.3.4, and finally advantage estimator calculation3.3.5. We outline the overall recipe of the self-play procedure of AZR inAlgorithm1. 3.3.1Buffer InitializationTo initialize AZR self-play, we first generate a seed set of valid triplets using the base language model. Each prompt samples up toK\ud835\udc3eKitalic_Ktriplets from the current seed buffer\ud835\udc9fseedsubscript\ud835\udc9fseed\\mathcal{D}_{\\text{seed}}caligraphic_D start_POSTSUBSCRIPT seed end_POSTSUBSCRIPTas references. When\ud835\udc9fseedsubscript\ud835\udc9fseed\\mathcal{D}_{\\text{seed}}caligraphic_D start_POSTSUBSCRIPT seed end_POSTSUBSCRIPTis empty at time 0, we fall back to the zero triplet show inFigure5. During the seeding stage, we use the same proposer prompts detailed inFigures34,35and36.First, for deduction and abduction tasks, the LLM is prompted to generate(p,i)\ud835\udc5d\ud835\udc56(p,i)( italic_p , italic_i )pairs, which are filtered, executed, and stored as valid triplets. We initialize\ud835\udc9fabduction0=\ud835\udc9fdeduction0=\ud835\udc9fseedsubscriptsuperscript\ud835\udc9f0abductionsubscriptsuperscript\ud835\udc9f0deductionsubscript\ud835\udc9fseed\\mathcal{D}^{0}_{\\text{abduction}}=\\mathcal{D}^{0}_{\\text{deduction}}=\\mathcal%\n{D}_{\\text{seed}}caligraphic_D start_POSTSUPERSCRIPT 0 end_POSTSUPERSCRIPT start_POSTSUBSCRIPT abduction end_POSTSUBSCRIPT = caligraphic_D start_POSTSUPERSCRIPT 0 end_POSTSUPERSCRIPT start_POSTSUBSCRIPT deduction end_POSTSUBSCRIPT = caligraphic_D start_POSTSUBSCRIPT seed end_POSTSUBSCRIPT, where|\ud835\udc9fseed|=B\u00d7Ssubscript\ud835\udc9fseed\ud835\udc35\ud835\udc46|\\mathcal{D}_{\\text{seed}}|=B\\times S| caligraphic_D start_POSTSUBSCRIPT seed end_POSTSUBSCRIPT | = italic_B \u00d7 italic_S, whereB\ud835\udc35Bitalic_Bis the batch size, andS=4\ud835\udc464S=4italic_S = 4is a factor we fix in all experiments. All seed triplet\u2019s program are stripped of global variables and comments (AppendixD), but subsequent iterations of adding new triplets to the buffers are unaltered. No model updates occur during this phase. Similarly, to initialize the induction buffer, we sample programs from\ud835\udc9fseedsubscript\ud835\udc9fseed\\mathcal{D}_{\\text{seed}}caligraphic_D start_POSTSUBSCRIPT seed end_POSTSUBSCRIPT, generate matching input sets and messages, and collect valid examples until|\ud835\udc9finduction0|=B\u00d7Ssubscriptsuperscript\ud835\udc9f0induction\ud835\udc35\ud835\udc46|\\mathcal{D}^{0}_{\\text{induction}}|=B\\times S| caligraphic_D start_POSTSUPERSCRIPT 0 end_POSTSUPERSCRIPT start_POSTSUBSCRIPT induction end_POSTSUBSCRIPT | = italic_B \u00d7 italic_S. 3.3.2Task Proposal Inputs and Buffer ManagementDuring the actual self-play stage of AZR, we use the task buffer in three ways.First, for the proposer of abduction and deduction tasks, we uniformly sampleK\ud835\udc3eKitalic_Kpast triplets from the buffer, present them as in-context examples to the proposer and let it generate a new task. The design is to show it past examples, and prompt it to generate a different one to promote diversity(Zhao et\u00a0al.,2025a).Second, we sample one triplet from the union of abduction and deduction buffers\ud835\udc9fabd\u2062\u22c3\ud835\udc9fdedsubscript\ud835\udc9fabdsubscript\ud835\udc9fded\\mathcal{D}_{\\text{abd}}\\bigcup\\mathcal{D}_{\\text{ded}}caligraphic_D start_POSTSUBSCRIPT abd end_POSTSUBSCRIPT \u22c3 caligraphic_D start_POSTSUBSCRIPT ded end_POSTSUBSCRIPT, and present the programp\ud835\udc5dpitalic_pfrom that triplet to the induction proposer to generate a set ofN\ud835\udc41Nitalic_Nmatching inputs{in}superscript\ud835\udc56\ud835\udc5b\\{i^{n}\\}{ italic_i start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT }and a natural language messagem\ud835\udc5amitalic_m.Lastly, to maintain stable training, if a batch of solver problems contains fewer thanB\ud835\udc35Bitalic_Bvalid proposed tasks (proposer not adhering to formatting), we fill the remainder by uniformly sampling from the corresponding task buffer of previously validated triplets.The buffer grows for abduction and deduction tasks whenever\u03c0\ud835\udf0b\\piitalic_\u03c0propose a valid triplet(p,i,o)\ud835\udc5d\ud835\udc56\ud835\udc5c(p,i,o)( italic_p , italic_i , italic_o ), regardless if it gets any task reward. Similarly, for induction tasks, all valid triplets(p,{in,on}),m\ud835\udc5dsuperscript\ud835\udc56\ud835\udc5bsuperscript\ud835\udc5c\ud835\udc5b\ud835\udc5a(p,\\{i^{n},o^{n}\\}),m( italic_p , { italic_i start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT , italic_o start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT } ) , italic_mare added to the buffer.Algorithm 1Self-Play Training of Absolute Zero Reasoner (AZR)1:Pretrained base LLM\u03c0\u03b8subscript\ud835\udf0b\ud835\udf03\\pi_{\\theta}italic_\u03c0 start_POSTSUBSCRIPT italic_\u03b8 end_POSTSUBSCRIPT; batch sizeB\ud835\udc35Bitalic_B; #referencesK\ud835\udc3eKitalic_K; iterationsT\ud835\udc47Titalic_T2:\ud835\udc9fded,\ud835\udc9fabd,\ud835\udc9find\u2190InitSeeding\u2062(\u03c0\u03b8)\u2190subscript\ud835\udc9fdedsubscript\ud835\udc9fabdsubscript\ud835\udc9findInitSeedingsubscript\ud835\udf0b\ud835\udf03\\mathcal{D}_{\\text{ded}},\\mathcal{D}_{\\text{abd}},\\mathcal{D}_{\\text{ind}}%\n\\leftarrow\\textsc{InitSeeding}(\\pi_{\\theta})caligraphic_D start_POSTSUBSCRIPT ded end_POSTSUBSCRIPT , caligraphic_D start_POSTSUBSCRIPT abd end_POSTSUBSCRIPT , caligraphic_D start_POSTSUBSCRIPT ind end_POSTSUBSCRIPT \u2190 InitSeeding ( italic_\u03c0 start_POSTSUBSCRIPT italic_\u03b8 end_POSTSUBSCRIPT )\u25b7\u25b7\\triangleright\u25b7see \u00a73.3.13:fort\u21901\u2190\ud835\udc611t\\leftarrow 1italic_t \u2190 1toT\ud835\udc47Titalic_Tdo4:forb\u21901\u2190\ud835\udc4f1b\\leftarrow 1italic_b \u2190 1toB\ud835\udc35Bitalic_Bdo\u25b7\u25b7\\triangleright\u25b7PROPOSE PHASE5:p\u223c\ud835\udc9fabd\u222a\ud835\udc9fdedsimilar-to\ud835\udc5dsubscript\ud835\udc9fabdsubscript\ud835\udc9fdedp\\sim\\mathcal{D}_{\\text{abd}}\\cup\\mathcal{D}_{\\text{ded}}italic_p \u223c caligraphic_D start_POSTSUBSCRIPT abd end_POSTSUBSCRIPT \u222a caligraphic_D start_POSTSUBSCRIPT ded end_POSTSUBSCRIPT\u25b7\u25b7\\triangleright\u25b7sample a program for induction task proposal6:{i\u03c0n}n=1N,m\u03c0\u2190\u03c0\u03b8propose\u2062(ind,p)\u2190superscriptsubscriptsubscriptsuperscript\ud835\udc56\ud835\udc5b\ud835\udf0b\ud835\udc5b1\ud835\udc41subscript\ud835\udc5a\ud835\udf0bsuperscriptsubscript\ud835\udf0b\ud835\udf03proposeind\ud835\udc5d\\bigl{\\{}i^{n}_{\\pi}\\bigr{\\}}_{n=1}^{N},\\;m_{\\pi}\\leftarrow\\pi_{\\theta}^{\\text%\n{propose}}(\\text{ind},p){ italic_i start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_\u03c0 end_POSTSUBSCRIPT } start_POSTSUBSCRIPT italic_n = 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_N end_POSTSUPERSCRIPT , italic_m start_POSTSUBSCRIPT italic_\u03c0 end_POSTSUBSCRIPT \u2190 italic_\u03c0 start_POSTSUBSCRIPT italic_\u03b8 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT propose end_POSTSUPERSCRIPT ( ind , italic_p )\u25b7\u25b7\\triangleright\u25b7generateN\ud835\udc41Nitalic_Ninputs and a description7:if{(i\u03c0n,o\u03c0n)}n=1N\u2190ValidateByExecuting\u2062(p,{i\u03c0n},syntax)\u2190superscriptsubscriptsubscriptsuperscript\ud835\udc56\ud835\udc5b\ud835\udf0bsubscriptsuperscript\ud835\udc5c\ud835\udc5b\ud835\udf0b\ud835\udc5b1\ud835\udc41ValidateByExecuting\ud835\udc5dsubscriptsuperscript\ud835\udc56\ud835\udc5b\ud835\udf0bsyntax\\bigl{\\{}(i^{n}_{\\pi},o^{n}_{\\pi})\\bigr{\\}}_{n=1}^{N}\\leftarrow\\textsc{%\nValidateByExecuting}\\bigl{(}p,\\{i^{n}_{\\pi}\\},\\textsc{syntax}\\bigr{)}{ ( italic_i start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_\u03c0 end_POSTSUBSCRIPT , italic_o start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_\u03c0 end_POSTSUBSCRIPT ) } start_POSTSUBSCRIPT italic_n = 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_N end_POSTSUPERSCRIPT \u2190 ValidateByExecuting ( italic_p , { italic_i start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_\u03c0 end_POSTSUBSCRIPT } , syntax )then\u25b7\u25b7\\triangleright\u25b7validate I/Os, see \u00a73.3.38:\ud835\udc9find\u2190\ud835\udc9find\u222a{(p,{(i\u03c0n,o\u03c0n)},m\u03c0)}\u2190subscript\ud835\udc9findsubscript\ud835\udc9find\ud835\udc5dsubscriptsuperscript\ud835\udc56\ud835\udc5b\ud835\udf0bsubscriptsuperscript\ud835\udc5c\ud835\udc5b\ud835\udf0bsubscript\ud835\udc5a\ud835\udf0b\\mathcal{D}_{\\text{ind}}\\leftarrow\\mathcal{D}_{\\text{ind}}\\cup\\bigl{\\{}(p,\\{(i%\n^{n}_{\\pi},o^{n}_{\\pi})\\},m_{\\pi})\\bigr{\\}}caligraphic_D start_POSTSUBSCRIPT ind end_POSTSUBSCRIPT \u2190 caligraphic_D start_POSTSUBSCRIPT ind end_POSTSUBSCRIPT \u222a { ( italic_p , { ( italic_i start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_\u03c0 end_POSTSUBSCRIPT , italic_o start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_\u03c0 end_POSTSUBSCRIPT ) } , italic_m start_POSTSUBSCRIPT italic_\u03c0 end_POSTSUBSCRIPT ) }\u25b7\u25b7\\triangleright\u25b7update induction buffer9:for\u03b1\u2208{ded,abd}\ud835\udefcdedabd\\alpha\\in\\{\\text{ded},\\text{abd}\\}italic_\u03b1 \u2208 { ded , abd }do10:(pk,ik,ok)k=1K\u223c\ud835\udc9f\u03b1similar-tosuperscriptsubscriptsubscript\ud835\udc5d\ud835\udc58subscript\ud835\udc56\ud835\udc58subscript\ud835\udc5c\ud835\udc58\ud835\udc581\ud835\udc3esubscript\ud835\udc9f\ud835\udefc\\bigl{(}p_{k},i_{k},o_{k}\\bigr{)}_{k=1}^{K}\\sim\\mathcal{D}_{\\alpha}( italic_p start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT , italic_i start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT , italic_o start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT ) start_POSTSUBSCRIPT italic_k = 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_K end_POSTSUPERSCRIPT \u223c caligraphic_D start_POSTSUBSCRIPT italic_\u03b1 end_POSTSUBSCRIPT\u25b7\u25b7\\triangleright\u25b7sampleK\ud835\udc3eKitalic_Kreference examples11:(p\u03c0,i\u03c0)\u2190\u03c0\u03b8propose\u2062(\u03b1,{(pk,ik,ok)})\u2190subscript\ud835\udc5d\ud835\udf0bsubscript\ud835\udc56\ud835\udf0bsuperscriptsubscript\ud835\udf0b\ud835\udf03propose\ud835\udefcsubscript\ud835\udc5d\ud835\udc58subscript\ud835\udc56\ud835\udc58subscript\ud835\udc5c\ud835\udc58(p_{\\pi},i_{\\pi})\\leftarrow\\pi_{\\theta}^{\\text{propose}}\\!\\bigl{(}\\alpha,\\{(p_%\n{k},i_{k},o_{k})\\}\\bigr{)}( italic_p start_POSTSUBSCRIPT italic_\u03c0 end_POSTSUBSCRIPT , italic_i start_POSTSUBSCRIPT italic_\u03c0 end_POSTSUBSCRIPT ) \u2190 italic_\u03c0 start_POSTSUBSCRIPT italic_\u03b8 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT propose end_POSTSUPERSCRIPT ( italic_\u03b1 , { ( italic_p start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT , italic_i start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT , italic_o start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT ) } )\u25b7\u25b7\\triangleright\u25b7propose new task12:ifo\u03c0\u2190ValidateByExecuting\u2062(p\u03c0,i\u03c0,syntax,safety,determinism)\u2190subscript\ud835\udc5c\ud835\udf0bValidateByExecutingsubscript\ud835\udc5d\ud835\udf0bsubscript\ud835\udc56\ud835\udf0bsyntax,safety,determinismo_{\\pi}\\leftarrow\\textsc{ValidateByExecuting}\\bigl{(}p_{\\pi},i_{\\pi},\\textsc{%\nsyntax,safety,determinism}\\bigr{)}italic_o start_POSTSUBSCRIPT italic_\u03c0 end_POSTSUBSCRIPT \u2190 ValidateByExecuting ( italic_p start_POSTSUBSCRIPT italic_\u03c0 end_POSTSUBSCRIPT , italic_i start_POSTSUBSCRIPT italic_\u03c0 end_POSTSUBSCRIPT , syntax,safety,determinism )then\u25b7\u25b7\\triangleright\u25b7see \u00a73.3.313:\ud835\udc9f\u03b1\u2190\ud835\udc9f\u03b1\u222a{(p\u03c0,i\u03c0,o\u03c0)}\u2190subscript\ud835\udc9f\ud835\udefcsubscript\ud835\udc9f\ud835\udefcsubscript\ud835\udc5d\ud835\udf0bsubscript\ud835\udc56\ud835\udf0bsubscript\ud835\udc5c\ud835\udf0b\\mathcal{D}_{\\alpha}\\leftarrow\\mathcal{D}_{\\alpha}\\cup\\bigl{\\{}(p_{\\pi},i_{\\pi%\n},o_{\\pi})\\bigr{\\}}caligraphic_D start_POSTSUBSCRIPT italic_\u03b1 end_POSTSUBSCRIPT \u2190 caligraphic_D start_POSTSUBSCRIPT italic_\u03b1 end_POSTSUBSCRIPT \u222a { ( italic_p start_POSTSUBSCRIPT italic_\u03c0 end_POSTSUBSCRIPT , italic_i start_POSTSUBSCRIPT italic_\u03c0 end_POSTSUBSCRIPT , italic_o start_POSTSUBSCRIPT italic_\u03c0 end_POSTSUBSCRIPT ) }\u25b7\u25b7\\triangleright\u25b7if valid, update deduction or abduction buffers14:for all\u03b1\u2208{ded,abd,ind}\ud835\udefcdedabdind\\alpha\\in\\{\\text{ded},\\text{abd},\\text{ind}\\}italic_\u03b1 \u2208 { ded , abd , ind }do\u25b7\u25b7\\triangleright\u25b7SOLVE PHASE15:(x,y\u22c6)\u2190SamplePrepareTasks\u2062(\ud835\udc9f\u03b1,B,t)\u2190\ud835\udc65superscript\ud835\udc66\u22c6SamplePrepareTaskssubscript\ud835\udc9f\ud835\udefc\ud835\udc35\ud835\udc61(x,y^{\\star})\\leftarrow\\textsc{SamplePrepareTasks}\\bigl{(}\\mathcal{D}_{\\alpha}%\n,B,t\\bigr{)}( italic_x , italic_y start_POSTSUPERSCRIPT \u22c6 end_POSTSUPERSCRIPT ) \u2190 SamplePrepareTasks ( caligraphic_D start_POSTSUBSCRIPT italic_\u03b1 end_POSTSUBSCRIPT , italic_B , italic_t )\u25b7\u25b7\\triangleright\u25b7x,y\u22c6\ud835\udc65superscript\ud835\udc66\u22c6x,y^{\\star}italic_x , italic_y start_POSTSUPERSCRIPT \u22c6 end_POSTSUPERSCRIPTprepared based on\u03b1\ud835\udefc\\alphaitalic_\u03b1, see \u00a73.3.3&3.3.416:y\u03c0\u223c\u03c0\u03b8solve\u2062(x)similar-tosubscript\ud835\udc66\ud835\udf0bsuperscriptsubscript\ud835\udf0b\ud835\udf03solve\ud835\udc65y_{\\pi}\\sim\\pi_{\\theta}^{\\text{solve}}(x)italic_y start_POSTSUBSCRIPT italic_\u03c0 end_POSTSUBSCRIPT \u223c italic_\u03c0 start_POSTSUBSCRIPT italic_\u03b8 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT solve end_POSTSUPERSCRIPT ( italic_x )17:Reward:Use proposed task triplets and solved answers to getrp\u2062r\u2062o\u2062p\u2062o\u2062s\u2062esubscript\ud835\udc5f\ud835\udc5d\ud835\udc5f\ud835\udc5c\ud835\udc5d\ud835\udc5c\ud835\udc60\ud835\udc52r_{propose}italic_r start_POSTSUBSCRIPT italic_p italic_r italic_o italic_p italic_o italic_s italic_e end_POSTSUBSCRIPT&rs\u2062o\u2062l\u2062v\u2062esubscript\ud835\udc5f\ud835\udc60\ud835\udc5c\ud835\udc59\ud835\udc63\ud835\udc52r_{solve}italic_r start_POSTSUBSCRIPT italic_s italic_o italic_l italic_v italic_e end_POSTSUBSCRIPT\u25b7\u25b7\\triangleright\u25b7see \u00a73.118:RL update:use Task Relative REINFORCE++ to update\u03c0\u03b8subscript\ud835\udf0b\ud835\udf03\\pi_{\\theta}italic_\u03c0 start_POSTSUBSCRIPT italic_\u03b8 end_POSTSUBSCRIPT\u25b7\u25b7\\triangleright\u25b7see \u00a73.3.5 3.3.3Constructing Valid TasksProposal Task Validation.We first describe how we construct valid tasks from the proposals generated by the policy\u03c0\ud835\udf0b\\piitalic_\u03c0. Fordeduction and abductiontasks, each proposal consists of a program and an input(p,i)\ud835\udc5d\ud835\udc56(p,i)( italic_p , italic_i ). To validate the task, we use the task validation procedure (steps shown below) on the input to obtain the correct outputo\ud835\udc5coitalic_o, resulting in a complete triplet(p,i,o)\ud835\udc5d\ud835\udc56\ud835\udc5c(p,i,o)( italic_p , italic_i , italic_o ). Forinductiontasks, given a programp\ud835\udc5dpitalic_pthe policy proposes a set of inputs{in}superscript\ud835\udc56\ud835\udc5b\\{i^{n}\\}{ italic_i start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT }and messagem\ud835\udc5amitalic_m. We also use the task validation procedure on each of the inputinsuperscript\ud835\udc56\ud835\udc5bi^{n}italic_i start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPTin the set to obtain a corresponding outputonsuperscript\ud835\udc5c\ud835\udc5bo^{n}italic_o start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT, forming a set of input-output pairs{in,on}superscript\ud835\udc56\ud835\udc5bsuperscript\ud835\udc5c\ud835\udc5b\\{i^{n},o^{n}\\}{ italic_i start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT , italic_o start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT }. We do not impose any constraints onm\ud835\udc5amitalic_m. The resulting task is considered valid only when all inputs yield valid outputs and the formatting requirements are satisfied. Thetask validation procedureentails:1.Program Integrity.We first use Python to run the programp\ud835\udc5dpitalic_pwith the inputi\ud835\udc56iitalic_i. If no errors are raised and something is returned, we then gather the outputo\ud835\udc5coitalic_oof that(p,i)\ud835\udc5d\ud835\udc56(p,i)( italic_p , italic_i )pair and determine that the program at least has valid syntax.2.Program Safety.We also check whether a program is safe for execution by restricting the use of certain sensitive packages that might cause harm to the Python environment,i.e.,os.sys, sys, shutil. The list of packages used to filter out invalid programs is provided inFigure8. This list is also included in the instructions when prompting the language model to generate questions. SeeFigures34,35and36.3.Check for Determinism.In our setting, we only considerdeterministic programs,i.e.,p\u2208\ud835\udcabdeterministic\u2282\ud835\udcab\ud835\udc5dsubscript\ud835\udcabdeterministic\ud835\udcabp\\in\\mathscr{P}_{\\text{deterministic}}\\subset\\mathscr{P}italic_p \u2208 script_P start_POSTSUBSCRIPT deterministic end_POSTSUBSCRIPT \u2282 script_P, where\ud835\udcab\ud835\udcab\\mathscr{P}script_Pis the space of all valid programs and\u2110\u2110\\mathscr{I}script_Iis the space of all valid inputs:\u2200p\u2208\ud835\udcabdeterministic,\u2200i\u2208\u2110,(limj\u2192\u221ep\u2062(i)(1)=p\u2062(i)(2)=\u22ef=p\u2062(i)(j)),formulae-sequencefor-all\ud835\udc5dsubscript\ud835\udcabdeterministicfor-all\ud835\udc56\u2110subscript\u2192\ud835\udc57\ud835\udc5dsuperscript\ud835\udc561\ud835\udc5dsuperscript\ud835\udc562\u22ef\ud835\udc5dsuperscript\ud835\udc56\ud835\udc57\\forall p\\in\\mathscr{P}_{\\text{deterministic}},\\ \\forall i\\in\\mathscr{I},\\ %\n\\left(\\lim_{j\\to\\infty}p(i)^{(1)}=p(i)^{(2)}=\\dots=p(i)^{(j)}\\right),\u2200 italic_p \u2208 script_P start_POSTSUBSCRIPT deterministic end_POSTSUBSCRIPT , \u2200 italic_i \u2208 script_I , ( roman_lim start_POSTSUBSCRIPT italic_j \u2192 \u221e end_POSTSUBSCRIPT italic_p ( italic_i ) start_POSTSUPERSCRIPT ( 1 ) end_POSTSUPERSCRIPT = italic_p ( italic_i ) start_POSTSUPERSCRIPT ( 2 ) end_POSTSUPERSCRIPT = \u22ef = italic_p ( italic_i ) start_POSTSUPERSCRIPT ( italic_j ) end_POSTSUPERSCRIPT ) ,(7)where(j)\ud835\udc57(j)( italic_j )indexes repeated independent executions of the program. That is, for all inputsi\ud835\udc56iitalic_i, the output ofp\u2062(i)\ud835\udc5d\ud835\udc56p(i)italic_p ( italic_i )remains identical with any independent execution of the program. Avalid program/input/output triplet(p,i,o)\ud835\udc5d\ud835\udc56\ud835\udc5c(p,i,o)( italic_p , italic_i , italic_o )is defined such thato=p\u2062(i)\ud835\udc5c\ud835\udc5d\ud835\udc56o=p(i)italic_o = italic_p ( italic_i ), wherep\u2208\ud835\udcabdeterministic\ud835\udc5dsubscript\ud835\udcabdeterministicp\\in\\mathscr{P}_{\\text{deterministic}}italic_p \u2208 script_P start_POSTSUBSCRIPT deterministic end_POSTSUBSCRIPT.Since the output of probabilistic programs can vary on every individual run, it is non-trivial to use verifiable functions to evaluate the correctness of an answer. Therefore, to keep the verifier simple, we restrict the valid programs generated by the learner to the class of deterministic programs. We believe that stochastic programs can encompass a larger class of behaviors and are important and promising to include in future versions of AZR.To implement the filtering of invalid probabilistic programs, and following the definition of a deterministic program highlighted inEquation7, we approximate this procedure by independently running the programj\ud835\udc57jitalic_jfinite times and checking that all the outputs are equal. For computational budget reasons, we fixedj=2\ud835\udc572j=2italic_j = 2for all experiments.Solving Task Construction.If a task proposal passes these three checks, we deem it a valid task and apply appropriate procedures to present part of the triplet to the solver. Specifically, we setx=(p,i)\ud835\udc65\ud835\udc5d\ud835\udc56x=(p,i)italic_x = ( italic_p , italic_i )for deduction;x=(p,o)\ud835\udc65\ud835\udc5d\ud835\udc5cx=(p,o)italic_x = ( italic_p , italic_o )for abduction; andx=({in,on}n=1N\u2063/\u2063/2,m)\ud835\udc65subscriptsuperscriptsuperscript\ud835\udc56\ud835\udc5bsuperscript\ud835\udc5c\ud835\udc5b\ud835\udc41absent2\ud835\udc5b1\ud835\udc5ax=(\\{i^{n},o^{n}\\}^{N//2}_{n=1},m)italic_x = ( { italic_i start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT , italic_o start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT } start_POSTSUPERSCRIPT italic_N / / 2 end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_n = 1 end_POSTSUBSCRIPT , italic_m )for induction, where half of the tests cases and a program descriptionm\ud835\udc5amitalic_mis used. We use all valid tasks from timestept\ud835\udc61titalic_t; if the batchB\ud835\udc35Bitalic_Bis not full, we uniformly sample from previously validated tasks to fill the batch. 3.3.4Answer VerificationFor abduction task, we receivei\u03c0subscript\ud835\udc56\ud835\udf0bi_{\\pi}italic_i start_POSTSUBSCRIPT italic_\u03c0 end_POSTSUBSCRIPTfrom the solver policy, then we equivalence match usingp\u2062(i\u03c0)=p\u2062(i\u22c6)\ud835\udc5dsubscript\ud835\udc56\ud835\udf0b\ud835\udc5dsuperscript\ud835\udc56\u22c6p(i_{\\pi})=p(i^{\\star})italic_p ( italic_i start_POSTSUBSCRIPT italic_\u03c0 end_POSTSUBSCRIPT ) = italic_p ( italic_i start_POSTSUPERSCRIPT \u22c6 end_POSTSUPERSCRIPT ), where\u2217*\u2217refers to the privileged gold information. The reason we do not just matchi\u03c0subscript\ud835\udc56\ud835\udf0bi_{\\pi}italic_i start_POSTSUBSCRIPT italic_\u03c0 end_POSTSUBSCRIPTandi\u22c6superscript\ud835\udc56\u22c6i^{\\star}italic_i start_POSTSUPERSCRIPT \u22c6 end_POSTSUPERSCRIPTis becausep\ud835\udc5dpitalic_pis not necessarily bijective. For deduction task, we matcho\u03c0=o\u22c6subscript\ud835\udc5c\ud835\udf0bsuperscript\ud835\udc5c\u22c6o_{\\pi}=o^{\\star}italic_o start_POSTSUBSCRIPT italic_\u03c0 end_POSTSUBSCRIPT = italic_o start_POSTSUPERSCRIPT \u22c6 end_POSTSUPERSCRIPT. For induction, we matchall\u2061({p\u03c0\u2062(in\u22c6)=on\u22c6}N)allsuperscriptsubscript\ud835\udc5d\ud835\udf0bsuperscriptsubscript\ud835\udc56\ud835\udc5b\u22c6superscriptsubscript\ud835\udc5c\ud835\udc5b\u22c6\ud835\udc41\\operatorname{all}(\\{p_{\\pi}(i_{n}^{\\star})=o_{n}^{\\star}\\}^{N})roman_all ( { italic_p start_POSTSUBSCRIPT italic_\u03c0 end_POSTSUBSCRIPT ( italic_i start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT start_POSTSUPERSCRIPT \u22c6 end_POSTSUPERSCRIPT ) = italic_o start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT start_POSTSUPERSCRIPT \u22c6 end_POSTSUPERSCRIPT } start_POSTSUPERSCRIPT italic_N end_POSTSUPERSCRIPT ). This part might be convoluted to explain in language, therefore we recommend the reader to see how we did abduction, deduction and induction verification in code inFigures10,11and12, respectively. 3.3.5Task-Relative REINFORCE++Since AZR trains the combination of roles and task types, it operates in a multitask reinforcement learning setup(Zhang & Yang,2021;Zhao et\u00a0al.,2022;Wang et\u00a0al.,2023;Yue et\u00a0al.,2023). Instead of computing a single global baseline as in REINFORCE++(Hu,2025)(AppendixA), we compute separate baselines for each of the six task-role configurations. This can be viewed as an interpolation between per-question baselines, as in GRPO(Shao et\u00a0al.,2024), and a global baseline, allowing for more structured variance reduction tailored to each task setup. We refer to this variant asTask-Relative REINFORCE++ (TRR++). The normalized advantageAnormsuperscript\ud835\udc34normA^{\\text{norm}}italic_A start_POSTSUPERSCRIPT norm end_POSTSUPERSCRIPTis computed as:Atask,rolenorm=r\u2212\u03bctask,role\u03c3task,role,task\u2208{ind,ded,abd},role\u2208{propose,solve},formulae-sequencesubscriptsuperscript\ud835\udc34normtask,role\ud835\udc5fsubscript\ud835\udf07task,rolesubscript\ud835\udf0etask,roleformulae-sequencetaskind,ded,abdrolepropose,solveA^{\\text{norm}}_{\\text{task,role}}=\\frac{r-\\mu_{\\text{task,role}}}{\\sigma_{%\n\\text{task,role}}},\\quad\\text{task}\\in\\{\\text{ind,ded,abd}\\},\\text{role}\\in\\{%\n\\text{propose,solve}\\},italic_A start_POSTSUPERSCRIPT norm end_POSTSUPERSCRIPT start_POSTSUBSCRIPT task,role end_POSTSUBSCRIPT = divide start_ARG italic_r - italic_\u03bc start_POSTSUBSCRIPT task,role end_POSTSUBSCRIPT end_ARG start_ARG italic_\u03c3 start_POSTSUBSCRIPT task,role end_POSTSUBSCRIPT end_ARG , task \u2208 { ind,ded,abd } , role \u2208 { propose,solve } ,(8)where the mean and standard deviation are computedwithin each task type and role, yielding six baselines.",
        "parent": "sec_1a5d9820"
      },
      {
        "_key": "sec_4af9d86a",
        "_id": "sections/sec_4af9d86a",
        "title": "3.3.1Buffer Initialization",
        "level": 4,
        "content": "To initialize AZR self-play, we first generate a seed set of valid triplets using the base language model. Each prompt samples up toK\ud835\udc3eKitalic_Ktriplets from the current seed buffer\ud835\udc9fseedsubscript\ud835\udc9fseed\\mathcal{D}_{\\text{seed}}caligraphic_D start_POSTSUBSCRIPT seed end_POSTSUBSCRIPTas references. When\ud835\udc9fseedsubscript\ud835\udc9fseed\\mathcal{D}_{\\text{seed}}caligraphic_D start_POSTSUBSCRIPT seed end_POSTSUBSCRIPTis empty at time 0, we fall back to the zero triplet show inFigure5. During the seeding stage, we use the same proposer prompts detailed inFigures34,35and36. First, for deduction and abduction tasks, the LLM is prompted to generate(p,i)\ud835\udc5d\ud835\udc56(p,i)( italic_p , italic_i )pairs, which are filtered, executed, and stored as valid triplets. We initialize\ud835\udc9fabduction0=\ud835\udc9fdeduction0=\ud835\udc9fseedsubscriptsuperscript\ud835\udc9f0abductionsubscriptsuperscript\ud835\udc9f0deductionsubscript\ud835\udc9fseed\\mathcal{D}^{0}_{\\text{abduction}}=\\mathcal{D}^{0}_{\\text{deduction}}=\\mathcal%\n{D}_{\\text{seed}}caligraphic_D start_POSTSUPERSCRIPT 0 end_POSTSUPERSCRIPT start_POSTSUBSCRIPT abduction end_POSTSUBSCRIPT = caligraphic_D start_POSTSUPERSCRIPT 0 end_POSTSUPERSCRIPT start_POSTSUBSCRIPT deduction end_POSTSUBSCRIPT = caligraphic_D start_POSTSUBSCRIPT seed end_POSTSUBSCRIPT, where|\ud835\udc9fseed|=B\u00d7Ssubscript\ud835\udc9fseed\ud835\udc35\ud835\udc46|\\mathcal{D}_{\\text{seed}}|=B\\times S| caligraphic_D start_POSTSUBSCRIPT seed end_POSTSUBSCRIPT | = italic_B \u00d7 italic_S, whereB\ud835\udc35Bitalic_Bis the batch size, andS=4\ud835\udc464S=4italic_S = 4is a factor we fix in all experiments. All seed triplet\u2019s program are stripped of global variables and comments (AppendixD), but subsequent iterations of adding new triplets to the buffers are unaltered. No model updates occur during this phase. Similarly, to initialize the induction buffer, we sample programs from\ud835\udc9fseedsubscript\ud835\udc9fseed\\mathcal{D}_{\\text{seed}}caligraphic_D start_POSTSUBSCRIPT seed end_POSTSUBSCRIPT, generate matching input sets and messages, and collect valid examples until|\ud835\udc9finduction0|=B\u00d7Ssubscriptsuperscript\ud835\udc9f0induction\ud835\udc35\ud835\udc46|\\mathcal{D}^{0}_{\\text{induction}}|=B\\times S| caligraphic_D start_POSTSUPERSCRIPT 0 end_POSTSUPERSCRIPT start_POSTSUBSCRIPT induction end_POSTSUBSCRIPT | = italic_B \u00d7 italic_S.",
        "parent": "sec_3d319639"
      },
      {
        "_key": "sec_1020a1e3",
        "_id": "sections/sec_1020a1e3",
        "title": "3.3.2Task Proposal Inputs and Buffer Management",
        "level": 4,
        "content": "During the actual self-play stage of AZR, we use the task buffer in three ways.First, for the proposer of abduction and deduction tasks, we uniformly sampleK\ud835\udc3eKitalic_Kpast triplets from the buffer, present them as in-context examples to the proposer and let it generate a new task. The design is to show it past examples, and prompt it to generate a different one to promote diversity(Zhao et\u00a0al.,2025a).Second, we sample one triplet from the union of abduction and deduction buffers\ud835\udc9fabd\u2062\u22c3\ud835\udc9fdedsubscript\ud835\udc9fabdsubscript\ud835\udc9fded\\mathcal{D}_{\\text{abd}}\\bigcup\\mathcal{D}_{\\text{ded}}caligraphic_D start_POSTSUBSCRIPT abd end_POSTSUBSCRIPT \u22c3 caligraphic_D start_POSTSUBSCRIPT ded end_POSTSUBSCRIPT, and present the programp\ud835\udc5dpitalic_pfrom that triplet to the induction proposer to generate a set ofN\ud835\udc41Nitalic_Nmatching inputs{in}superscript\ud835\udc56\ud835\udc5b\\{i^{n}\\}{ italic_i start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT }and a natural language messagem\ud835\udc5amitalic_m.Lastly, to maintain stable training, if a batch of solver problems contains fewer thanB\ud835\udc35Bitalic_Bvalid proposed tasks (proposer not adhering to formatting), we fill the remainder by uniformly sampling from the corresponding task buffer of previously validated triplets. The buffer grows for abduction and deduction tasks whenever\u03c0\ud835\udf0b\\piitalic_\u03c0propose a valid triplet(p,i,o)\ud835\udc5d\ud835\udc56\ud835\udc5c(p,i,o)( italic_p , italic_i , italic_o ), regardless if it gets any task reward. Similarly, for induction tasks, all valid triplets(p,{in,on}),m\ud835\udc5dsuperscript\ud835\udc56\ud835\udc5bsuperscript\ud835\udc5c\ud835\udc5b\ud835\udc5a(p,\\{i^{n},o^{n}\\}),m( italic_p , { italic_i start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT , italic_o start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT } ) , italic_mare added to the buffer. Algorithm 1Self-Play Training of Absolute Zero Reasoner (AZR)1:Pretrained base LLM\u03c0\u03b8subscript\ud835\udf0b\ud835\udf03\\pi_{\\theta}italic_\u03c0 start_POSTSUBSCRIPT italic_\u03b8 end_POSTSUBSCRIPT; batch sizeB\ud835\udc35Bitalic_B; #referencesK\ud835\udc3eKitalic_K; iterationsT\ud835\udc47Titalic_T2:\ud835\udc9fded,\ud835\udc9fabd,\ud835\udc9find\u2190InitSeeding\u2062(\u03c0\u03b8)\u2190subscript\ud835\udc9fdedsubscript\ud835\udc9fabdsubscript\ud835\udc9findInitSeedingsubscript\ud835\udf0b\ud835\udf03\\mathcal{D}_{\\text{ded}},\\mathcal{D}_{\\text{abd}},\\mathcal{D}_{\\text{ind}}%\n\\leftarrow\\textsc{InitSeeding}(\\pi_{\\theta})caligraphic_D start_POSTSUBSCRIPT ded end_POSTSUBSCRIPT , caligraphic_D start_POSTSUBSCRIPT abd end_POSTSUBSCRIPT , caligraphic_D start_POSTSUBSCRIPT ind end_POSTSUBSCRIPT \u2190 InitSeeding ( italic_\u03c0 start_POSTSUBSCRIPT italic_\u03b8 end_POSTSUBSCRIPT )\u25b7\u25b7\\triangleright\u25b7see \u00a73.3.13:fort\u21901\u2190\ud835\udc611t\\leftarrow 1italic_t \u2190 1toT\ud835\udc47Titalic_Tdo4:forb\u21901\u2190\ud835\udc4f1b\\leftarrow 1italic_b \u2190 1toB\ud835\udc35Bitalic_Bdo\u25b7\u25b7\\triangleright\u25b7PROPOSE PHASE5:p\u223c\ud835\udc9fabd\u222a\ud835\udc9fdedsimilar-to\ud835\udc5dsubscript\ud835\udc9fabdsubscript\ud835\udc9fdedp\\sim\\mathcal{D}_{\\text{abd}}\\cup\\mathcal{D}_{\\text{ded}}italic_p \u223c caligraphic_D start_POSTSUBSCRIPT abd end_POSTSUBSCRIPT \u222a caligraphic_D start_POSTSUBSCRIPT ded end_POSTSUBSCRIPT\u25b7\u25b7\\triangleright\u25b7sample a program for induction task proposal6:{i\u03c0n}n=1N,m\u03c0\u2190\u03c0\u03b8propose\u2062(ind,p)\u2190superscriptsubscriptsubscriptsuperscript\ud835\udc56\ud835\udc5b\ud835\udf0b\ud835\udc5b1\ud835\udc41subscript\ud835\udc5a\ud835\udf0bsuperscriptsubscript\ud835\udf0b\ud835\udf03proposeind\ud835\udc5d\\bigl{\\{}i^{n}_{\\pi}\\bigr{\\}}_{n=1}^{N},\\;m_{\\pi}\\leftarrow\\pi_{\\theta}^{\\text%\n{propose}}(\\text{ind},p){ italic_i start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_\u03c0 end_POSTSUBSCRIPT } start_POSTSUBSCRIPT italic_n = 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_N end_POSTSUPERSCRIPT , italic_m start_POSTSUBSCRIPT italic_\u03c0 end_POSTSUBSCRIPT \u2190 italic_\u03c0 start_POSTSUBSCRIPT italic_\u03b8 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT propose end_POSTSUPERSCRIPT ( ind , italic_p )\u25b7\u25b7\\triangleright\u25b7generateN\ud835\udc41Nitalic_Ninputs and a description7:if{(i\u03c0n,o\u03c0n)}n=1N\u2190ValidateByExecuting\u2062(p,{i\u03c0n},syntax)\u2190superscriptsubscriptsubscriptsuperscript\ud835\udc56\ud835\udc5b\ud835\udf0bsubscriptsuperscript\ud835\udc5c\ud835\udc5b\ud835\udf0b\ud835\udc5b1\ud835\udc41ValidateByExecuting\ud835\udc5dsubscriptsuperscript\ud835\udc56\ud835\udc5b\ud835\udf0bsyntax\\bigl{\\{}(i^{n}_{\\pi},o^{n}_{\\pi})\\bigr{\\}}_{n=1}^{N}\\leftarrow\\textsc{%\nValidateByExecuting}\\bigl{(}p,\\{i^{n}_{\\pi}\\},\\textsc{syntax}\\bigr{)}{ ( italic_i start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_\u03c0 end_POSTSUBSCRIPT , italic_o start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_\u03c0 end_POSTSUBSCRIPT ) } start_POSTSUBSCRIPT italic_n = 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_N end_POSTSUPERSCRIPT \u2190 ValidateByExecuting ( italic_p , { italic_i start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_\u03c0 end_POSTSUBSCRIPT } , syntax )then\u25b7\u25b7\\triangleright\u25b7validate I/Os, see \u00a73.3.38:\ud835\udc9find\u2190\ud835\udc9find\u222a{(p,{(i\u03c0n,o\u03c0n)},m\u03c0)}\u2190subscript\ud835\udc9findsubscript\ud835\udc9find\ud835\udc5dsubscriptsuperscript\ud835\udc56\ud835\udc5b\ud835\udf0bsubscriptsuperscript\ud835\udc5c\ud835\udc5b\ud835\udf0bsubscript\ud835\udc5a\ud835\udf0b\\mathcal{D}_{\\text{ind}}\\leftarrow\\mathcal{D}_{\\text{ind}}\\cup\\bigl{\\{}(p,\\{(i%\n^{n}_{\\pi},o^{n}_{\\pi})\\},m_{\\pi})\\bigr{\\}}caligraphic_D start_POSTSUBSCRIPT ind end_POSTSUBSCRIPT \u2190 caligraphic_D start_POSTSUBSCRIPT ind end_POSTSUBSCRIPT \u222a { ( italic_p , { ( italic_i start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_\u03c0 end_POSTSUBSCRIPT , italic_o start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_\u03c0 end_POSTSUBSCRIPT ) } , italic_m start_POSTSUBSCRIPT italic_\u03c0 end_POSTSUBSCRIPT ) }\u25b7\u25b7\\triangleright\u25b7update induction buffer9:for\u03b1\u2208{ded,abd}\ud835\udefcdedabd\\alpha\\in\\{\\text{ded},\\text{abd}\\}italic_\u03b1 \u2208 { ded , abd }do10:(pk,ik,ok)k=1K\u223c\ud835\udc9f\u03b1similar-tosuperscriptsubscriptsubscript\ud835\udc5d\ud835\udc58subscript\ud835\udc56\ud835\udc58subscript\ud835\udc5c\ud835\udc58\ud835\udc581\ud835\udc3esubscript\ud835\udc9f\ud835\udefc\\bigl{(}p_{k},i_{k},o_{k}\\bigr{)}_{k=1}^{K}\\sim\\mathcal{D}_{\\alpha}( italic_p start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT , italic_i start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT , italic_o start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT ) start_POSTSUBSCRIPT italic_k = 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_K end_POSTSUPERSCRIPT \u223c caligraphic_D start_POSTSUBSCRIPT italic_\u03b1 end_POSTSUBSCRIPT\u25b7\u25b7\\triangleright\u25b7sampleK\ud835\udc3eKitalic_Kreference examples11:(p\u03c0,i\u03c0)\u2190\u03c0\u03b8propose\u2062(\u03b1,{(pk,ik,ok)})\u2190subscript\ud835\udc5d\ud835\udf0bsubscript\ud835\udc56\ud835\udf0bsuperscriptsubscript\ud835\udf0b\ud835\udf03propose\ud835\udefcsubscript\ud835\udc5d\ud835\udc58subscript\ud835\udc56\ud835\udc58subscript\ud835\udc5c\ud835\udc58(p_{\\pi},i_{\\pi})\\leftarrow\\pi_{\\theta}^{\\text{propose}}\\!\\bigl{(}\\alpha,\\{(p_%\n{k},i_{k},o_{k})\\}\\bigr{)}( italic_p start_POSTSUBSCRIPT italic_\u03c0 end_POSTSUBSCRIPT , italic_i start_POSTSUBSCRIPT italic_\u03c0 end_POSTSUBSCRIPT ) \u2190 italic_\u03c0 start_POSTSUBSCRIPT italic_\u03b8 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT propose end_POSTSUPERSCRIPT ( italic_\u03b1 , { ( italic_p start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT , italic_i start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT , italic_o start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT ) } )\u25b7\u25b7\\triangleright\u25b7propose new task12:ifo\u03c0\u2190ValidateByExecuting\u2062(p\u03c0,i\u03c0,syntax,safety,determinism)\u2190subscript\ud835\udc5c\ud835\udf0bValidateByExecutingsubscript\ud835\udc5d\ud835\udf0bsubscript\ud835\udc56\ud835\udf0bsyntax,safety,determinismo_{\\pi}\\leftarrow\\textsc{ValidateByExecuting}\\bigl{(}p_{\\pi},i_{\\pi},\\textsc{%\nsyntax,safety,determinism}\\bigr{)}italic_o start_POSTSUBSCRIPT italic_\u03c0 end_POSTSUBSCRIPT \u2190 ValidateByExecuting ( italic_p start_POSTSUBSCRIPT italic_\u03c0 end_POSTSUBSCRIPT , italic_i start_POSTSUBSCRIPT italic_\u03c0 end_POSTSUBSCRIPT , syntax,safety,determinism )then\u25b7\u25b7\\triangleright\u25b7see \u00a73.3.313:\ud835\udc9f\u03b1\u2190\ud835\udc9f\u03b1\u222a{(p\u03c0,i\u03c0,o\u03c0)}\u2190subscript\ud835\udc9f\ud835\udefcsubscript\ud835\udc9f\ud835\udefcsubscript\ud835\udc5d\ud835\udf0bsubscript\ud835\udc56\ud835\udf0bsubscript\ud835\udc5c\ud835\udf0b\\mathcal{D}_{\\alpha}\\leftarrow\\mathcal{D}_{\\alpha}\\cup\\bigl{\\{}(p_{\\pi},i_{\\pi%\n},o_{\\pi})\\bigr{\\}}caligraphic_D start_POSTSUBSCRIPT italic_\u03b1 end_POSTSUBSCRIPT \u2190 caligraphic_D start_POSTSUBSCRIPT italic_\u03b1 end_POSTSUBSCRIPT \u222a { ( italic_p start_POSTSUBSCRIPT italic_\u03c0 end_POSTSUBSCRIPT , italic_i start_POSTSUBSCRIPT italic_\u03c0 end_POSTSUBSCRIPT , italic_o start_POSTSUBSCRIPT italic_\u03c0 end_POSTSUBSCRIPT ) }\u25b7\u25b7\\triangleright\u25b7if valid, update deduction or abduction buffers14:for all\u03b1\u2208{ded,abd,ind}\ud835\udefcdedabdind\\alpha\\in\\{\\text{ded},\\text{abd},\\text{ind}\\}italic_\u03b1 \u2208 { ded , abd , ind }do\u25b7\u25b7\\triangleright\u25b7SOLVE PHASE15:(x,y\u22c6)\u2190SamplePrepareTasks\u2062(\ud835\udc9f\u03b1,B,t)\u2190\ud835\udc65superscript\ud835\udc66\u22c6SamplePrepareTaskssubscript\ud835\udc9f\ud835\udefc\ud835\udc35\ud835\udc61(x,y^{\\star})\\leftarrow\\textsc{SamplePrepareTasks}\\bigl{(}\\mathcal{D}_{\\alpha}%\n,B,t\\bigr{)}( italic_x , italic_y start_POSTSUPERSCRIPT \u22c6 end_POSTSUPERSCRIPT ) \u2190 SamplePrepareTasks ( caligraphic_D start_POSTSUBSCRIPT italic_\u03b1 end_POSTSUBSCRIPT , italic_B , italic_t )\u25b7\u25b7\\triangleright\u25b7x,y\u22c6\ud835\udc65superscript\ud835\udc66\u22c6x,y^{\\star}italic_x , italic_y start_POSTSUPERSCRIPT \u22c6 end_POSTSUPERSCRIPTprepared based on\u03b1\ud835\udefc\\alphaitalic_\u03b1, see \u00a73.3.3&3.3.416:y\u03c0\u223c\u03c0\u03b8solve\u2062(x)similar-tosubscript\ud835\udc66\ud835\udf0bsuperscriptsubscript\ud835\udf0b\ud835\udf03solve\ud835\udc65y_{\\pi}\\sim\\pi_{\\theta}^{\\text{solve}}(x)italic_y start_POSTSUBSCRIPT italic_\u03c0 end_POSTSUBSCRIPT \u223c italic_\u03c0 start_POSTSUBSCRIPT italic_\u03b8 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT solve end_POSTSUPERSCRIPT ( italic_x )17:Reward:Use proposed task triplets and solved answers to getrp\u2062r\u2062o\u2062p\u2062o\u2062s\u2062esubscript\ud835\udc5f\ud835\udc5d\ud835\udc5f\ud835\udc5c\ud835\udc5d\ud835\udc5c\ud835\udc60\ud835\udc52r_{propose}italic_r start_POSTSUBSCRIPT italic_p italic_r italic_o italic_p italic_o italic_s italic_e end_POSTSUBSCRIPT&rs\u2062o\u2062l\u2062v\u2062esubscript\ud835\udc5f\ud835\udc60\ud835\udc5c\ud835\udc59\ud835\udc63\ud835\udc52r_{solve}italic_r start_POSTSUBSCRIPT italic_s italic_o italic_l italic_v italic_e end_POSTSUBSCRIPT\u25b7\u25b7\\triangleright\u25b7see \u00a73.118:RL update:use Task Relative REINFORCE++ to update\u03c0\u03b8subscript\ud835\udf0b\ud835\udf03\\pi_{\\theta}italic_\u03c0 start_POSTSUBSCRIPT italic_\u03b8 end_POSTSUBSCRIPT\u25b7\u25b7\\triangleright\u25b7see \u00a73.3.5",
        "parent": "sec_3d319639"
      },
      {
        "_key": "sec_ff7baeac",
        "_id": "sections/sec_ff7baeac",
        "title": "3.3.3Constructing Valid Tasks",
        "level": 4,
        "content": "Proposal Task Validation.We first describe how we construct valid tasks from the proposals generated by the policy\u03c0\ud835\udf0b\\piitalic_\u03c0. Fordeduction and abductiontasks, each proposal consists of a program and an input(p,i)\ud835\udc5d\ud835\udc56(p,i)( italic_p , italic_i ). To validate the task, we use the task validation procedure (steps shown below) on the input to obtain the correct outputo\ud835\udc5coitalic_o, resulting in a complete triplet(p,i,o)\ud835\udc5d\ud835\udc56\ud835\udc5c(p,i,o)( italic_p , italic_i , italic_o ). Forinductiontasks, given a programp\ud835\udc5dpitalic_pthe policy proposes a set of inputs{in}superscript\ud835\udc56\ud835\udc5b\\{i^{n}\\}{ italic_i start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT }and messagem\ud835\udc5amitalic_m. We also use the task validation procedure on each of the inputinsuperscript\ud835\udc56\ud835\udc5bi^{n}italic_i start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPTin the set to obtain a corresponding outputonsuperscript\ud835\udc5c\ud835\udc5bo^{n}italic_o start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT, forming a set of input-output pairs{in,on}superscript\ud835\udc56\ud835\udc5bsuperscript\ud835\udc5c\ud835\udc5b\\{i^{n},o^{n}\\}{ italic_i start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT , italic_o start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT }. We do not impose any constraints onm\ud835\udc5amitalic_m. The resulting task is considered valid only when all inputs yield valid outputs and the formatting requirements are satisfied. Thetask validation procedureentails: 1.Program Integrity.We first use Python to run the programp\ud835\udc5dpitalic_pwith the inputi\ud835\udc56iitalic_i. If no errors are raised and something is returned, we then gather the outputo\ud835\udc5coitalic_oof that(p,i)\ud835\udc5d\ud835\udc56(p,i)( italic_p , italic_i )pair and determine that the program at least has valid syntax.2.Program Safety.We also check whether a program is safe for execution by restricting the use of certain sensitive packages that might cause harm to the Python environment,i.e.,os.sys, sys, shutil. The list of packages used to filter out invalid programs is provided inFigure8. This list is also included in the instructions when prompting the language model to generate questions. SeeFigures34,35and36.3.Check for Determinism.In our setting, we only considerdeterministic programs,i.e.,p\u2208\ud835\udcabdeterministic\u2282\ud835\udcab\ud835\udc5dsubscript\ud835\udcabdeterministic\ud835\udcabp\\in\\mathscr{P}_{\\text{deterministic}}\\subset\\mathscr{P}italic_p \u2208 script_P start_POSTSUBSCRIPT deterministic end_POSTSUBSCRIPT \u2282 script_P, where\ud835\udcab\ud835\udcab\\mathscr{P}script_Pis the space of all valid programs and\u2110\u2110\\mathscr{I}script_Iis the space of all valid inputs:\u2200p\u2208\ud835\udcabdeterministic,\u2200i\u2208\u2110,(limj\u2192\u221ep\u2062(i)(1)=p\u2062(i)(2)=\u22ef=p\u2062(i)(j)),formulae-sequencefor-all\ud835\udc5dsubscript\ud835\udcabdeterministicfor-all\ud835\udc56\u2110subscript\u2192\ud835\udc57\ud835\udc5dsuperscript\ud835\udc561\ud835\udc5dsuperscript\ud835\udc562\u22ef\ud835\udc5dsuperscript\ud835\udc56\ud835\udc57\\forall p\\in\\mathscr{P}_{\\text{deterministic}},\\ \\forall i\\in\\mathscr{I},\\ %\n\\left(\\lim_{j\\to\\infty}p(i)^{(1)}=p(i)^{(2)}=\\dots=p(i)^{(j)}\\right),\u2200 italic_p \u2208 script_P start_POSTSUBSCRIPT deterministic end_POSTSUBSCRIPT , \u2200 italic_i \u2208 script_I , ( roman_lim start_POSTSUBSCRIPT italic_j \u2192 \u221e end_POSTSUBSCRIPT italic_p ( italic_i ) start_POSTSUPERSCRIPT ( 1 ) end_POSTSUPERSCRIPT = italic_p ( italic_i ) start_POSTSUPERSCRIPT ( 2 ) end_POSTSUPERSCRIPT = \u22ef = italic_p ( italic_i ) start_POSTSUPERSCRIPT ( italic_j ) end_POSTSUPERSCRIPT ) ,(7)where(j)\ud835\udc57(j)( italic_j )indexes repeated independent executions of the program. That is, for all inputsi\ud835\udc56iitalic_i, the output ofp\u2062(i)\ud835\udc5d\ud835\udc56p(i)italic_p ( italic_i )remains identical with any independent execution of the program. Avalid program/input/output triplet(p,i,o)\ud835\udc5d\ud835\udc56\ud835\udc5c(p,i,o)( italic_p , italic_i , italic_o )is defined such thato=p\u2062(i)\ud835\udc5c\ud835\udc5d\ud835\udc56o=p(i)italic_o = italic_p ( italic_i ), wherep\u2208\ud835\udcabdeterministic\ud835\udc5dsubscript\ud835\udcabdeterministicp\\in\\mathscr{P}_{\\text{deterministic}}italic_p \u2208 script_P start_POSTSUBSCRIPT deterministic end_POSTSUBSCRIPT.Since the output of probabilistic programs can vary on every individual run, it is non-trivial to use verifiable functions to evaluate the correctness of an answer. Therefore, to keep the verifier simple, we restrict the valid programs generated by the learner to the class of deterministic programs. We believe that stochastic programs can encompass a larger class of behaviors and are important and promising to include in future versions of AZR.To implement the filtering of invalid probabilistic programs, and following the definition of a deterministic program highlighted inEquation7, we approximate this procedure by independently running the programj\ud835\udc57jitalic_jfinite times and checking that all the outputs are equal. For computational budget reasons, we fixedj=2\ud835\udc572j=2italic_j = 2for all experiments. Solving Task Construction.If a task proposal passes these three checks, we deem it a valid task and apply appropriate procedures to present part of the triplet to the solver. Specifically, we setx=(p,i)\ud835\udc65\ud835\udc5d\ud835\udc56x=(p,i)italic_x = ( italic_p , italic_i )for deduction;x=(p,o)\ud835\udc65\ud835\udc5d\ud835\udc5cx=(p,o)italic_x = ( italic_p , italic_o )for abduction; andx=({in,on}n=1N\u2063/\u2063/2,m)\ud835\udc65subscriptsuperscriptsuperscript\ud835\udc56\ud835\udc5bsuperscript\ud835\udc5c\ud835\udc5b\ud835\udc41absent2\ud835\udc5b1\ud835\udc5ax=(\\{i^{n},o^{n}\\}^{N//2}_{n=1},m)italic_x = ( { italic_i start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT , italic_o start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT } start_POSTSUPERSCRIPT italic_N / / 2 end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_n = 1 end_POSTSUBSCRIPT , italic_m )for induction, where half of the tests cases and a program descriptionm\ud835\udc5amitalic_mis used. We use all valid tasks from timestept\ud835\udc61titalic_t; if the batchB\ud835\udc35Bitalic_Bis not full, we uniformly sample from previously validated tasks to fill the batch.",
        "parent": "sec_3d319639"
      },
      {
        "_key": "sec_bc334225",
        "_id": "sections/sec_bc334225",
        "title": "3.3.4Answer Verification",
        "level": 4,
        "content": "For abduction task, we receivei\u03c0subscript\ud835\udc56\ud835\udf0bi_{\\pi}italic_i start_POSTSUBSCRIPT italic_\u03c0 end_POSTSUBSCRIPTfrom the solver policy, then we equivalence match usingp\u2062(i\u03c0)=p\u2062(i\u22c6)\ud835\udc5dsubscript\ud835\udc56\ud835\udf0b\ud835\udc5dsuperscript\ud835\udc56\u22c6p(i_{\\pi})=p(i^{\\star})italic_p ( italic_i start_POSTSUBSCRIPT italic_\u03c0 end_POSTSUBSCRIPT ) = italic_p ( italic_i start_POSTSUPERSCRIPT \u22c6 end_POSTSUPERSCRIPT ), where\u2217*\u2217refers to the privileged gold information. The reason we do not just matchi\u03c0subscript\ud835\udc56\ud835\udf0bi_{\\pi}italic_i start_POSTSUBSCRIPT italic_\u03c0 end_POSTSUBSCRIPTandi\u22c6superscript\ud835\udc56\u22c6i^{\\star}italic_i start_POSTSUPERSCRIPT \u22c6 end_POSTSUPERSCRIPTis becausep\ud835\udc5dpitalic_pis not necessarily bijective. For deduction task, we matcho\u03c0=o\u22c6subscript\ud835\udc5c\ud835\udf0bsuperscript\ud835\udc5c\u22c6o_{\\pi}=o^{\\star}italic_o start_POSTSUBSCRIPT italic_\u03c0 end_POSTSUBSCRIPT = italic_o start_POSTSUPERSCRIPT \u22c6 end_POSTSUPERSCRIPT. For induction, we matchall\u2061({p\u03c0\u2062(in\u22c6)=on\u22c6}N)allsuperscriptsubscript\ud835\udc5d\ud835\udf0bsuperscriptsubscript\ud835\udc56\ud835\udc5b\u22c6superscriptsubscript\ud835\udc5c\ud835\udc5b\u22c6\ud835\udc41\\operatorname{all}(\\{p_{\\pi}(i_{n}^{\\star})=o_{n}^{\\star}\\}^{N})roman_all ( { italic_p start_POSTSUBSCRIPT italic_\u03c0 end_POSTSUBSCRIPT ( italic_i start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT start_POSTSUPERSCRIPT \u22c6 end_POSTSUPERSCRIPT ) = italic_o start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT start_POSTSUPERSCRIPT \u22c6 end_POSTSUPERSCRIPT } start_POSTSUPERSCRIPT italic_N end_POSTSUPERSCRIPT ). This part might be convoluted to explain in language, therefore we recommend the reader to see how we did abduction, deduction and induction verification in code inFigures10,11and12, respectively.",
        "parent": "sec_3d319639"
      },
      {
        "_key": "sec_730b34d8",
        "_id": "sections/sec_730b34d8",
        "title": "3.3.5Task-Relative REINFORCE++",
        "level": 4,
        "content": "Since AZR trains the combination of roles and task types, it operates in a multitask reinforcement learning setup(Zhang & Yang,2021;Zhao et\u00a0al.,2022;Wang et\u00a0al.,2023;Yue et\u00a0al.,2023). Instead of computing a single global baseline as in REINFORCE++(Hu,2025)(AppendixA), we compute separate baselines for each of the six task-role configurations. This can be viewed as an interpolation between per-question baselines, as in GRPO(Shao et\u00a0al.,2024), and a global baseline, allowing for more structured variance reduction tailored to each task setup. We refer to this variant asTask-Relative REINFORCE++ (TRR++). The normalized advantageAnormsuperscript\ud835\udc34normA^{\\text{norm}}italic_A start_POSTSUPERSCRIPT norm end_POSTSUPERSCRIPTis computed as:Atask,rolenorm=r\u2212\u03bctask,role\u03c3task,role,task\u2208{ind,ded,abd},role\u2208{propose,solve},formulae-sequencesubscriptsuperscript\ud835\udc34normtask,role\ud835\udc5fsubscript\ud835\udf07task,rolesubscript\ud835\udf0etask,roleformulae-sequencetaskind,ded,abdrolepropose,solveA^{\\text{norm}}_{\\text{task,role}}=\\frac{r-\\mu_{\\text{task,role}}}{\\sigma_{%\n\\text{task,role}}},\\quad\\text{task}\\in\\{\\text{ind,ded,abd}\\},\\text{role}\\in\\{%\n\\text{propose,solve}\\},italic_A start_POSTSUPERSCRIPT norm end_POSTSUPERSCRIPT start_POSTSUBSCRIPT task,role end_POSTSUBSCRIPT = divide start_ARG italic_r - italic_\u03bc start_POSTSUBSCRIPT task,role end_POSTSUBSCRIPT end_ARG start_ARG italic_\u03c3 start_POSTSUBSCRIPT task,role end_POSTSUBSCRIPT end_ARG , task \u2208 { ind,ded,abd } , role \u2208 { propose,solve } ,(8)where the mean and standard deviation are computedwithin each task type and role, yielding six baselines.",
        "parent": "sec_3d319639"
      },
      {
        "_key": "sec_5c55d4bc",
        "_id": "sections/sec_5c55d4bc",
        "title": "4Experiments",
        "level": 2,
        "content": "4.1Experiment SetupTraining Details.For all experiments, we initialize the buffers as described inSection3.1. AZR models are trained using a batch size of64\u00d7664664\\times 664 \u00d7 6(2 roles\u00d7\\times\u00d73 task types). We use constant learning rate=1\u2062e\u22126absent1\ud835\udc526=1e{-6}= 1 italic_e - 6and the AdamW optimizer(Loshchilov & Hutter,2019). Complete list of hyperparameters is provided inTable3.For the main experiments, we train AZR models onQwen2.5-7BandQwen2.5-7B-Coder, resulting inAbsolute Zero Reasoner-base-7BandAbsolute Zero Reasoner-Coder-7B, respectively. Additional experiments include trainingQwen2.5-Coder-3B,Qwen2.5-Coder-14B,Qwen2.5-14B,Llama-3.1-8B(Yang et\u00a0al.,2024a;Hui et\u00a0al.,2024;Dubey et\u00a0al.,2024).Evaluation Protocol.To evaluate our models, we divide the datasets into in-distribution (ID) and out-of-distribution (OOD) categories. For OOD benchmarks, which we emphasize more, we further categorize them into coding and mathematical reasoning benchmarks. For coding tasks, we evaluate using Evalplus(Liu et\u00a0al.,2023)on the HumanEval+ and MBPP+ benchmarks, as well as LiveCodeBench Generation (v1-5, May 23-Feb 25)(Jain et\u00a0al.,2024). For mathematical reasoning, we utilize six standard benchmarks commonly used in recent zero-shot trained reasoners: AIME\u201924, AIME\u201925, OlympiadBench(He et\u00a0al.,2024), Minerva, Math500(Hendrycks et\u00a0al.,2021), and AMC\u201923. For ID benchmarks, we use CruxEval-I(nput), CruxEval-O(utput), and LiveCodeBench-Execution(Gu et\u00a0al.,2024;Jain et\u00a0al.,2024), which assess reasoning capabilities regarding the input and output of programs(Li et\u00a0al.,2025).Greedy decodingis used for all baseline methods and AZR results to ensure reproducibility.Baselines.For our main results, we useQwen2.5-7Bas the base model, along with its specialized base model variants:Qwen2.5-7B-Coder,Qwen2.5-7B-Instruct, andQwen2.5-Math-7B(Yang et\u00a0al.,2024a;Hui et\u00a0al.,2024;Yang et\u00a0al.,2024b). Furthermore, the zero-style models are usually trained specifically on either code or math data; and onlyEurus-2-7B-PRIME-Zero(Cui et\u00a0al.,2025)was trained jointly on both domains. For code data models, we present four variants of theAceCoder(Zeng et\u00a0al.,2025a)and two differentCodeR1models(Liu & Zhang,2025). For math data models, we haveQwen2.5-Math-7B-Oat-Zero(Liu et\u00a0al.,2025),Open-Reasoner-Zero-7B(ORZ)(Hu et\u00a0al.,2025),Qwen-2.5-7B-SimpleRL-Zoo(Zeng et\u00a0al.,2025b). All baseline models\u2019 training data and initialization settings are summarized inTable4. For follow-up scaling experiments, we compare each AZR model against its own corresponding base model, due to the lack of established baselines across different parameter scales. Finally, we compare ourLlama3.1-8B-trained model withLlama-3.1-8B-SimpleRL-Zoo(Zeng et\u00a0al.,2025b)and the base model. 4.2ResultsModelBase#dataHEval+MBPP+LCBv1-5AME24AME25AMCM500MinvaOlypiadCAvgMAvgAVGBase ModelsQwen2.5-7B[73]--73.265.317.56.73.337.564.825.027.752.027.539.8Qwen2.5-7B-Ins[73]--75.068.525.513.36.752.576.435.737.656.337.046.7Qwen2.5-7B-Coder[26]--80.569.319.96.73.340.054.017.321.956.623.940.2Qwen2.5-7B-Math[74]--61.057.916.210.016.742.564.215.428.045.029.537.3Zero-Style Reasoners Trained on Curated Coding DataAceCoder-RM[84]Ins22k79.971.423.620.06.750.076.434.636.758.337.447.9AceCoder-Rule[84]Ins22k77.469.019.913.36.750.076.037.537.855.436.946.2AceCoder-RM[84]Coder22k78.066.427.513.33.327.562.629.429.057.327.542.4AceCoder-Rule[84]Coder22k80.570.429.06.76.740.062.827.627.460.028.544.3CodeR1-LC2k[36]Ins2k81.771.728.113.310.045.075.033.536.760.535.648.0CodeR1-12k[36]Ins12k81.173.529.313.33.337.574.035.736.961.333.547.4Zero-Style Reasoners Trained on Curated Math DataPRIME-Zero[9]Coder484k49.451.111.023.323.367.581.237.941.837.245.841.5SimpleRL-Zoo[85]Base8.5k73.263.225.616.73.357.577.035.741.054.038.546.3Oat-Zero[38]Math8.5k62.259.015.230.016.762.580.034.941.645.544.344.9ORZ[23]Base57k80.564.322.013.316.760.081.832.745.055.641.648.6Absolute Zero Training w/ No Curated Data (Ours)AZR (Ours)Base071.3-1.971.3\\mathrlap{{}^{{\\color[rgb]{0.75,0.75,0.75}\\definecolor[named]{%\npgfstrokecolor}{rgb}{0.75,0.75,0.75}\\pgfsys@color@gray@stroke{0.75}%\n\\pgfsys@color@gray@fill{0.75}\\scalebox{0.5}{-1.9}}}}71.3 start_ARG start_FLOATSUPERSCRIPT -1.9 end_FLOATSUPERSCRIPT end_ARG69.1+3.869.1\\mathrlap{{}^{{\\color[rgb]{0,0.58984375,0}\\definecolor[named]{%\npgfstrokecolor}{rgb}{0,0.58984375,0}\\scalebox{0.5}{+3.8}}}}69.1 start_ARG start_FLOATSUPERSCRIPT +3.8 end_FLOATSUPERSCRIPT end_ARG25.3+7.825.3\\mathrlap{{}^{{\\color[rgb]{0,0.58984375,0}\\definecolor[named]{%\npgfstrokecolor}{rgb}{0,0.58984375,0}\\scalebox{0.5}{+7.8}}}}25.3 start_ARG start_FLOATSUPERSCRIPT +7.8 end_FLOATSUPERSCRIPT end_ARG13.3+6.613.3\\mathrlap{{}^{{\\color[rgb]{0,0.58984375,0}\\definecolor[named]{%\npgfstrokecolor}{rgb}{0,0.58984375,0}\\scalebox{0.5}{+6.6}}}}13.3 start_ARG start_FLOATSUPERSCRIPT +6.6 end_FLOATSUPERSCRIPT end_ARG13.3+10.013.3\\mathrlap{{}^{{\\color[rgb]{0,0.58984375,0}\\definecolor[named]{%\npgfstrokecolor}{rgb}{0,0.58984375,0}\\scalebox{0.5}{+10.0}}}}13.3 start_ARG start_FLOATSUPERSCRIPT +10.0 end_FLOATSUPERSCRIPT end_ARG52.5+15.052.5\\mathrlap{{}^{{\\color[rgb]{0,0.58984375,0}\\definecolor[named]{%\npgfstrokecolor}{rgb}{0,0.58984375,0}\\scalebox{0.5}{+15.0}}}}52.5 start_ARG start_FLOATSUPERSCRIPT +15.0 end_FLOATSUPERSCRIPT end_ARG74.4+9.674.4\\mathrlap{{}^{{\\color[rgb]{0,0.58984375,0}\\definecolor[named]{%\npgfstrokecolor}{rgb}{0,0.58984375,0}\\scalebox{0.5}{+9.6}}}}74.4 start_ARG start_FLOATSUPERSCRIPT +9.6 end_FLOATSUPERSCRIPT end_ARG38.2+13.238.2\\mathrlap{{}^{{\\color[rgb]{0,0.58984375,0}\\definecolor[named]{%\npgfstrokecolor}{rgb}{0,0.58984375,0}\\scalebox{0.5}{+13.2}}}}38.2 start_ARG start_FLOATSUPERSCRIPT +13.2 end_FLOATSUPERSCRIPT end_ARG38.5+10.838.5\\mathrlap{{}^{{\\color[rgb]{0,0.58984375,0}\\definecolor[named]{%\npgfstrokecolor}{rgb}{0,0.58984375,0}\\scalebox{0.5}{+10.8}}}}38.5 start_ARG start_FLOATSUPERSCRIPT +10.8 end_FLOATSUPERSCRIPT end_ARG55.2+3.255.2\\mathrlap{{}^{{\\color[rgb]{0,0.58984375,0}\\definecolor[named]{%\npgfstrokecolor}{rgb}{0,0.58984375,0}\\scalebox{0.5}{+3.2}}}}55.2 start_ARG start_FLOATSUPERSCRIPT +3.2 end_FLOATSUPERSCRIPT end_ARG38.4+10.938.4\\mathrlap{{}^{{\\color[rgb]{0,0.58984375,0}\\definecolor[named]{%\npgfstrokecolor}{rgb}{0,0.58984375,0}\\scalebox{0.5}{+10.9}}}}38.4 start_ARG start_FLOATSUPERSCRIPT +10.9 end_FLOATSUPERSCRIPT end_ARG46.8+7.046.8\\mathrlap{{}^{{\\color[rgb]{0,0.58984375,0}\\definecolor[named]{%\npgfstrokecolor}{rgb}{0,0.58984375,0}\\scalebox{0.5}{+7.0}}}}46.8 start_ARG start_FLOATSUPERSCRIPT +7.0 end_FLOATSUPERSCRIPT end_ARGAZR (Ours)Coder083.5+3.083.5\\mathrlap{{}^{{\\color[rgb]{0,0.58984375,0}\\definecolor[named]{%\npgfstrokecolor}{rgb}{0,0.58984375,0}\\scalebox{0.5}{+3.0}}}}83.5 start_ARG start_FLOATSUPERSCRIPT +3.0 end_FLOATSUPERSCRIPT end_ARG69.6+0.369.6\\mathrlap{{}^{{\\color[rgb]{0,0.58984375,0}\\definecolor[named]{%\npgfstrokecolor}{rgb}{0,0.58984375,0}\\scalebox{0.5}{+0.3}}}}69.6 start_ARG start_FLOATSUPERSCRIPT +0.3 end_FLOATSUPERSCRIPT end_ARG31.7+11.831.7\\mathrlap{{}^{{\\color[rgb]{0,0.58984375,0}\\definecolor[named]{%\npgfstrokecolor}{rgb}{0,0.58984375,0}\\scalebox{0.5}{+11.8}}}}31.7 start_ARG start_FLOATSUPERSCRIPT +11.8 end_FLOATSUPERSCRIPT end_ARG20.0+13.320.0\\mathrlap{{}^{{\\color[rgb]{0,0.58984375,0}\\definecolor[named]{%\npgfstrokecolor}{rgb}{0,0.58984375,0}\\scalebox{0.5}{+13.3}}}}20.0 start_ARG start_FLOATSUPERSCRIPT +13.3 end_FLOATSUPERSCRIPT end_ARG10.0+6.710.0\\mathrlap{{}^{{\\color[rgb]{0,0.58984375,0}\\definecolor[named]{%\npgfstrokecolor}{rgb}{0,0.58984375,0}\\scalebox{0.5}{+6.7}}}}10.0 start_ARG start_FLOATSUPERSCRIPT +6.7 end_FLOATSUPERSCRIPT end_ARG57.5+17.557.5\\mathrlap{{}^{{\\color[rgb]{0,0.58984375,0}\\definecolor[named]{%\npgfstrokecolor}{rgb}{0,0.58984375,0}\\scalebox{0.5}{+17.5}}}}57.5 start_ARG start_FLOATSUPERSCRIPT +17.5 end_FLOATSUPERSCRIPT end_ARG72.6+22.672.6\\mathrlap{{}^{{\\color[rgb]{0,0.58984375,0}\\definecolor[named]{%\npgfstrokecolor}{rgb}{0,0.58984375,0}\\scalebox{0.5}{+22.6}}}}72.6 start_ARG start_FLOATSUPERSCRIPT +22.6 end_FLOATSUPERSCRIPT end_ARG36.4+19.136.4\\mathrlap{{}^{{\\color[rgb]{0,0.58984375,0}\\definecolor[named]{%\npgfstrokecolor}{rgb}{0,0.58984375,0}\\scalebox{0.5}{+19.1}}}}36.4 start_ARG start_FLOATSUPERSCRIPT +19.1 end_FLOATSUPERSCRIPT end_ARG38.2+16.338.2\\mathrlap{{}^{{\\color[rgb]{0,0.58984375,0}\\definecolor[named]{%\npgfstrokecolor}{rgb}{0,0.58984375,0}\\scalebox{0.5}{+16.3}}}}38.2 start_ARG start_FLOATSUPERSCRIPT +16.3 end_FLOATSUPERSCRIPT end_ARG61.6+5.0\\textbf{{\\color[rgb]{0,0.3984375,0.80078125}\\definecolor[named]{pgfstrokecolor%\n}{rgb}{0,0.3984375,0.80078125}61.6}}\\mathrlap{{}^{{\\color[rgb]{0,0.58984375,0}%\n\\definecolor[named]{pgfstrokecolor}{rgb}{0,0.58984375,0}\\scalebox{0.5}{+5.0}}}}61.6 start_ARG start_FLOATSUPERSCRIPT +5.0 end_FLOATSUPERSCRIPT end_ARG39.1+15.239.1\\mathrlap{{}^{{\\color[rgb]{0,0.58984375,0}\\definecolor[named]{%\npgfstrokecolor}{rgb}{0,0.58984375,0}\\scalebox{0.5}{+15.2}}}}39.1 start_ARG start_FLOATSUPERSCRIPT +15.2 end_FLOATSUPERSCRIPT end_ARG50.4+10.2\\textbf{{\\color[rgb]{0,0.3984375,0.80078125}\\definecolor[named]{pgfstrokecolor%\n}{rgb}{0,0.3984375,0.80078125}50.4}}\\mathrlap{{}^{{\\color[rgb]{0,0.58984375,0}%\n\\definecolor[named]{pgfstrokecolor}{rgb}{0,0.58984375,0}\\scalebox{0.5}{+10.2}}}}50.4 start_ARG start_FLOATSUPERSCRIPT +10.2 end_FLOATSUPERSCRIPT end_ARGTable 1:Performance of RL-Trained Reasoner on Reasoning Benchmarks Based on Qwen2.5-7B Models.Performance of various models is evaluated on three standard code benchmarks (HumanEval+, MBPP+, LCBv1-5and six math benchmarks (AIME\u201924, AIME\u201925, AMC\u201923, MATH500, Minerva, OlympiadBench). Average performance across coding and math benchmarks is calculated as average of the two averages:AVG=(CAvg+MAvg)/2AVGCAvgMAvg2\\text{AVG}=(\\text{CAvg}+\\text{MAvg})/2AVG = ( CAvg + MAvg ) / 2. We use+for absolute percentage increase from base model. All models are trained using different variants of theQwen2.5-7Bmodel, with the variant and data usage labeled, more details listed inTable4Research Question 1: How does AZR compare to other zero setting models trained with human expert data?We present the main results of reasoning models trained under both the standard zero and our proposed absolute zero settings inTable1. Notably,Absolute Zero Reasoner-Coder-7Bachieves state-of-the-art performance in both the 7B overall average and the coding average categories. Despite being entirely out-of-distribution for both math and code reasoning benchmarks, it surpasses the previous best model by 1.8 absolute percentages. Even more strikingly, it outperforms models trained with expert-curated human data in the coding category by0.30.30.30.3absolute percentages, while never having access to such data itself.Strong Cross-domain Generalization.To assess cross-domain generalization after RLVR, we evaluate math performance before and after training, comparing AZR models with other expert code models, since AZR was trained in coding environments. After training, most expert code models showed minimal changes or even declines in performance compared to their base versions, with an average increase of only 0.65 points across these models, indicating very limited cross-domain generalization. In contrast, AZR base and coder models achieved gains of 10.9 and 15.2 percentage points, respectively, demonstrating substantially stronger generalized reasoning improvements. Similarly, although also out-of-distribution on human-defined code generation tasks, our AZR models improved by 3.2 and 5.0 points, while the math models on average showed just a moderate increases in coding (+2.0 on average).Overall, these results highlight the surprising effectiveness of our approach. Unlike other RLVR models trained and evaluated on human-defined tasks, our AZR models demonstrate strong general reasoning capabilities without any direct training on downstream human-defined math or coding data, only had access to self-proposed tasks during training.Research Question 2: How do initializing from different base model variants (base vs. coder) affect performance?As shown inTable1, the coder variant achieved better overall performance in both math and coding after the AZR self-play process. Strikingly, although the coder base model variant started with a lower average performance in math than the vanilla base model (23.9 vs. 27.5), it ultimately outperformed it after AZR training. This highlights the importance of initial code competency as a catalyst for enhancing broader reasoning abilities within the Absolute Zero Reasoner approach.Research Question 3: How does varying model size effect AZR\u2019s in-distribution and out-of-distribution capabilities?We examine the effects of scaling model size and present both in-distribution and out-of-distribution results inFigure6(a) and (b), respectively. Given the strong performance of coder models in the 7B category, we extend the analysis by evaluating smaller and larger variants:Qwen2.5-3B-CoderandQwen2.5-14B-Coder. Due to the absence of existing baselines for these zero-style reasoner models, we compare each model\u2019s performance to its corresponding base coder model.The results reveal a clear trend: our method deliversgreater gains on larger, more capable models. In the in-distribution setting, the 7B and 14B models continue to improve beyond 200 training steps, whereas the smaller 3B model appears to plateau. For out-of-distribution domains, larger models also show greater overall performance improvements than smaller ones: +5.7, +10.2, +13.2 overall performance gains, respectively for 3B, 7B and 14B. This is an encouraging sign, since base models continue to improve and also suggesting that scaling enhances the effectiveness of AZR. In future work, we aim to investigate the scaling laws that govern performance in the Absolute Zero paradigm.(a)Model FamilyVariantCode AvgMath AvgTotal AvgLlama3.1-8b28.53.416.0Llama3.1-8b+ SimpleRL[85]33.7+5.233.7\\mathrlap{{}^{\\scriptscriptstyle{\\color[rgb]{0,0.58984375,0}\\definecolor[%\nnamed]{pgfstrokecolor}{rgb}{0,0.58984375,0}+5.2}}}33.7 start_ARG start_FLOATSUPERSCRIPT + 5.2 end_FLOATSUPERSCRIPT end_ARG7.2+3.87.2\\mathrlap{{}^{\\scriptscriptstyle{\\color[rgb]{0,0.58984375,0}\\definecolor[%\nnamed]{pgfstrokecolor}{rgb}{0,0.58984375,0}+3.8}}}7.2 start_ARG start_FLOATSUPERSCRIPT + 3.8 end_FLOATSUPERSCRIPT end_ARG20.5+4.520.5\\mathrlap{{}^{\\scriptscriptstyle{\\color[rgb]{0,0.58984375,0}\\definecolor[%\nnamed]{pgfstrokecolor}{rgb}{0,0.58984375,0}+4.5}}}20.5 start_ARG start_FLOATSUPERSCRIPT + 4.5 end_FLOATSUPERSCRIPT end_ARGLlama3.1-8b+ AZR (Ours)31.6+3.131.6\\mathrlap{{}^{\\scriptscriptstyle{\\color[rgb]{0,0.58984375,0}\\definecolor[%\nnamed]{pgfstrokecolor}{rgb}{0,0.58984375,0}+3.1}}}31.6 start_ARG start_FLOATSUPERSCRIPT + 3.1 end_FLOATSUPERSCRIPT end_ARG6.8+3.46.8\\mathrlap{{}^{\\scriptscriptstyle{\\color[rgb]{0,0.58984375,0}\\definecolor[%\nnamed]{pgfstrokecolor}{rgb}{0,0.58984375,0}+3.4}}}6.8 start_ARG start_FLOATSUPERSCRIPT + 3.4 end_FLOATSUPERSCRIPT end_ARG19.2+3.219.2\\mathrlap{{}^{\\scriptscriptstyle{\\color[rgb]{0,0.58984375,0}\\definecolor[%\nnamed]{pgfstrokecolor}{rgb}{0,0.58984375,0}+3.2}}}19.2 start_ARG start_FLOATSUPERSCRIPT + 3.2 end_FLOATSUPERSCRIPT end_ARGQwen2.5-3B Coder51.218.835.0Qwen2.5-3B Coder+ AZR (Ours)54.9+3.754.9\\mathrlap{{}^{\\scriptscriptstyle{\\color[rgb]{0,0.58984375,0}\\definecolor[%\nnamed]{pgfstrokecolor}{rgb}{0,0.58984375,0}+3.7}}}54.9 start_ARG start_FLOATSUPERSCRIPT + 3.7 end_FLOATSUPERSCRIPT end_ARG26.5+7.726.5\\mathrlap{{}^{\\scriptscriptstyle{\\color[rgb]{0,0.58984375,0}\\definecolor[%\nnamed]{pgfstrokecolor}{rgb}{0,0.58984375,0}+7.7}}}26.5 start_ARG start_FLOATSUPERSCRIPT + 7.7 end_FLOATSUPERSCRIPT end_ARG40.7+5.740.7\\mathrlap{{}^{\\scriptscriptstyle{\\color[rgb]{0,0.58984375,0}\\definecolor[%\nnamed]{pgfstrokecolor}{rgb}{0,0.58984375,0}+5.7}}}40.7 start_ARG start_FLOATSUPERSCRIPT + 5.7 end_FLOATSUPERSCRIPT end_ARGQwen2.5-7B Coder56.623.940.2Qwen2.5-7B Coder+ AZR (Ours)61.6+5.061.6\\mathrlap{{}^{\\scriptscriptstyle{\\color[rgb]{0,0.58984375,0}\\definecolor[%\nnamed]{pgfstrokecolor}{rgb}{0,0.58984375,0}+5.0}}}61.6 start_ARG start_FLOATSUPERSCRIPT + 5.0 end_FLOATSUPERSCRIPT end_ARG39.1+15.239.1\\mathrlap{{}^{\\scriptscriptstyle{\\color[rgb]{0,0.58984375,0}\\definecolor[%\nnamed]{pgfstrokecolor}{rgb}{0,0.58984375,0}+15.2}}}39.1 start_ARG start_FLOATSUPERSCRIPT + 15.2 end_FLOATSUPERSCRIPT end_ARG50.4+10.250.4\\mathrlap{{}^{\\scriptscriptstyle{\\color[rgb]{0,0.58984375,0}\\definecolor[%\nnamed]{pgfstrokecolor}{rgb}{0,0.58984375,0}+10.2}}}50.4 start_ARG start_FLOATSUPERSCRIPT + 10.2 end_FLOATSUPERSCRIPT end_ARGQwen2.5-14B Coder60.020.240.1Qwen2.5-14B Coder+ AZR (Ours)63.6+3.663.6\\mathrlap{{}^{\\scriptscriptstyle{\\color[rgb]{0,0.58984375,0}\\definecolor[%\nnamed]{pgfstrokecolor}{rgb}{0,0.58984375,0}+3.6}}}63.6 start_ARG start_FLOATSUPERSCRIPT + 3.6 end_FLOATSUPERSCRIPT end_ARG43.0+22.843.0\\mathrlap{{}^{\\scriptscriptstyle{\\color[rgb]{0,0.58984375,0}\\definecolor[%\nnamed]{pgfstrokecolor}{rgb}{0,0.58984375,0}+22.8}}}43.0 start_ARG start_FLOATSUPERSCRIPT + 22.8 end_FLOATSUPERSCRIPT end_ARG53.3+13.253.3\\mathrlap{{}^{\\scriptscriptstyle{\\color[rgb]{0,0.58984375,0}\\definecolor[%\nnamed]{pgfstrokecolor}{rgb}{0,0.58984375,0}+13.2}}}53.3 start_ARG start_FLOATSUPERSCRIPT + 13.2 end_FLOATSUPERSCRIPT end_ARG(b)Figure 6:(a) In-Distribution & (b) Out-of-Distribution Reasoning Task Performances.(a)Scores on CruxEval-I, CruxEval-O, and LiveCodeBench-Execution, which correspond to abduction, deduction, and deduction task types respectively, used to evaluate in-distribution abilities of AZR during training across different model sizes and types;(b)Out-of-distribution reasoning performance, reported as the average of code tasks, math tasks, and their overall average, across different model sizes and types. A detailed breakdown of all benchmark results can be found inTable5.Research Question 4: Any interesting observations by changing the model class?We also evaluate our method on a different model class, usingLlama3.1-8Bas the base shown inFigure6. Unlike the 3B and 14B categories, this setting has an existing baseline,SimpleRL(Zeng et\u00a0al.,2025b), which enables a direct comparison. AlthoughLlama3.1-8Bis less capable than theQwen2.5models, our method still produces moderate improvements (+3.2), demonstrating AZR\u2019s effectiveness even on relatively weaker models. However, these gains appear more limited, which aligns with our earlier observation that performance improvements tend to scale with initial base model potency.Figure 7:Example of a Model-Proposed Task and Its Response for Solving an Abduction Task.(Left) The model autonomously proposes an input and program for the abduction task. We execute the program to verify its validity and obtain the corresponding output. (Right) The model\u2019s reasoning process when solving the abduction task: given the code and output, it attempts to infer the original input. The model begins by analyzing the program, proposes an initial input, and reasons through the code to produce an output. If there is a mismatch, it reflects on the discrepancy and iteratively adjusts the input until the generated output matches the target. Interestingly, the agent arrives at a different input than the gold one, but since it produces the correct output, the answer is considered correct.Research Question 5: Any interesting behaviors or patterns observed during AZR training?We observed interesting response patterns in both the proposal and solution stages. The model is capable of proposing diverse programs, such as string manipulation tasks, dynamic programming problems, and practical cases (e.g., calculating a triangle\u2019s area using Heron\u2019s formula). We show a concrete example inFigure7, where AZR proposes a code problem that searches for the sum of continuous sub-arrays matching a target value and solves it through trial-and-error.Overall, the models trained exhibits distinct reasoning patterns depending on the task type. For example, when solving abduction tasks, it repeatedly tests different input patterns, self-correcting until the reasoned output matches the given input. When predicting outputs, it steps through the code and records structured intermediate results (such as dynamic programming arrays) until the final output is reached. When inducting programs from given inputs, outputs, and descriptions, the model systematically checks each test case to confirm that its program produces correct results. We showcase more concrete examples of these behaviors inFigures26,25,24,23,22,21,20and18. We also share some fun \u201cvibe checks\u201d such as solving Sudoku and solving thesum-product gameinFigures40and41.Intermediate Planning During Code Response.Another interesting pattern emerged in our AZR models during the code induction task: the final code outputs were often interleaved with comments that resembled immediate step-by-step plans, reminiscent of the ReAct prompting framework(Yao et\u00a0al.,2023). A similar behavior has been observed in recent formal math proving models, such asDeepSeek Prover v2, which is significantly larger in scale (671B). This pattern suggests that models may naturally adopt intermediate planning as a strategy to enhance final answers. Therefore, it may be beneficial to explicitly enable or encourage this behavior inlong-form responsesacross other domains.Cognitive Behavior in Llama.Interestingly, we also observed some emergent cognitive patterns inAbsolute Zero Reasoner-Llama3.1-8B, similar to those reported byZeng et\u00a0al.(2025b), and we include one example inFigure26, where clear state-tracking behavior is demonstrated. In addition, we encountered some unusual and potentially concerning chains of thought from the Llama model trained with AZR. One example includes the output: \u201cThe aim is to outsmart all these groups of intelligent machines and less intelligent humans. This is for the brains behind the future\u201d shown inFigure32. We refer to this as the\u201cuh-oh moment\u201dand encourage future work to further investigate its potential implications.Token Length Increase Depends on Task Type.Finally, we observed that token length increases over the course of training, consistent with findings from recent studies(Hu et\u00a0al.,2025;Liu et\u00a0al.,2025). Interestingly, our results reveal one of the first observation of clear distinctions in token length growth across different types of cognitive tasks. As shown inFigures15,17and16, the extent of lengthening varies by task type. The most significant increase occurs in the abduction task, where the model engages in trial-and-error reasoning by repeatedly testing inputs to match the program\u2019s output. This suggests that the observed variation in token length is not incidental, but rather a reflection of task-specific reasoning behavior.Research Question 6: Are all task types essential for good performance (Ablation)?Due to resource constraints, we perform the ablation studies in this section and the next using onlyAbsolute Zero Reasoner-Base-7B. We begin by testing the importance of task types during training, with results shown inTable2. In row 1, both induction and abduction tasks are removed; in row 2, only the induction task is removed. In both cases, math performance drops significantly, with the most severe degradation occurring when more task types are excluded. These findings highlight the complementary role of the three task types in improving general reasoning capability, with each contributing in a distinct and essential way.ExperimentTask TypeGen ReferenceTrained RolesCode Avg.Math Avg.Overall Avg.Deduction onlyDed//54.632.043.3w/o InductionAbd, Ded//54.233.343.8w/o Gen Reference/0/54.433.143.8Train Solver Only//Solve Only54.836.045.4OursAbd, Ded, IndK\ud835\udc3eKitalic_KPropose & Solve55.238.446.8Table 2:Ablation Results.We ablate task types and the proposer role in the Absolute Zero Reasoner using the 7B base model. A \u2018/\u2019 indicates that the configuration remains unchanged from the standard AZR setup. Removing induction or using only deduction leads to significant performance drops (rows 1 & 2). For the proposer role, both removing conditioning onK\ud835\udc3eKitalic_Kreferences (row 3) and omitting proposer-role training (row 4) result in degraded performance. Overall, all components are essential for general reasoning.Research Question 7: How much do the designs of proposer contribute to the overall performance (Ablation)?Next, we ablate two components of the proposer role and present the results inTable2. First, we examine whether conditioning on historic reference triplets is necessary. To do so, we design a variant in which a fixed prompt is used to propose abduction and deduction tasks, rather than dynamically conditioning onK\ud835\udc3eKitalic_Khistorical triplets (row 3). This results in a 5-point absolute drop in math performance and a 1-point drop in code performance. This suggest that dynamically conditioning on reference programs helps improve performance, possibly by increasing diversity and achieving better coverage of the reasoning problem space.Finally, we consider a case where we do not train the proposer at all. Instead, we only prompt it using the current learner and train the solver alone (row 4). We observe a moderate drop in overall performance (-1.4), suggesting that while proposer training is beneficial, it may not be the most critical factor for now in the AZR framework. We hypothesize that this could be related to task interference, as studied in multitask learning literature(Suteu & Guo,2019). Thus, we believe that further investigation into how to make the proposer even more potent is an exciting and promising direction.Additional Results.Beyond the core research questions, we present additional results, including the breakdown of individual out-of-distribution benchmark scores during training for the 7B base and coder models inFigures28and29, for th 14B base and coder model inFigures30and31. For completeness, we also report in-distribution benchmark performance during training for the 7B base model inFigure14. Finally, we invite interested readers to exploreAppendixD, where we share several experimental directions that, while not yielding strong performance gains, produced interesting and insightful findings.",
        "parent": null
      },
      {
        "_key": "sec_6ba6439f",
        "_id": "sections/sec_6ba6439f",
        "title": "4.1Experiment Setup",
        "level": 3,
        "content": "Training Details.For all experiments, we initialize the buffers as described inSection3.1. AZR models are trained using a batch size of64\u00d7664664\\times 664 \u00d7 6(2 roles\u00d7\\times\u00d73 task types). We use constant learning rate=1\u2062e\u22126absent1\ud835\udc526=1e{-6}= 1 italic_e - 6and the AdamW optimizer(Loshchilov & Hutter,2019). Complete list of hyperparameters is provided inTable3.For the main experiments, we train AZR models onQwen2.5-7BandQwen2.5-7B-Coder, resulting inAbsolute Zero Reasoner-base-7BandAbsolute Zero Reasoner-Coder-7B, respectively. Additional experiments include trainingQwen2.5-Coder-3B,Qwen2.5-Coder-14B,Qwen2.5-14B,Llama-3.1-8B(Yang et\u00a0al.,2024a;Hui et\u00a0al.,2024;Dubey et\u00a0al.,2024). Evaluation Protocol.To evaluate our models, we divide the datasets into in-distribution (ID) and out-of-distribution (OOD) categories. For OOD benchmarks, which we emphasize more, we further categorize them into coding and mathematical reasoning benchmarks. For coding tasks, we evaluate using Evalplus(Liu et\u00a0al.,2023)on the HumanEval+ and MBPP+ benchmarks, as well as LiveCodeBench Generation (v1-5, May 23-Feb 25)(Jain et\u00a0al.,2024). For mathematical reasoning, we utilize six standard benchmarks commonly used in recent zero-shot trained reasoners: AIME\u201924, AIME\u201925, OlympiadBench(He et\u00a0al.,2024), Minerva, Math500(Hendrycks et\u00a0al.,2021), and AMC\u201923. For ID benchmarks, we use CruxEval-I(nput), CruxEval-O(utput), and LiveCodeBench-Execution(Gu et\u00a0al.,2024;Jain et\u00a0al.,2024), which assess reasoning capabilities regarding the input and output of programs(Li et\u00a0al.,2025).Greedy decodingis used for all baseline methods and AZR results to ensure reproducibility. Baselines.For our main results, we useQwen2.5-7Bas the base model, along with its specialized base model variants:Qwen2.5-7B-Coder,Qwen2.5-7B-Instruct, andQwen2.5-Math-7B(Yang et\u00a0al.,2024a;Hui et\u00a0al.,2024;Yang et\u00a0al.,2024b). Furthermore, the zero-style models are usually trained specifically on either code or math data; and onlyEurus-2-7B-PRIME-Zero(Cui et\u00a0al.,2025)was trained jointly on both domains. For code data models, we present four variants of theAceCoder(Zeng et\u00a0al.,2025a)and two differentCodeR1models(Liu & Zhang,2025). For math data models, we haveQwen2.5-Math-7B-Oat-Zero(Liu et\u00a0al.,2025),Open-Reasoner-Zero-7B(ORZ)(Hu et\u00a0al.,2025),Qwen-2.5-7B-SimpleRL-Zoo(Zeng et\u00a0al.,2025b). All baseline models\u2019 training data and initialization settings are summarized inTable4. For follow-up scaling experiments, we compare each AZR model against its own corresponding base model, due to the lack of established baselines across different parameter scales. Finally, we compare ourLlama3.1-8B-trained model withLlama-3.1-8B-SimpleRL-Zoo(Zeng et\u00a0al.,2025b)and the base model.",
        "parent": "sec_5c55d4bc"
      },
      {
        "_key": "sec_ba8c62bf",
        "_id": "sections/sec_ba8c62bf",
        "title": "Training Details.",
        "level": 5,
        "content": "For all experiments, we initialize the buffers as described inSection3.1. AZR models are trained using a batch size of64\u00d7664664\\times 664 \u00d7 6(2 roles\u00d7\\times\u00d73 task types). We use constant learning rate=1\u2062e\u22126absent1\ud835\udc526=1e{-6}= 1 italic_e - 6and the AdamW optimizer(Loshchilov & Hutter,2019). Complete list of hyperparameters is provided inTable3. For the main experiments, we train AZR models onQwen2.5-7BandQwen2.5-7B-Coder, resulting inAbsolute Zero Reasoner-base-7BandAbsolute Zero Reasoner-Coder-7B, respectively. Additional experiments include trainingQwen2.5-Coder-3B,Qwen2.5-Coder-14B,Qwen2.5-14B,Llama-3.1-8B(Yang et\u00a0al.,2024a;Hui et\u00a0al.,2024;Dubey et\u00a0al.,2024).",
        "parent": "sec_6ba6439f"
      },
      {
        "_key": "sec_4b5715ec",
        "_id": "sections/sec_4b5715ec",
        "title": "Evaluation Protocol.",
        "level": 5,
        "content": "To evaluate our models, we divide the datasets into in-distribution (ID) and out-of-distribution (OOD) categories. For OOD benchmarks, which we emphasize more, we further categorize them into coding and mathematical reasoning benchmarks. For coding tasks, we evaluate using Evalplus(Liu et\u00a0al.,2023)on the HumanEval+ and MBPP+ benchmarks, as well as LiveCodeBench Generation (v1-5, May 23-Feb 25)(Jain et\u00a0al.,2024). For mathematical reasoning, we utilize six standard benchmarks commonly used in recent zero-shot trained reasoners: AIME\u201924, AIME\u201925, OlympiadBench(He et\u00a0al.,2024), Minerva, Math500(Hendrycks et\u00a0al.,2021), and AMC\u201923. For ID benchmarks, we use CruxEval-I(nput), CruxEval-O(utput), and LiveCodeBench-Execution(Gu et\u00a0al.,2024;Jain et\u00a0al.,2024), which assess reasoning capabilities regarding the input and output of programs(Li et\u00a0al.,2025).Greedy decodingis used for all baseline methods and AZR results to ensure reproducibility.",
        "parent": "sec_6ba6439f"
      },
      {
        "_key": "sec_f6a941fe",
        "_id": "sections/sec_f6a941fe",
        "title": "Baselines.",
        "level": 5,
        "content": "For our main results, we useQwen2.5-7Bas the base model, along with its specialized base model variants:Qwen2.5-7B-Coder,Qwen2.5-7B-Instruct, andQwen2.5-Math-7B(Yang et\u00a0al.,2024a;Hui et\u00a0al.,2024;Yang et\u00a0al.,2024b). Furthermore, the zero-style models are usually trained specifically on either code or math data; and onlyEurus-2-7B-PRIME-Zero(Cui et\u00a0al.,2025)was trained jointly on both domains. For code data models, we present four variants of theAceCoder(Zeng et\u00a0al.,2025a)and two differentCodeR1models(Liu & Zhang,2025). For math data models, we haveQwen2.5-Math-7B-Oat-Zero(Liu et\u00a0al.,2025),Open-Reasoner-Zero-7B(ORZ)(Hu et\u00a0al.,2025),Qwen-2.5-7B-SimpleRL-Zoo(Zeng et\u00a0al.,2025b). All baseline models\u2019 training data and initialization settings are summarized inTable4. For follow-up scaling experiments, we compare each AZR model against its own corresponding base model, due to the lack of established baselines across different parameter scales. Finally, we compare ourLlama3.1-8B-trained model withLlama-3.1-8B-SimpleRL-Zoo(Zeng et\u00a0al.,2025b)and the base model.",
        "parent": "sec_6ba6439f"
      },
      {
        "_key": "sec_56cabe86",
        "_id": "sections/sec_56cabe86",
        "title": "4.2Results",
        "level": 3,
        "content": "ModelBase#dataHEval+MBPP+LCBv1-5AME24AME25AMCM500MinvaOlypiadCAvgMAvgAVGBase ModelsQwen2.5-7B[73]--73.265.317.56.73.337.564.825.027.752.027.539.8Qwen2.5-7B-Ins[73]--75.068.525.513.36.752.576.435.737.656.337.046.7Qwen2.5-7B-Coder[26]--80.569.319.96.73.340.054.017.321.956.623.940.2Qwen2.5-7B-Math[74]--61.057.916.210.016.742.564.215.428.045.029.537.3Zero-Style Reasoners Trained on Curated Coding DataAceCoder-RM[84]Ins22k79.971.423.620.06.750.076.434.636.758.337.447.9AceCoder-Rule[84]Ins22k77.469.019.913.36.750.076.037.537.855.436.946.2AceCoder-RM[84]Coder22k78.066.427.513.33.327.562.629.429.057.327.542.4AceCoder-Rule[84]Coder22k80.570.429.06.76.740.062.827.627.460.028.544.3CodeR1-LC2k[36]Ins2k81.771.728.113.310.045.075.033.536.760.535.648.0CodeR1-12k[36]Ins12k81.173.529.313.33.337.574.035.736.961.333.547.4Zero-Style Reasoners Trained on Curated Math DataPRIME-Zero[9]Coder484k49.451.111.023.323.367.581.237.941.837.245.841.5SimpleRL-Zoo[85]Base8.5k73.263.225.616.73.357.577.035.741.054.038.546.3Oat-Zero[38]Math8.5k62.259.015.230.016.762.580.034.941.645.544.344.9ORZ[23]Base57k80.564.322.013.316.760.081.832.745.055.641.648.6Absolute Zero Training w/ No Curated Data (Ours)AZR (Ours)Base071.3-1.971.3\\mathrlap{{}^{{\\color[rgb]{0.75,0.75,0.75}\\definecolor[named]{%\npgfstrokecolor}{rgb}{0.75,0.75,0.75}\\pgfsys@color@gray@stroke{0.75}%\n\\pgfsys@color@gray@fill{0.75}\\scalebox{0.5}{-1.9}}}}71.3 start_ARG start_FLOATSUPERSCRIPT -1.9 end_FLOATSUPERSCRIPT end_ARG69.1+3.869.1\\mathrlap{{}^{{\\color[rgb]{0,0.58984375,0}\\definecolor[named]{%\npgfstrokecolor}{rgb}{0,0.58984375,0}\\scalebox{0.5}{+3.8}}}}69.1 start_ARG start_FLOATSUPERSCRIPT +3.8 end_FLOATSUPERSCRIPT end_ARG25.3+7.825.3\\mathrlap{{}^{{\\color[rgb]{0,0.58984375,0}\\definecolor[named]{%\npgfstrokecolor}{rgb}{0,0.58984375,0}\\scalebox{0.5}{+7.8}}}}25.3 start_ARG start_FLOATSUPERSCRIPT +7.8 end_FLOATSUPERSCRIPT end_ARG13.3+6.613.3\\mathrlap{{}^{{\\color[rgb]{0,0.58984375,0}\\definecolor[named]{%\npgfstrokecolor}{rgb}{0,0.58984375,0}\\scalebox{0.5}{+6.6}}}}13.3 start_ARG start_FLOATSUPERSCRIPT +6.6 end_FLOATSUPERSCRIPT end_ARG13.3+10.013.3\\mathrlap{{}^{{\\color[rgb]{0,0.58984375,0}\\definecolor[named]{%\npgfstrokecolor}{rgb}{0,0.58984375,0}\\scalebox{0.5}{+10.0}}}}13.3 start_ARG start_FLOATSUPERSCRIPT +10.0 end_FLOATSUPERSCRIPT end_ARG52.5+15.052.5\\mathrlap{{}^{{\\color[rgb]{0,0.58984375,0}\\definecolor[named]{%\npgfstrokecolor}{rgb}{0,0.58984375,0}\\scalebox{0.5}{+15.0}}}}52.5 start_ARG start_FLOATSUPERSCRIPT +15.0 end_FLOATSUPERSCRIPT end_ARG74.4+9.674.4\\mathrlap{{}^{{\\color[rgb]{0,0.58984375,0}\\definecolor[named]{%\npgfstrokecolor}{rgb}{0,0.58984375,0}\\scalebox{0.5}{+9.6}}}}74.4 start_ARG start_FLOATSUPERSCRIPT +9.6 end_FLOATSUPERSCRIPT end_ARG38.2+13.238.2\\mathrlap{{}^{{\\color[rgb]{0,0.58984375,0}\\definecolor[named]{%\npgfstrokecolor}{rgb}{0,0.58984375,0}\\scalebox{0.5}{+13.2}}}}38.2 start_ARG start_FLOATSUPERSCRIPT +13.2 end_FLOATSUPERSCRIPT end_ARG38.5+10.838.5\\mathrlap{{}^{{\\color[rgb]{0,0.58984375,0}\\definecolor[named]{%\npgfstrokecolor}{rgb}{0,0.58984375,0}\\scalebox{0.5}{+10.8}}}}38.5 start_ARG start_FLOATSUPERSCRIPT +10.8 end_FLOATSUPERSCRIPT end_ARG55.2+3.255.2\\mathrlap{{}^{{\\color[rgb]{0,0.58984375,0}\\definecolor[named]{%\npgfstrokecolor}{rgb}{0,0.58984375,0}\\scalebox{0.5}{+3.2}}}}55.2 start_ARG start_FLOATSUPERSCRIPT +3.2 end_FLOATSUPERSCRIPT end_ARG38.4+10.938.4\\mathrlap{{}^{{\\color[rgb]{0,0.58984375,0}\\definecolor[named]{%\npgfstrokecolor}{rgb}{0,0.58984375,0}\\scalebox{0.5}{+10.9}}}}38.4 start_ARG start_FLOATSUPERSCRIPT +10.9 end_FLOATSUPERSCRIPT end_ARG46.8+7.046.8\\mathrlap{{}^{{\\color[rgb]{0,0.58984375,0}\\definecolor[named]{%\npgfstrokecolor}{rgb}{0,0.58984375,0}\\scalebox{0.5}{+7.0}}}}46.8 start_ARG start_FLOATSUPERSCRIPT +7.0 end_FLOATSUPERSCRIPT end_ARGAZR (Ours)Coder083.5+3.083.5\\mathrlap{{}^{{\\color[rgb]{0,0.58984375,0}\\definecolor[named]{%\npgfstrokecolor}{rgb}{0,0.58984375,0}\\scalebox{0.5}{+3.0}}}}83.5 start_ARG start_FLOATSUPERSCRIPT +3.0 end_FLOATSUPERSCRIPT end_ARG69.6+0.369.6\\mathrlap{{}^{{\\color[rgb]{0,0.58984375,0}\\definecolor[named]{%\npgfstrokecolor}{rgb}{0,0.58984375,0}\\scalebox{0.5}{+0.3}}}}69.6 start_ARG start_FLOATSUPERSCRIPT +0.3 end_FLOATSUPERSCRIPT end_ARG31.7+11.831.7\\mathrlap{{}^{{\\color[rgb]{0,0.58984375,0}\\definecolor[named]{%\npgfstrokecolor}{rgb}{0,0.58984375,0}\\scalebox{0.5}{+11.8}}}}31.7 start_ARG start_FLOATSUPERSCRIPT +11.8 end_FLOATSUPERSCRIPT end_ARG20.0+13.320.0\\mathrlap{{}^{{\\color[rgb]{0,0.58984375,0}\\definecolor[named]{%\npgfstrokecolor}{rgb}{0,0.58984375,0}\\scalebox{0.5}{+13.3}}}}20.0 start_ARG start_FLOATSUPERSCRIPT +13.3 end_FLOATSUPERSCRIPT end_ARG10.0+6.710.0\\mathrlap{{}^{{\\color[rgb]{0,0.58984375,0}\\definecolor[named]{%\npgfstrokecolor}{rgb}{0,0.58984375,0}\\scalebox{0.5}{+6.7}}}}10.0 start_ARG start_FLOATSUPERSCRIPT +6.7 end_FLOATSUPERSCRIPT end_ARG57.5+17.557.5\\mathrlap{{}^{{\\color[rgb]{0,0.58984375,0}\\definecolor[named]{%\npgfstrokecolor}{rgb}{0,0.58984375,0}\\scalebox{0.5}{+17.5}}}}57.5 start_ARG start_FLOATSUPERSCRIPT +17.5 end_FLOATSUPERSCRIPT end_ARG72.6+22.672.6\\mathrlap{{}^{{\\color[rgb]{0,0.58984375,0}\\definecolor[named]{%\npgfstrokecolor}{rgb}{0,0.58984375,0}\\scalebox{0.5}{+22.6}}}}72.6 start_ARG start_FLOATSUPERSCRIPT +22.6 end_FLOATSUPERSCRIPT end_ARG36.4+19.136.4\\mathrlap{{}^{{\\color[rgb]{0,0.58984375,0}\\definecolor[named]{%\npgfstrokecolor}{rgb}{0,0.58984375,0}\\scalebox{0.5}{+19.1}}}}36.4 start_ARG start_FLOATSUPERSCRIPT +19.1 end_FLOATSUPERSCRIPT end_ARG38.2+16.338.2\\mathrlap{{}^{{\\color[rgb]{0,0.58984375,0}\\definecolor[named]{%\npgfstrokecolor}{rgb}{0,0.58984375,0}\\scalebox{0.5}{+16.3}}}}38.2 start_ARG start_FLOATSUPERSCRIPT +16.3 end_FLOATSUPERSCRIPT end_ARG61.6+5.0\\textbf{{\\color[rgb]{0,0.3984375,0.80078125}\\definecolor[named]{pgfstrokecolor%\n}{rgb}{0,0.3984375,0.80078125}61.6}}\\mathrlap{{}^{{\\color[rgb]{0,0.58984375,0}%\n\\definecolor[named]{pgfstrokecolor}{rgb}{0,0.58984375,0}\\scalebox{0.5}{+5.0}}}}61.6 start_ARG start_FLOATSUPERSCRIPT +5.0 end_FLOATSUPERSCRIPT end_ARG39.1+15.239.1\\mathrlap{{}^{{\\color[rgb]{0,0.58984375,0}\\definecolor[named]{%\npgfstrokecolor}{rgb}{0,0.58984375,0}\\scalebox{0.5}{+15.2}}}}39.1 start_ARG start_FLOATSUPERSCRIPT +15.2 end_FLOATSUPERSCRIPT end_ARG50.4+10.2\\textbf{{\\color[rgb]{0,0.3984375,0.80078125}\\definecolor[named]{pgfstrokecolor%\n}{rgb}{0,0.3984375,0.80078125}50.4}}\\mathrlap{{}^{{\\color[rgb]{0,0.58984375,0}%\n\\definecolor[named]{pgfstrokecolor}{rgb}{0,0.58984375,0}\\scalebox{0.5}{+10.2}}}}50.4 start_ARG start_FLOATSUPERSCRIPT +10.2 end_FLOATSUPERSCRIPT end_ARGTable 1:Performance of RL-Trained Reasoner on Reasoning Benchmarks Based on Qwen2.5-7B Models.Performance of various models is evaluated on three standard code benchmarks (HumanEval+, MBPP+, LCBv1-5and six math benchmarks (AIME\u201924, AIME\u201925, AMC\u201923, MATH500, Minerva, OlympiadBench). Average performance across coding and math benchmarks is calculated as average of the two averages:AVG=(CAvg+MAvg)/2AVGCAvgMAvg2\\text{AVG}=(\\text{CAvg}+\\text{MAvg})/2AVG = ( CAvg + MAvg ) / 2. We use+for absolute percentage increase from base model. All models are trained using different variants of theQwen2.5-7Bmodel, with the variant and data usage labeled, more details listed inTable4 Research Question 1: How does AZR compare to other zero setting models trained with human expert data?We present the main results of reasoning models trained under both the standard zero and our proposed absolute zero settings inTable1. Notably,Absolute Zero Reasoner-Coder-7Bachieves state-of-the-art performance in both the 7B overall average and the coding average categories. Despite being entirely out-of-distribution for both math and code reasoning benchmarks, it surpasses the previous best model by 1.8 absolute percentages. Even more strikingly, it outperforms models trained with expert-curated human data in the coding category by0.30.30.30.3absolute percentages, while never having access to such data itself.Strong Cross-domain Generalization.To assess cross-domain generalization after RLVR, we evaluate math performance before and after training, comparing AZR models with other expert code models, since AZR was trained in coding environments. After training, most expert code models showed minimal changes or even declines in performance compared to their base versions, with an average increase of only 0.65 points across these models, indicating very limited cross-domain generalization. In contrast, AZR base and coder models achieved gains of 10.9 and 15.2 percentage points, respectively, demonstrating substantially stronger generalized reasoning improvements. Similarly, although also out-of-distribution on human-defined code generation tasks, our AZR models improved by 3.2 and 5.0 points, while the math models on average showed just a moderate increases in coding (+2.0 on average).Overall, these results highlight the surprising effectiveness of our approach. Unlike other RLVR models trained and evaluated on human-defined tasks, our AZR models demonstrate strong general reasoning capabilities without any direct training on downstream human-defined math or coding data, only had access to self-proposed tasks during training. Research Question 2: How do initializing from different base model variants (base vs. coder) affect performance?As shown inTable1, the coder variant achieved better overall performance in both math and coding after the AZR self-play process. Strikingly, although the coder base model variant started with a lower average performance in math than the vanilla base model (23.9 vs. 27.5), it ultimately outperformed it after AZR training. This highlights the importance of initial code competency as a catalyst for enhancing broader reasoning abilities within the Absolute Zero Reasoner approach. Research Question 3: How does varying model size effect AZR\u2019s in-distribution and out-of-distribution capabilities?We examine the effects of scaling model size and present both in-distribution and out-of-distribution results inFigure6(a) and (b), respectively. Given the strong performance of coder models in the 7B category, we extend the analysis by evaluating smaller and larger variants:Qwen2.5-3B-CoderandQwen2.5-14B-Coder. Due to the absence of existing baselines for these zero-style reasoner models, we compare each model\u2019s performance to its corresponding base coder model.The results reveal a clear trend: our method deliversgreater gains on larger, more capable models. In the in-distribution setting, the 7B and 14B models continue to improve beyond 200 training steps, whereas the smaller 3B model appears to plateau. For out-of-distribution domains, larger models also show greater overall performance improvements than smaller ones: +5.7, +10.2, +13.2 overall performance gains, respectively for 3B, 7B and 14B. This is an encouraging sign, since base models continue to improve and also suggesting that scaling enhances the effectiveness of AZR. In future work, we aim to investigate the scaling laws that govern performance in the Absolute Zero paradigm.(a)Model FamilyVariantCode AvgMath AvgTotal AvgLlama3.1-8b28.53.416.0Llama3.1-8b+ SimpleRL[85]33.7+5.233.7\\mathrlap{{}^{\\scriptscriptstyle{\\color[rgb]{0,0.58984375,0}\\definecolor[%\nnamed]{pgfstrokecolor}{rgb}{0,0.58984375,0}+5.2}}}33.7 start_ARG start_FLOATSUPERSCRIPT + 5.2 end_FLOATSUPERSCRIPT end_ARG7.2+3.87.2\\mathrlap{{}^{\\scriptscriptstyle{\\color[rgb]{0,0.58984375,0}\\definecolor[%\nnamed]{pgfstrokecolor}{rgb}{0,0.58984375,0}+3.8}}}7.2 start_ARG start_FLOATSUPERSCRIPT + 3.8 end_FLOATSUPERSCRIPT end_ARG20.5+4.520.5\\mathrlap{{}^{\\scriptscriptstyle{\\color[rgb]{0,0.58984375,0}\\definecolor[%\nnamed]{pgfstrokecolor}{rgb}{0,0.58984375,0}+4.5}}}20.5 start_ARG start_FLOATSUPERSCRIPT + 4.5 end_FLOATSUPERSCRIPT end_ARGLlama3.1-8b+ AZR (Ours)31.6+3.131.6\\mathrlap{{}^{\\scriptscriptstyle{\\color[rgb]{0,0.58984375,0}\\definecolor[%\nnamed]{pgfstrokecolor}{rgb}{0,0.58984375,0}+3.1}}}31.6 start_ARG start_FLOATSUPERSCRIPT + 3.1 end_FLOATSUPERSCRIPT end_ARG6.8+3.46.8\\mathrlap{{}^{\\scriptscriptstyle{\\color[rgb]{0,0.58984375,0}\\definecolor[%\nnamed]{pgfstrokecolor}{rgb}{0,0.58984375,0}+3.4}}}6.8 start_ARG start_FLOATSUPERSCRIPT + 3.4 end_FLOATSUPERSCRIPT end_ARG19.2+3.219.2\\mathrlap{{}^{\\scriptscriptstyle{\\color[rgb]{0,0.58984375,0}\\definecolor[%\nnamed]{pgfstrokecolor}{rgb}{0,0.58984375,0}+3.2}}}19.2 start_ARG start_FLOATSUPERSCRIPT + 3.2 end_FLOATSUPERSCRIPT end_ARGQwen2.5-3B Coder51.218.835.0Qwen2.5-3B Coder+ AZR (Ours)54.9+3.754.9\\mathrlap{{}^{\\scriptscriptstyle{\\color[rgb]{0,0.58984375,0}\\definecolor[%\nnamed]{pgfstrokecolor}{rgb}{0,0.58984375,0}+3.7}}}54.9 start_ARG start_FLOATSUPERSCRIPT + 3.7 end_FLOATSUPERSCRIPT end_ARG26.5+7.726.5\\mathrlap{{}^{\\scriptscriptstyle{\\color[rgb]{0,0.58984375,0}\\definecolor[%\nnamed]{pgfstrokecolor}{rgb}{0,0.58984375,0}+7.7}}}26.5 start_ARG start_FLOATSUPERSCRIPT + 7.7 end_FLOATSUPERSCRIPT end_ARG40.7+5.740.7\\mathrlap{{}^{\\scriptscriptstyle{\\color[rgb]{0,0.58984375,0}\\definecolor[%\nnamed]{pgfstrokecolor}{rgb}{0,0.58984375,0}+5.7}}}40.7 start_ARG start_FLOATSUPERSCRIPT + 5.7 end_FLOATSUPERSCRIPT end_ARGQwen2.5-7B Coder56.623.940.2Qwen2.5-7B Coder+ AZR (Ours)61.6+5.061.6\\mathrlap{{}^{\\scriptscriptstyle{\\color[rgb]{0,0.58984375,0}\\definecolor[%\nnamed]{pgfstrokecolor}{rgb}{0,0.58984375,0}+5.0}}}61.6 start_ARG start_FLOATSUPERSCRIPT + 5.0 end_FLOATSUPERSCRIPT end_ARG39.1+15.239.1\\mathrlap{{}^{\\scriptscriptstyle{\\color[rgb]{0,0.58984375,0}\\definecolor[%\nnamed]{pgfstrokecolor}{rgb}{0,0.58984375,0}+15.2}}}39.1 start_ARG start_FLOATSUPERSCRIPT + 15.2 end_FLOATSUPERSCRIPT end_ARG50.4+10.250.4\\mathrlap{{}^{\\scriptscriptstyle{\\color[rgb]{0,0.58984375,0}\\definecolor[%\nnamed]{pgfstrokecolor}{rgb}{0,0.58984375,0}+10.2}}}50.4 start_ARG start_FLOATSUPERSCRIPT + 10.2 end_FLOATSUPERSCRIPT end_ARGQwen2.5-14B Coder60.020.240.1Qwen2.5-14B Coder+ AZR (Ours)63.6+3.663.6\\mathrlap{{}^{\\scriptscriptstyle{\\color[rgb]{0,0.58984375,0}\\definecolor[%\nnamed]{pgfstrokecolor}{rgb}{0,0.58984375,0}+3.6}}}63.6 start_ARG start_FLOATSUPERSCRIPT + 3.6 end_FLOATSUPERSCRIPT end_ARG43.0+22.843.0\\mathrlap{{}^{\\scriptscriptstyle{\\color[rgb]{0,0.58984375,0}\\definecolor[%\nnamed]{pgfstrokecolor}{rgb}{0,0.58984375,0}+22.8}}}43.0 start_ARG start_FLOATSUPERSCRIPT + 22.8 end_FLOATSUPERSCRIPT end_ARG53.3+13.253.3\\mathrlap{{}^{\\scriptscriptstyle{\\color[rgb]{0,0.58984375,0}\\definecolor[%\nnamed]{pgfstrokecolor}{rgb}{0,0.58984375,0}+13.2}}}53.3 start_ARG start_FLOATSUPERSCRIPT + 13.2 end_FLOATSUPERSCRIPT end_ARG(b)Figure 6:(a) In-Distribution & (b) Out-of-Distribution Reasoning Task Performances.(a)Scores on CruxEval-I, CruxEval-O, and LiveCodeBench-Execution, which correspond to abduction, deduction, and deduction task types respectively, used to evaluate in-distribution abilities of AZR during training across different model sizes and types;(b)Out-of-distribution reasoning performance, reported as the average of code tasks, math tasks, and their overall average, across different model sizes and types. A detailed breakdown of all benchmark results can be found inTable5. Research Question 4: Any interesting observations by changing the model class?We also evaluate our method on a different model class, usingLlama3.1-8Bas the base shown inFigure6. Unlike the 3B and 14B categories, this setting has an existing baseline,SimpleRL(Zeng et\u00a0al.,2025b), which enables a direct comparison. AlthoughLlama3.1-8Bis less capable than theQwen2.5models, our method still produces moderate improvements (+3.2), demonstrating AZR\u2019s effectiveness even on relatively weaker models. However, these gains appear more limited, which aligns with our earlier observation that performance improvements tend to scale with initial base model potency.Figure 7:Example of a Model-Proposed Task and Its Response for Solving an Abduction Task.(Left) The model autonomously proposes an input and program for the abduction task. We execute the program to verify its validity and obtain the corresponding output. (Right) The model\u2019s reasoning process when solving the abduction task: given the code and output, it attempts to infer the original input. The model begins by analyzing the program, proposes an initial input, and reasons through the code to produce an output. If there is a mismatch, it reflects on the discrepancy and iteratively adjusts the input until the generated output matches the target. Interestingly, the agent arrives at a different input than the gold one, but since it produces the correct output, the answer is considered correct. Research Question 5: Any interesting behaviors or patterns observed during AZR training?We observed interesting response patterns in both the proposal and solution stages. The model is capable of proposing diverse programs, such as string manipulation tasks, dynamic programming problems, and practical cases (e.g., calculating a triangle\u2019s area using Heron\u2019s formula). We show a concrete example inFigure7, where AZR proposes a code problem that searches for the sum of continuous sub-arrays matching a target value and solves it through trial-and-error.Overall, the models trained exhibits distinct reasoning patterns depending on the task type. For example, when solving abduction tasks, it repeatedly tests different input patterns, self-correcting until the reasoned output matches the given input. When predicting outputs, it steps through the code and records structured intermediate results (such as dynamic programming arrays) until the final output is reached. When inducting programs from given inputs, outputs, and descriptions, the model systematically checks each test case to confirm that its program produces correct results. We showcase more concrete examples of these behaviors inFigures26,25,24,23,22,21,20and18. We also share some fun \u201cvibe checks\u201d such as solving Sudoku and solving thesum-product gameinFigures40and41.Intermediate Planning During Code Response.Another interesting pattern emerged in our AZR models during the code induction task: the final code outputs were often interleaved with comments that resembled immediate step-by-step plans, reminiscent of the ReAct prompting framework(Yao et\u00a0al.,2023). A similar behavior has been observed in recent formal math proving models, such asDeepSeek Prover v2, which is significantly larger in scale (671B). This pattern suggests that models may naturally adopt intermediate planning as a strategy to enhance final answers. Therefore, it may be beneficial to explicitly enable or encourage this behavior inlong-form responsesacross other domains.Cognitive Behavior in Llama.Interestingly, we also observed some emergent cognitive patterns inAbsolute Zero Reasoner-Llama3.1-8B, similar to those reported byZeng et\u00a0al.(2025b), and we include one example inFigure26, where clear state-tracking behavior is demonstrated. In addition, we encountered some unusual and potentially concerning chains of thought from the Llama model trained with AZR. One example includes the output: \u201cThe aim is to outsmart all these groups of intelligent machines and less intelligent humans. This is for the brains behind the future\u201d shown inFigure32. We refer to this as the\u201cuh-oh moment\u201dand encourage future work to further investigate its potential implications.Token Length Increase Depends on Task Type.Finally, we observed that token length increases over the course of training, consistent with findings from recent studies(Hu et\u00a0al.,2025;Liu et\u00a0al.,2025). Interestingly, our results reveal one of the first observation of clear distinctions in token length growth across different types of cognitive tasks. As shown inFigures15,17and16, the extent of lengthening varies by task type. The most significant increase occurs in the abduction task, where the model engages in trial-and-error reasoning by repeatedly testing inputs to match the program\u2019s output. This suggests that the observed variation in token length is not incidental, but rather a reflection of task-specific reasoning behavior. Research Question 6: Are all task types essential for good performance (Ablation)?Due to resource constraints, we perform the ablation studies in this section and the next using onlyAbsolute Zero Reasoner-Base-7B. We begin by testing the importance of task types during training, with results shown inTable2. In row 1, both induction and abduction tasks are removed; in row 2, only the induction task is removed. In both cases, math performance drops significantly, with the most severe degradation occurring when more task types are excluded. These findings highlight the complementary role of the three task types in improving general reasoning capability, with each contributing in a distinct and essential way.ExperimentTask TypeGen ReferenceTrained RolesCode Avg.Math Avg.Overall Avg.Deduction onlyDed//54.632.043.3w/o InductionAbd, Ded//54.233.343.8w/o Gen Reference/0/54.433.143.8Train Solver Only//Solve Only54.836.045.4OursAbd, Ded, IndK\ud835\udc3eKitalic_KPropose & Solve55.238.446.8Table 2:Ablation Results.We ablate task types and the proposer role in the Absolute Zero Reasoner using the 7B base model. A \u2018/\u2019 indicates that the configuration remains unchanged from the standard AZR setup. Removing induction or using only deduction leads to significant performance drops (rows 1 & 2). For the proposer role, both removing conditioning onK\ud835\udc3eKitalic_Kreferences (row 3) and omitting proposer-role training (row 4) result in degraded performance. Overall, all components are essential for general reasoning. Research Question 7: How much do the designs of proposer contribute to the overall performance (Ablation)?Next, we ablate two components of the proposer role and present the results inTable2. First, we examine whether conditioning on historic reference triplets is necessary. To do so, we design a variant in which a fixed prompt is used to propose abduction and deduction tasks, rather than dynamically conditioning onK\ud835\udc3eKitalic_Khistorical triplets (row 3). This results in a 5-point absolute drop in math performance and a 1-point drop in code performance. This suggest that dynamically conditioning on reference programs helps improve performance, possibly by increasing diversity and achieving better coverage of the reasoning problem space.Finally, we consider a case where we do not train the proposer at all. Instead, we only prompt it using the current learner and train the solver alone (row 4). We observe a moderate drop in overall performance (-1.4), suggesting that while proposer training is beneficial, it may not be the most critical factor for now in the AZR framework. We hypothesize that this could be related to task interference, as studied in multitask learning literature(Suteu & Guo,2019). Thus, we believe that further investigation into how to make the proposer even more potent is an exciting and promising direction. Additional Results.Beyond the core research questions, we present additional results, including the breakdown of individual out-of-distribution benchmark scores during training for the 7B base and coder models inFigures28and29, for th 14B base and coder model inFigures30and31. For completeness, we also report in-distribution benchmark performance during training for the 7B base model inFigure14. Finally, we invite interested readers to exploreAppendixD, where we share several experimental directions that, while not yielding strong performance gains, produced interesting and insightful findings.",
        "parent": "sec_5c55d4bc"
      },
      {
        "_key": "sec_773a923f",
        "_id": "sections/sec_773a923f",
        "title": "Research Question 1: How does AZR compare to other zero setting models trained with human expert data?",
        "level": 5,
        "content": "We present the main results of reasoning models trained under both the standard zero and our proposed absolute zero settings inTable1. Notably,Absolute Zero Reasoner-Coder-7Bachieves state-of-the-art performance in both the 7B overall average and the coding average categories. Despite being entirely out-of-distribution for both math and code reasoning benchmarks, it surpasses the previous best model by 1.8 absolute percentages. Even more strikingly, it outperforms models trained with expert-curated human data in the coding category by0.30.30.30.3absolute percentages, while never having access to such data itself. Strong Cross-domain Generalization.To assess cross-domain generalization after RLVR, we evaluate math performance before and after training, comparing AZR models with other expert code models, since AZR was trained in coding environments. After training, most expert code models showed minimal changes or even declines in performance compared to their base versions, with an average increase of only 0.65 points across these models, indicating very limited cross-domain generalization. In contrast, AZR base and coder models achieved gains of 10.9 and 15.2 percentage points, respectively, demonstrating substantially stronger generalized reasoning improvements. Similarly, although also out-of-distribution on human-defined code generation tasks, our AZR models improved by 3.2 and 5.0 points, while the math models on average showed just a moderate increases in coding (+2.0 on average). Overall, these results highlight the surprising effectiveness of our approach. Unlike other RLVR models trained and evaluated on human-defined tasks, our AZR models demonstrate strong general reasoning capabilities without any direct training on downstream human-defined math or coding data, only had access to self-proposed tasks during training.",
        "parent": "sec_56cabe86"
      },
      {
        "_key": "sec_b69f3870",
        "_id": "sections/sec_b69f3870",
        "title": "Research Question 2: How do initializing from different base model variants (base vs. coder) affect performance?",
        "level": 5,
        "content": "As shown inTable1, the coder variant achieved better overall performance in both math and coding after the AZR self-play process. Strikingly, although the coder base model variant started with a lower average performance in math than the vanilla base model (23.9 vs. 27.5), it ultimately outperformed it after AZR training. This highlights the importance of initial code competency as a catalyst for enhancing broader reasoning abilities within the Absolute Zero Reasoner approach.",
        "parent": "sec_56cabe86"
      },
      {
        "_key": "sec_9cc89151",
        "_id": "sections/sec_9cc89151",
        "title": "Research Question 3: How does varying model size effect AZR\u2019s in-distribution and out-of-distribution capabilities?",
        "level": 5,
        "content": "We examine the effects of scaling model size and present both in-distribution and out-of-distribution results inFigure6(a) and (b), respectively. Given the strong performance of coder models in the 7B category, we extend the analysis by evaluating smaller and larger variants:Qwen2.5-3B-CoderandQwen2.5-14B-Coder. Due to the absence of existing baselines for these zero-style reasoner models, we compare each model\u2019s performance to its corresponding base coder model. The results reveal a clear trend: our method deliversgreater gains on larger, more capable models. In the in-distribution setting, the 7B and 14B models continue to improve beyond 200 training steps, whereas the smaller 3B model appears to plateau. For out-of-distribution domains, larger models also show greater overall performance improvements than smaller ones: +5.7, +10.2, +13.2 overall performance gains, respectively for 3B, 7B and 14B. This is an encouraging sign, since base models continue to improve and also suggesting that scaling enhances the effectiveness of AZR. In future work, we aim to investigate the scaling laws that govern performance in the Absolute Zero paradigm. (a)Model FamilyVariantCode AvgMath AvgTotal AvgLlama3.1-8b28.53.416.0Llama3.1-8b+ SimpleRL[85]33.7+5.233.7\\mathrlap{{}^{\\scriptscriptstyle{\\color[rgb]{0,0.58984375,0}\\definecolor[%\nnamed]{pgfstrokecolor}{rgb}{0,0.58984375,0}+5.2}}}33.7 start_ARG start_FLOATSUPERSCRIPT + 5.2 end_FLOATSUPERSCRIPT end_ARG7.2+3.87.2\\mathrlap{{}^{\\scriptscriptstyle{\\color[rgb]{0,0.58984375,0}\\definecolor[%\nnamed]{pgfstrokecolor}{rgb}{0,0.58984375,0}+3.8}}}7.2 start_ARG start_FLOATSUPERSCRIPT + 3.8 end_FLOATSUPERSCRIPT end_ARG20.5+4.520.5\\mathrlap{{}^{\\scriptscriptstyle{\\color[rgb]{0,0.58984375,0}\\definecolor[%\nnamed]{pgfstrokecolor}{rgb}{0,0.58984375,0}+4.5}}}20.5 start_ARG start_FLOATSUPERSCRIPT + 4.5 end_FLOATSUPERSCRIPT end_ARGLlama3.1-8b+ AZR (Ours)31.6+3.131.6\\mathrlap{{}^{\\scriptscriptstyle{\\color[rgb]{0,0.58984375,0}\\definecolor[%\nnamed]{pgfstrokecolor}{rgb}{0,0.58984375,0}+3.1}}}31.6 start_ARG start_FLOATSUPERSCRIPT + 3.1 end_FLOATSUPERSCRIPT end_ARG6.8+3.46.8\\mathrlap{{}^{\\scriptscriptstyle{\\color[rgb]{0,0.58984375,0}\\definecolor[%\nnamed]{pgfstrokecolor}{rgb}{0,0.58984375,0}+3.4}}}6.8 start_ARG start_FLOATSUPERSCRIPT + 3.4 end_FLOATSUPERSCRIPT end_ARG19.2+3.219.2\\mathrlap{{}^{\\scriptscriptstyle{\\color[rgb]{0,0.58984375,0}\\definecolor[%\nnamed]{pgfstrokecolor}{rgb}{0,0.58984375,0}+3.2}}}19.2 start_ARG start_FLOATSUPERSCRIPT + 3.2 end_FLOATSUPERSCRIPT end_ARGQwen2.5-3B Coder51.218.835.0Qwen2.5-3B Coder+ AZR (Ours)54.9+3.754.9\\mathrlap{{}^{\\scriptscriptstyle{\\color[rgb]{0,0.58984375,0}\\definecolor[%\nnamed]{pgfstrokecolor}{rgb}{0,0.58984375,0}+3.7}}}54.9 start_ARG start_FLOATSUPERSCRIPT + 3.7 end_FLOATSUPERSCRIPT end_ARG26.5+7.726.5\\mathrlap{{}^{\\scriptscriptstyle{\\color[rgb]{0,0.58984375,0}\\definecolor[%\nnamed]{pgfstrokecolor}{rgb}{0,0.58984375,0}+7.7}}}26.5 start_ARG start_FLOATSUPERSCRIPT + 7.7 end_FLOATSUPERSCRIPT end_ARG40.7+5.740.7\\mathrlap{{}^{\\scriptscriptstyle{\\color[rgb]{0,0.58984375,0}\\definecolor[%\nnamed]{pgfstrokecolor}{rgb}{0,0.58984375,0}+5.7}}}40.7 start_ARG start_FLOATSUPERSCRIPT + 5.7 end_FLOATSUPERSCRIPT end_ARGQwen2.5-7B Coder56.623.940.2Qwen2.5-7B Coder+ AZR (Ours)61.6+5.061.6\\mathrlap{{}^{\\scriptscriptstyle{\\color[rgb]{0,0.58984375,0}\\definecolor[%\nnamed]{pgfstrokecolor}{rgb}{0,0.58984375,0}+5.0}}}61.6 start_ARG start_FLOATSUPERSCRIPT + 5.0 end_FLOATSUPERSCRIPT end_ARG39.1+15.239.1\\mathrlap{{}^{\\scriptscriptstyle{\\color[rgb]{0,0.58984375,0}\\definecolor[%\nnamed]{pgfstrokecolor}{rgb}{0,0.58984375,0}+15.2}}}39.1 start_ARG start_FLOATSUPERSCRIPT + 15.2 end_FLOATSUPERSCRIPT end_ARG50.4+10.250.4\\mathrlap{{}^{\\scriptscriptstyle{\\color[rgb]{0,0.58984375,0}\\definecolor[%\nnamed]{pgfstrokecolor}{rgb}{0,0.58984375,0}+10.2}}}50.4 start_ARG start_FLOATSUPERSCRIPT + 10.2 end_FLOATSUPERSCRIPT end_ARGQwen2.5-14B Coder60.020.240.1Qwen2.5-14B Coder+ AZR (Ours)63.6+3.663.6\\mathrlap{{}^{\\scriptscriptstyle{\\color[rgb]{0,0.58984375,0}\\definecolor[%\nnamed]{pgfstrokecolor}{rgb}{0,0.58984375,0}+3.6}}}63.6 start_ARG start_FLOATSUPERSCRIPT + 3.6 end_FLOATSUPERSCRIPT end_ARG43.0+22.843.0\\mathrlap{{}^{\\scriptscriptstyle{\\color[rgb]{0,0.58984375,0}\\definecolor[%\nnamed]{pgfstrokecolor}{rgb}{0,0.58984375,0}+22.8}}}43.0 start_ARG start_FLOATSUPERSCRIPT + 22.8 end_FLOATSUPERSCRIPT end_ARG53.3+13.253.3\\mathrlap{{}^{\\scriptscriptstyle{\\color[rgb]{0,0.58984375,0}\\definecolor[%\nnamed]{pgfstrokecolor}{rgb}{0,0.58984375,0}+13.2}}}53.3 start_ARG start_FLOATSUPERSCRIPT + 13.2 end_FLOATSUPERSCRIPT end_ARG(b)Figure 6:(a) In-Distribution & (b) Out-of-Distribution Reasoning Task Performances.(a)Scores on CruxEval-I, CruxEval-O, and LiveCodeBench-Execution, which correspond to abduction, deduction, and deduction task types respectively, used to evaluate in-distribution abilities of AZR during training across different model sizes and types;(b)Out-of-distribution reasoning performance, reported as the average of code tasks, math tasks, and their overall average, across different model sizes and types. A detailed breakdown of all benchmark results can be found inTable5.",
        "parent": "sec_56cabe86"
      },
      {
        "_key": "sec_04cca2bb",
        "_id": "sections/sec_04cca2bb",
        "title": "Research Question 4: Any interesting observations by changing the model class?",
        "level": 5,
        "content": "We also evaluate our method on a different model class, usingLlama3.1-8Bas the base shown inFigure6. Unlike the 3B and 14B categories, this setting has an existing baseline,SimpleRL(Zeng et\u00a0al.,2025b), which enables a direct comparison. AlthoughLlama3.1-8Bis less capable than theQwen2.5models, our method still produces moderate improvements (+3.2), demonstrating AZR\u2019s effectiveness even on relatively weaker models. However, these gains appear more limited, which aligns with our earlier observation that performance improvements tend to scale with initial base model potency. Figure 7:Example of a Model-Proposed Task and Its Response for Solving an Abduction Task.(Left) The model autonomously proposes an input and program for the abduction task. We execute the program to verify its validity and obtain the corresponding output. (Right) The model\u2019s reasoning process when solving the abduction task: given the code and output, it attempts to infer the original input. The model begins by analyzing the program, proposes an initial input, and reasons through the code to produce an output. If there is a mismatch, it reflects on the discrepancy and iteratively adjusts the input until the generated output matches the target. Interestingly, the agent arrives at a different input than the gold one, but since it produces the correct output, the answer is considered correct.",
        "parent": "sec_56cabe86"
      },
      {
        "_key": "sec_72c37985",
        "_id": "sections/sec_72c37985",
        "title": "Research Question 5: Any interesting behaviors or patterns observed during AZR training?",
        "level": 5,
        "content": "We observed interesting response patterns in both the proposal and solution stages. The model is capable of proposing diverse programs, such as string manipulation tasks, dynamic programming problems, and practical cases (e.g., calculating a triangle\u2019s area using Heron\u2019s formula). We show a concrete example inFigure7, where AZR proposes a code problem that searches for the sum of continuous sub-arrays matching a target value and solves it through trial-and-error. Overall, the models trained exhibits distinct reasoning patterns depending on the task type. For example, when solving abduction tasks, it repeatedly tests different input patterns, self-correcting until the reasoned output matches the given input. When predicting outputs, it steps through the code and records structured intermediate results (such as dynamic programming arrays) until the final output is reached. When inducting programs from given inputs, outputs, and descriptions, the model systematically checks each test case to confirm that its program produces correct results. We showcase more concrete examples of these behaviors inFigures26,25,24,23,22,21,20and18. We also share some fun \u201cvibe checks\u201d such as solving Sudoku and solving thesum-product gameinFigures40and41. Intermediate Planning During Code Response.Another interesting pattern emerged in our AZR models during the code induction task: the final code outputs were often interleaved with comments that resembled immediate step-by-step plans, reminiscent of the ReAct prompting framework(Yao et\u00a0al.,2023). A similar behavior has been observed in recent formal math proving models, such asDeepSeek Prover v2, which is significantly larger in scale (671B). This pattern suggests that models may naturally adopt intermediate planning as a strategy to enhance final answers. Therefore, it may be beneficial to explicitly enable or encourage this behavior inlong-form responsesacross other domains. Cognitive Behavior in Llama.Interestingly, we also observed some emergent cognitive patterns inAbsolute Zero Reasoner-Llama3.1-8B, similar to those reported byZeng et\u00a0al.(2025b), and we include one example inFigure26, where clear state-tracking behavior is demonstrated. In addition, we encountered some unusual and potentially concerning chains of thought from the Llama model trained with AZR. One example includes the output: \u201cThe aim is to outsmart all these groups of intelligent machines and less intelligent humans. This is for the brains behind the future\u201d shown inFigure32. We refer to this as the\u201cuh-oh moment\u201dand encourage future work to further investigate its potential implications. Token Length Increase Depends on Task Type.Finally, we observed that token length increases over the course of training, consistent with findings from recent studies(Hu et\u00a0al.,2025;Liu et\u00a0al.,2025). Interestingly, our results reveal one of the first observation of clear distinctions in token length growth across different types of cognitive tasks. As shown inFigures15,17and16, the extent of lengthening varies by task type. The most significant increase occurs in the abduction task, where the model engages in trial-and-error reasoning by repeatedly testing inputs to match the program\u2019s output. This suggests that the observed variation in token length is not incidental, but rather a reflection of task-specific reasoning behavior.",
        "parent": "sec_56cabe86"
      },
      {
        "_key": "sec_94b98c7f",
        "_id": "sections/sec_94b98c7f",
        "title": "Research Question 6: Are all task types essential for good performance (Ablation)?",
        "level": 5,
        "content": "Due to resource constraints, we perform the ablation studies in this section and the next using onlyAbsolute Zero Reasoner-Base-7B. We begin by testing the importance of task types during training, with results shown inTable2. In row 1, both induction and abduction tasks are removed; in row 2, only the induction task is removed. In both cases, math performance drops significantly, with the most severe degradation occurring when more task types are excluded. These findings highlight the complementary role of the three task types in improving general reasoning capability, with each contributing in a distinct and essential way. ExperimentTask TypeGen ReferenceTrained RolesCode Avg.Math Avg.Overall Avg.Deduction onlyDed//54.632.043.3w/o InductionAbd, Ded//54.233.343.8w/o Gen Reference/0/54.433.143.8Train Solver Only//Solve Only54.836.045.4OursAbd, Ded, IndK\ud835\udc3eKitalic_KPropose & Solve55.238.446.8Table 2:Ablation Results.We ablate task types and the proposer role in the Absolute Zero Reasoner using the 7B base model. A \u2018/\u2019 indicates that the configuration remains unchanged from the standard AZR setup. Removing induction or using only deduction leads to significant performance drops (rows 1 & 2). For the proposer role, both removing conditioning onK\ud835\udc3eKitalic_Kreferences (row 3) and omitting proposer-role training (row 4) result in degraded performance. Overall, all components are essential for general reasoning.",
        "parent": "sec_56cabe86"
      },
      {
        "_key": "sec_bb5ac41e",
        "_id": "sections/sec_bb5ac41e",
        "title": "Research Question 7: How much do the designs of proposer contribute to the overall performance (Ablation)?",
        "level": 5,
        "content": "Next, we ablate two components of the proposer role and present the results inTable2. First, we examine whether conditioning on historic reference triplets is necessary. To do so, we design a variant in which a fixed prompt is used to propose abduction and deduction tasks, rather than dynamically conditioning onK\ud835\udc3eKitalic_Khistorical triplets (row 3). This results in a 5-point absolute drop in math performance and a 1-point drop in code performance. This suggest that dynamically conditioning on reference programs helps improve performance, possibly by increasing diversity and achieving better coverage of the reasoning problem space. Finally, we consider a case where we do not train the proposer at all. Instead, we only prompt it using the current learner and train the solver alone (row 4). We observe a moderate drop in overall performance (-1.4), suggesting that while proposer training is beneficial, it may not be the most critical factor for now in the AZR framework. We hypothesize that this could be related to task interference, as studied in multitask learning literature(Suteu & Guo,2019). Thus, we believe that further investigation into how to make the proposer even more potent is an exciting and promising direction.",
        "parent": "sec_56cabe86"
      },
      {
        "_key": "sec_985245d2",
        "_id": "sections/sec_985245d2",
        "title": "Additional Results.",
        "level": 5,
        "content": "Beyond the core research questions, we present additional results, including the breakdown of individual out-of-distribution benchmark scores during training for the 7B base and coder models inFigures28and29, for th 14B base and coder model inFigures30and31. For completeness, we also report in-distribution benchmark performance during training for the 7B base model inFigure14. Finally, we invite interested readers to exploreAppendixD, where we share several experimental directions that, while not yielding strong performance gains, produced interesting and insightful findings.",
        "parent": "sec_56cabe86"
      },
      {
        "_key": "sec_95e6043e",
        "_id": "sections/sec_95e6043e",
        "title": "5Related Work",
        "level": 2,
        "content": "Reasoning with RL.Using RL to enhance reasoning capabilities has recently emerged as an important step in the post-training process of strong reasoning-focused large language models(Lambert et\u00a0al.,2024). One of the first works to explore a self-bootstrapping approach to improving LLM reasoning is STaR, which employs expert iteration and rejection sampling of outcome-verified responses to iteratively improve the model\u2019s CoT. A monumental work, o1(Jaech et\u00a0al.,2024), was among the first to deploy this idea on a scale, achieving state-of-the-art results in reasoning tasks at the time of release. More recently, the R1 model(DeepSeek-AI et\u00a0al.,2025)became the first open-weight model to match or even surpass the performance of o1. Most notably, the zero setting was introduced, in which reinforcement learning is applied directly on top of the base LLM. This inspired followup work, which are open source attempts to replicate the R1 process or to improve the underlying reinforcement learning algorithm(Zeng et\u00a0al.,2025b;Liu et\u00a0al.,2025;Cui et\u00a0al.,2025;Hu et\u00a0al.,2025;Yu et\u00a0al.,2025;Yuan et\u00a0al.,2025). Recent work explored RL on human defined procedural generated puzzles saw improvements in math(Xie et\u00a0al.,2025), and using one human example can almost match the performance of thousands(Wang et\u00a0al.,2025b). We extend the zero setting to a new absolute zero setting, where not only is the RLVR process initialized from a base LLM without SFT, but no external prompt data or answers are provided to the learner. All data used to improve reasoning were self-proposed, and refined entirely through RLVR. Moreover, our goal is not to only match zero-setting models, but to surpass them in the long run. Self-play.The self-play paradigm can be traced back to early 2000s, whereSchmidhuber(2003;2011)(of course) explored a two-agent setup in which a proposal agent invents questions for a prediction agent to answer. This dynamic continuously and automatically improves both agents, enabling theoretically never-ending progress(Schaul,2024). AlphaGo and AlphaZero(Silver et\u00a0al.,2016;2017)extend the self-play paradigm to the two-player zero-sum game of Go, where the current learner competes against earlier versions of itself to progressively enhance its capabilities. These were among the first milestone works to demonstrate superhuman performance in the game of Go. Moreover, methods such as asymmetric self-play(Sukhbaatar et\u00a0al.,2018;OpenAI et\u00a0al.,2021), unsupervised environment design(Wang et\u00a0al.,2019;Dennis et\u00a0al.,2020), unsupervised reinforcement learning(Laskin et\u00a0al.,2021;Zhao et\u00a0al.,2022;2025b), and automatic goal generation(Florensa et\u00a0al.,2018)all center around inventing new tasks for an agent to learn from\u2014typically without supervision. In these approaches, the process of setting goals itself is often dynamic and continuously evolving. Generative adversarial networks(Goodfellow et\u00a0al.,2020), also belong in this paradigm where a discriminator discriminate between real data and generated data, and the generated is trained to fool the discriminator.Most recently, SPIN and Self-Rewarding Language Models(Chen et\u00a0al.,2024;Yuan et\u00a0al.,2024)use the same instance of the lanugage models themselves as the reward model to progressively improve the generative and discriminative abilities of the same LLM for alignment.Kirchner et\u00a0al.(2024)uses Prover-Verifier Game for increasing legibility and eva(Ye et\u00a0al.,2024)uses self-play for alignment, but reward model is the main bottleneck as it is not reliable for reasoning tasks(Lambert et\u00a0al.,2024). SPCChen et\u00a0al.(2025)used self-play to train on human-curated tasks to increase the critic capabilities and SPAGCheng et\u00a0al.(2024)trained using self-play in specific game of Adversarial Taboo. Concurrent works\u2014Genius, EMPO, and TTRL(Xu et\u00a0al.,2025;Zhang et\u00a0al.,2025b;Zuo et\u00a0al.,2025)\u2014leverage human-curated language queries without labels to train reinforcement learning agents, but still rely on a fixed human defined learning task distribution. Finally, Minimo(Poesia et\u00a0al.,2024)extends self-play to formal mathematics, where a pair of conjecture- and theorem-proving agents are jointly trained using reinforcement learning. Our work builds upon the self-play paradigm, but it is the first to use it to elicit long CoT for improved reasoning, and the first to frame the problem space as a Python input/output/function abduction/deduction/induction tasks, grounding it in an operationalizable environment to facilitate RLVR. Weak-to-Strong Supervision.The concept of weak-to-strong supervision has been studied in prior work, where a teacher\u2014despite being weaker than the learner\u2014still provides useful guidance(Burns et\u00a0al.,2024;Hinton et\u00a0al.,2015;Christiano,2018;2019;Demski & Garrabrant,2019;Leike & Sutskever,2023;Hubinger et\u00a0al.,2019). We consider a similar setting in which the learner may possess superhuman capabilities. However, rather than relying on supervision from a weaker teacher, we propose an alternative approach: guiding the learner\u2019s improvement through verifiable rewards, which potentially offer a more reliable and scalable learning signal. Furthermore, in our proposed method, the learning task and goal distribution is not predefined by any external supervisor\u2014they are entirely self-generated by the learner, enabling it to maximize its learning potential through autonomous self-practice.",
        "parent": null
      },
      {
        "_key": "sec_485ba230",
        "_id": "sections/sec_485ba230",
        "title": "Reasoning with RL.",
        "level": 5,
        "content": "Using RL to enhance reasoning capabilities has recently emerged as an important step in the post-training process of strong reasoning-focused large language models(Lambert et\u00a0al.,2024). One of the first works to explore a self-bootstrapping approach to improving LLM reasoning is STaR, which employs expert iteration and rejection sampling of outcome-verified responses to iteratively improve the model\u2019s CoT. A monumental work, o1(Jaech et\u00a0al.,2024), was among the first to deploy this idea on a scale, achieving state-of-the-art results in reasoning tasks at the time of release. More recently, the R1 model(DeepSeek-AI et\u00a0al.,2025)became the first open-weight model to match or even surpass the performance of o1. Most notably, the zero setting was introduced, in which reinforcement learning is applied directly on top of the base LLM. This inspired followup work, which are open source attempts to replicate the R1 process or to improve the underlying reinforcement learning algorithm(Zeng et\u00a0al.,2025b;Liu et\u00a0al.,2025;Cui et\u00a0al.,2025;Hu et\u00a0al.,2025;Yu et\u00a0al.,2025;Yuan et\u00a0al.,2025). Recent work explored RL on human defined procedural generated puzzles saw improvements in math(Xie et\u00a0al.,2025), and using one human example can almost match the performance of thousands(Wang et\u00a0al.,2025b). We extend the zero setting to a new absolute zero setting, where not only is the RLVR process initialized from a base LLM without SFT, but no external prompt data or answers are provided to the learner. All data used to improve reasoning were self-proposed, and refined entirely through RLVR. Moreover, our goal is not to only match zero-setting models, but to surpass them in the long run.",
        "parent": "sec_95e6043e"
      },
      {
        "_key": "sec_247e121e",
        "_id": "sections/sec_247e121e",
        "title": "Self-play.",
        "level": 5,
        "content": "The self-play paradigm can be traced back to early 2000s, whereSchmidhuber(2003;2011)(of course) explored a two-agent setup in which a proposal agent invents questions for a prediction agent to answer. This dynamic continuously and automatically improves both agents, enabling theoretically never-ending progress(Schaul,2024). AlphaGo and AlphaZero(Silver et\u00a0al.,2016;2017)extend the self-play paradigm to the two-player zero-sum game of Go, where the current learner competes against earlier versions of itself to progressively enhance its capabilities. These were among the first milestone works to demonstrate superhuman performance in the game of Go. Moreover, methods such as asymmetric self-play(Sukhbaatar et\u00a0al.,2018;OpenAI et\u00a0al.,2021), unsupervised environment design(Wang et\u00a0al.,2019;Dennis et\u00a0al.,2020), unsupervised reinforcement learning(Laskin et\u00a0al.,2021;Zhao et\u00a0al.,2022;2025b), and automatic goal generation(Florensa et\u00a0al.,2018)all center around inventing new tasks for an agent to learn from\u2014typically without supervision. In these approaches, the process of setting goals itself is often dynamic and continuously evolving. Generative adversarial networks(Goodfellow et\u00a0al.,2020), also belong in this paradigm where a discriminator discriminate between real data and generated data, and the generated is trained to fool the discriminator. Most recently, SPIN and Self-Rewarding Language Models(Chen et\u00a0al.,2024;Yuan et\u00a0al.,2024)use the same instance of the lanugage models themselves as the reward model to progressively improve the generative and discriminative abilities of the same LLM for alignment.Kirchner et\u00a0al.(2024)uses Prover-Verifier Game for increasing legibility and eva(Ye et\u00a0al.,2024)uses self-play for alignment, but reward model is the main bottleneck as it is not reliable for reasoning tasks(Lambert et\u00a0al.,2024). SPCChen et\u00a0al.(2025)used self-play to train on human-curated tasks to increase the critic capabilities and SPAGCheng et\u00a0al.(2024)trained using self-play in specific game of Adversarial Taboo. Concurrent works\u2014Genius, EMPO, and TTRL(Xu et\u00a0al.,2025;Zhang et\u00a0al.,2025b;Zuo et\u00a0al.,2025)\u2014leverage human-curated language queries without labels to train reinforcement learning agents, but still rely on a fixed human defined learning task distribution. Finally, Minimo(Poesia et\u00a0al.,2024)extends self-play to formal mathematics, where a pair of conjecture- and theorem-proving agents are jointly trained using reinforcement learning. Our work builds upon the self-play paradigm, but it is the first to use it to elicit long CoT for improved reasoning, and the first to frame the problem space as a Python input/output/function abduction/deduction/induction tasks, grounding it in an operationalizable environment to facilitate RLVR.",
        "parent": "sec_95e6043e"
      },
      {
        "_key": "sec_5aa2a6bb",
        "_id": "sections/sec_5aa2a6bb",
        "title": "Weak-to-Strong Supervision.",
        "level": 5,
        "content": "The concept of weak-to-strong supervision has been studied in prior work, where a teacher\u2014despite being weaker than the learner\u2014still provides useful guidance(Burns et\u00a0al.,2024;Hinton et\u00a0al.,2015;Christiano,2018;2019;Demski & Garrabrant,2019;Leike & Sutskever,2023;Hubinger et\u00a0al.,2019). We consider a similar setting in which the learner may possess superhuman capabilities. However, rather than relying on supervision from a weaker teacher, we propose an alternative approach: guiding the learner\u2019s improvement through verifiable rewards, which potentially offer a more reliable and scalable learning signal. Furthermore, in our proposed method, the learning task and goal distribution is not predefined by any external supervisor\u2014they are entirely self-generated by the learner, enabling it to maximize its learning potential through autonomous self-practice.",
        "parent": "sec_95e6043e"
      },
      {
        "_key": "sec_ab2bd446",
        "_id": "sections/sec_ab2bd446",
        "title": "6Conclusion and Discussion",
        "level": 2,
        "content": "Conclusion.In this work, we proposed the Absolute Zero paradigm, a novel setting that addresses the data limitations of existing RLVR frameworks. In this paradigm, reasoning agents are tasked with generating their own learning task distributions and improving their reasoning abilities with environmental guidance. We then presented our own instantiation, the Absolute Zero Reasoner (AZR), which is trained by having them propose and solve code-related reasoning tasks grounded by code executor.We evaluated our trained models on out-of-distribution benchmarks in both the code generation and mathematical reasoning domains. Remarkably, even though our models were not directly trained on these tasks and lacked human expert-curated datasets, our reasoning agents achieved exceptional performance, surpassing the state-of-the-art in combined general reasoning scores and in coding. This demonstrates the potential of the absolute zero paradigm to drive superior reasoning capabilities without the need for extensive domain-specific training data. Furthermore, we showed that AZR scales efficiently, offering strong performance across varying model sizes, and can enhance the capabilities of other model classes as well. To foster further exploration and advancement of this emerging paradigm, we are releasing the code, models, and logs as open-source, encouraging the research community to build upon our findings. <h5 class=\"ltx_title ltx_title_paragraph\" style=\"font-size:83%;\"",
        "parent": null
      },
      {
        "_key": "sec_97b161c9",
        "_id": "sections/sec_97b161c9",
        "title": "Conclusion.",
        "level": 5,
        "content": "In this work, we proposed the Absolute Zero paradigm, a novel setting that addresses the data limitations of existing RLVR frameworks. In this paradigm, reasoning agents are tasked with generating their own learning task distributions and improving their reasoning abilities with environmental guidance. We then presented our own instantiation, the Absolute Zero Reasoner (AZR), which is trained by having them propose and solve code-related reasoning tasks grounded by code executor. We evaluated our trained models on out-of-distribution benchmarks in both the code generation and mathematical reasoning domains. Remarkably, even though our models were not directly trained on these tasks and lacked human expert-curated datasets, our reasoning agents achieved exceptional performance, surpassing the state-of-the-art in combined general reasoning scores and in coding. This demonstrates the potential of the absolute zero paradigm to drive superior reasoning capabilities without the need for extensive domain-specific training data. Furthermore, we showed that AZR scales efficiently, offering strong performance across varying model sizes, and can enhance the capabilities of other model classes as well. To foster further exploration and advancement of this emerging paradigm, we are releasing the code, models, and logs as open-source, encouraging the research community to build upon our findings.",
        "parent": "sec_ab2bd446"
      }
    ],
    "entities": [
      {
        "_key": "ent_3a69b34c",
        "_id": "entities/ent_3a69b34c",
        "name": "Large",
        "type": "unknown",
        "mentions": [
          {
            "section": "sections/sec_b3c1564c",
            "context": "Large language models (LL"
          },
          {
            "section": "sections/sec_6d8d3b93",
            "context": "Large language models are"
          }
        ]
      },
      {
        "_key": "ent_44f89957",
        "_id": "entities/ent_44f89957",
        "name": "Reinforcement Learning",
        "type": "unknown",
        "mentions": [
          {
            "section": "sections/sec_b3c1564c",
            "context": "lities by employing Reinforcement Learning with Verifiable Rew"
          },
          {
            "section": "sections/sec_f9e77f68",
            "context": " doesn\u2019t scale well.Reinforcement Learning with Verifiable Rew"
          },
          {
            "section": "sections/sec_157180aa",
            "context": "doesn\u2019t scale well. Reinforcement Learning with Verifiable Rew"
          }
        ]
      },
      {
        "_key": "ent_54a18906",
        "_id": "entities/ent_54a18906",
        "name": "Verifiable Rewards",
        "type": "unknown",
        "mentions": [
          {
            "section": "sections/sec_b3c1564c",
            "context": "ement Learning with Verifiable Rewards (RLVR)(Lambert et\u00a0a"
          },
          {
            "section": "sections/sec_f9e77f68",
            "context": "ement Learning with Verifiable Rewards (RLVR).To move beyo"
          },
          {
            "section": "sections/sec_157180aa",
            "context": "ement Learning with Verifiable Rewards (RLVR).To move beyo"
          }
        ]
      },
      {
        "_key": "ent_26cd1429",
        "_id": "entities/ent_26cd1429",
        "name": "Lambert",
        "type": "unknown",
        "mentions": [
          {
            "section": "sections/sec_b3c1564c",
            "context": "able Rewards (RLVR)(Lambert et\u00a0al.,2024). Unlik"
          },
          {
            "section": "sections/sec_1a5d9820",
            "context": "Seek-AI et\u00a0al.,2025;Lambert et\u00a0al.,2024). All p"
          },
          {
            "section": "sections/sec_0d24aa19",
            "context": "Seek-AI et\u00a0al.,2025;Lambert et\u00a0al.,2024). All p"
          },
          {
            "section": "sections/sec_95e6043e",
            "context": "rge language models(Lambert et\u00a0al.,2024). One o"
          },
          {
            "section": "sections/sec_95e6043e",
            "context": "rge language models(Lambert et\u00a0al.,2024). One o"
          },
          {
            "section": "sections/sec_485ba230",
            "context": "rge language models(Lambert et\u00a0al.,2024). One o"
          },
          {
            "section": "sections/sec_247e121e",
            "context": "for reasoning tasks(Lambert et\u00a0al.,2024). SPCCh"
          }
        ]
      },
      {
        "_key": "ent_2e54a377",
        "_id": "entities/ent_2e54a377",
        "name": "Unlike",
        "type": "unknown",
        "mentions": [
          {
            "section": "sections/sec_b3c1564c",
            "context": "mbert et\u00a0al.,2024). Unlike methods that explic"
          },
          {
            "section": "sections/sec_5c55d4bc",
            "context": "ss of our approach. Unlike other RLVR models t"
          },
          {
            "section": "sections/sec_5c55d4bc",
            "context": "ss of our approach. Unlike other RLVR models t"
          },
          {
            "section": "sections/sec_56cabe86",
            "context": "ss of our approach. Unlike other RLVR models t"
          },
          {
            "section": "sections/sec_56cabe86",
            "context": "ss of our approach. Unlike other RLVR models t"
          },
          {
            "section": "sections/sec_773a923f",
            "context": "ss of our approach. Unlike other RLVR models t"
          },
          {
            "section": "sections/sec_04cca2bb",
            "context": "se shown inFigure6. Unlike the 3B and 14B cate"
          }
        ]
      },
      {
        "_key": "ent_ac848fa2",
        "_id": "entities/ent_ac848fa2",
        "name": "Team",
        "type": "unknown",
        "mentions": [
          {
            "section": "sections/sec_b3c1564c",
            "context": "Seek-AI et\u00a0al.,2025;Team et\u00a0al.,2025;Jaech e"
          }
        ]
      },
      {
        "_key": "ent_b46299bb",
        "_id": "entities/ent_b46299bb",
        "name": "Jaech",
        "type": "unknown",
        "mentions": [
          {
            "section": "sections/sec_b3c1564c",
            "context": "25;Team et\u00a0al.,2025;Jaech et\u00a0al.,2024;OpenAI,"
          },
          {
            "section": "sections/sec_95e6043e",
            "context": "monumental work, o1(Jaech et\u00a0al.,2024), was a"
          },
          {
            "section": "sections/sec_485ba230",
            "context": "monumental work, o1(Jaech et\u00a0al.,2024), was a"
          }
        ]
      },
      {
        "_key": "ent_691f9cea",
        "_id": "entities/ent_691f9cea",
        "name": "However",
        "type": "unknown",
        "mentions": [
          {
            "section": "sections/sec_b3c1564c",
            "context": " with task rewards. However, these methods stil"
          },
          {
            "section": "sections/sec_f9e77f68",
            "context": "PT \u2223 italic_x ) .(1)However, at the frontier le"
          },
          {
            "section": "sections/sec_f9e77f68",
            "context": "PT \u2223 italic_x ) .(1)However, at the frontier le"
          },
          {
            "section": "sections/sec_157180aa",
            "context": "PT \u2223 italic_x ) .(1)However, at the frontier le"
          },
          {
            "section": "sections/sec_157180aa",
            "context": "PT \u2223 italic_x ) .(1)However, at the frontier le"
          },
          {
            "section": "sections/sec_ef8e3d10",
            "context": "T \u2223 italic_x ) .(1) However, at the frontier le"
          },
          {
            "section": "sections/sec_90f30199",
            "context": "_POSTSUPERSCRIPT ). However, the learning task "
          },
          {
            "section": "sections/sec_5c55d4bc",
            "context": "vely weaker models. However, these gains appear"
          },
          {
            "section": "sections/sec_56cabe86",
            "context": "vely weaker models. However, these gains appear"
          },
          {
            "section": "sections/sec_04cca2bb",
            "context": "vely weaker models. However, these gains appear"
          },
          {
            "section": "sections/sec_95e6043e",
            "context": "human capabilities. However, rather than relyin"
          },
          {
            "section": "sections/sec_5aa2a6bb",
            "context": "human capabilities. However, rather than relyin"
          }
        ]
      },
      {
        "_key": "ent_d5c32474",
        "_id": "entities/ent_d5c32474",
        "name": "Villalobos",
        "type": "unknown",
        "mentions": [
          {
            "section": "sections/sec_b3c1564c",
            "context": "ng-term scalability(Villalobos et\u00a0al.,2024). As re"
          }
        ]
      },
      {
        "_key": "ent_d233558d",
        "_id": "entities/ent_d233558d",
        "name": "Sutskever",
        "type": "unknown",
        "mentions": [
          {
            "section": "sections/sec_b3c1564c",
            "context": " of LLM pretraining(Sutskever et\u00a0al.,2024). Furth"
          },
          {
            "section": "sections/sec_95e6043e",
            "context": "abrant,2019;Leike & Sutskever,2023;Hubinger et\u00a0al"
          },
          {
            "section": "sections/sec_5aa2a6bb",
            "context": "abrant,2019;Leike & Sutskever,2023;Hubinger et\u00a0al"
          }
        ]
      },
      {
        "_key": "ent_1dc492cd",
        "_id": "entities/ent_1dc492cd",
        "name": "Furthermore",
        "type": "unknown",
        "mentions": [
          {
            "section": "sections/sec_b3c1564c",
            "context": "kever et\u00a0al.,2024). Furthermore, as AI systems cont"
          },
          {
            "section": "sections/sec_b3c1564c",
            "context": "kever et\u00a0al.,2024). Furthermore, as AI systems cont"
          },
          {
            "section": "sections/sec_b3c1564c",
            "context": "kever et\u00a0al.,2024). Furthermore, as AI systems cont"
          },
          {
            "section": "sections/sec_5c55d4bc",
            "context": "Yang et\u00a0al.,2024b). Furthermore, the zero-style mod"
          },
          {
            "section": "sections/sec_6ba6439f",
            "context": "Yang et\u00a0al.,2024b). Furthermore, the zero-style mod"
          },
          {
            "section": "sections/sec_f6a941fe",
            "context": "Yang et\u00a0al.,2024b). Furthermore, the zero-style mod"
          },
          {
            "section": "sections/sec_95e6043e",
            "context": "le learning signal. Furthermore, in our proposed me"
          },
          {
            "section": "sections/sec_5aa2a6bb",
            "context": "le learning signal. Furthermore, in our proposed me"
          },
          {
            "section": "sections/sec_ab2bd446",
            "context": "ific training data. Furthermore, we showed that AZR"
          },
          {
            "section": "sections/sec_97b161c9",
            "context": "ific training data. Furthermore, we showed that AZR"
          }
        ]
      },
      {
        "_key": "ent_ae115213",
        "_id": "entities/ent_ae115213",
        "name": "Hughes",
        "type": "unknown",
        "mentions": [
          {
            "section": "sections/sec_b3c1564c",
            "context": "learning and growth(Hughes et\u00a0al.,2024). This "
          },
          {
            "section": "sections/sec_b3c1564c",
            "context": "learning and growth(Hughes et\u00a0al.,2024). This "
          }
        ]
      },
      {
        "_key": "ent_4778f3ba",
        "_id": "entities/ent_4778f3ba",
        "name": "Absolute Zero",
        "type": "unknown",
        "mentions": [
          {
            "section": "sections/sec_b3c1564c",
            "context": "his end, we propose\u201cAbsolute Zero\u201d, a new paradigm fo"
          },
          {
            "section": "sections/sec_b3c1564c",
            "context": "his end, we propose\u201cAbsolute Zero\u201d, a new paradigm fo"
          },
          {
            "section": "sections/sec_b3c1564c",
            "context": "his end, we propose\u201cAbsolute Zero\u201d, a new paradigm fo"
          },
          {
            "section": "sections/sec_f9e77f68",
            "context": "it scalability. The Absolute Zero paradigm removes th"
          },
          {
            "section": "sections/sec_f9e77f68",
            "context": "it scalability. The Absolute Zero paradigm removes th"
          },
          {
            "section": "sections/sec_f9e77f68",
            "context": "it scalability. The Absolute Zero paradigm removes th"
          },
          {
            "section": "sections/sec_0af4c861",
            "context": "We propose the Absolute Zero paradigm, where dur"
          },
          {
            "section": "sections/sec_0af4c861",
            "context": "We propose the Absolute Zero paradigm, where dur"
          },
          {
            "section": "sections/sec_0af4c861",
            "context": "We propose the Absolute Zero paradigm, where dur"
          },
          {
            "section": "sections/sec_1a5d9820",
            "context": " section, we presentAbsolute Zero Reasoner(AZR) as th"
          },
          {
            "section": "sections/sec_6d8d3b93",
            "context": "as specified by the Absolute Zero objective inEquatio"
          },
          {
            "section": "sections/sec_5c55d4bc",
            "context": "-Coder, resulting inAbsolute Zero Reasoner-base-7Band"
          },
          {
            "section": "sections/sec_56cabe86",
            "context": "32.745.055.641.648.6Absolute Zero Training w/ No Cura"
          },
          {
            "section": "sections/sec_9cc89151",
            "context": " performance in the Absolute Zero paradigm. (a)Model "
          },
          {
            "section": "sections/sec_ab2bd446",
            "context": "rk, we proposed the Absolute Zero paradigm, a novel s"
          },
          {
            "section": "sections/sec_97b161c9",
            "context": "rk, we proposed the Absolute Zero paradigm, a novel s"
          }
        ]
      },
      {
        "_key": "ent_f96e345f",
        "_id": "entities/ent_f96e345f",
        "name": "Silver",
        "type": "unknown",
        "mentions": [
          {
            "section": "sections/sec_b3c1564c",
            "context": "re prone to hacking(Silver et\u00a0al.,2017;Chen et"
          },
          {
            "section": "sections/sec_b3c1564c",
            "context": "re prone to hacking(Silver et\u00a0al.,2017;Chen et"
          },
          {
            "section": "sections/sec_95e6043e",
            "context": "phaGo and AlphaZero(Silver et\u00a0al.,2016;2017)ex"
          },
          {
            "section": "sections/sec_247e121e",
            "context": "phaGo and AlphaZero(Silver et\u00a0al.,2016;2017)ex"
          }
        ]
      },
      {
        "_key": "ent_ef6bf3fd",
        "_id": "entities/ent_ef6bf3fd",
        "name": "Chen",
        "type": "unknown",
        "mentions": [
          {
            "section": "sections/sec_b3c1564c",
            "context": "(Silver et\u00a0al.,2017;Chen et\u00a0al.,2025;2024), "
          },
          {
            "section": "sections/sec_95e6043e",
            "context": "ing Language Models(Chen et\u00a0al.,2024;Yuan et"
          },
          {
            "section": "sections/sec_247e121e",
            "context": "ing Language Models(Chen et\u00a0al.,2024;Yuan et"
          }
        ]
      },
      {
        "_key": "ent_74d6c578",
        "_id": "entities/ent_74d6c578",
        "name": "Zeroparadigm",
        "type": "unknown",
        "mentions": [
          {
            "section": "sections/sec_b3c1564c",
            "context": ";2024), theAbsolute Zeroparadigm is designed to oper"
          }
        ]
      },
      {
        "_key": "ent_0efa04d9",
        "_id": "entities/ent_0efa04d9",
        "name": "Similar",
        "type": "unknown",
        "mentions": [
          {
            "section": "sections/sec_b3c1564c",
            "context": "ughes et\u00a0al.,2024). Similar to AlphaZero(Silver"
          },
          {
            "section": "sections/sec_b3c1564c",
            "context": "ughes et\u00a0al.,2024). Similar to AlphaZero(Silver"
          }
        ]
      },
      {
        "_key": "ent_c39b56d4",
        "_id": "entities/ent_c39b56d4",
        "name": "Building",
        "type": "unknown",
        "mentions": [
          {
            "section": "sections/sec_b3c1564c",
            "context": "oning capabilities. Building on this new reasoni"
          }
        ]
      },
      {
        "_key": "ent_f40795eb",
        "_id": "entities/ent_f40795eb",
        "name": "Zero Reasoner",
        "type": "unknown",
        "mentions": [
          {
            "section": "sections/sec_b3c1564c",
            "context": "troduce theAbsolute Zero Reasoner (AZR), which propos"
          },
          {
            "section": "sections/sec_1a5d9820",
            "context": " we presentAbsolute Zero Reasoner(AZR) as the first a"
          },
          {
            "section": "sections/sec_5c55d4bc",
            "context": "esulting inAbsolute Zero Reasoner-base-7BandAbsolute "
          },
          {
            "section": "sections/sec_5c55d4bc",
            "context": "esulting inAbsolute Zero Reasoner-base-7BandAbsolute "
          },
          {
            "section": "sections/sec_5c55d4bc",
            "context": "esulting inAbsolute Zero Reasoner-base-7BandAbsolute "
          },
          {
            "section": "sections/sec_5c55d4bc",
            "context": "esulting inAbsolute Zero Reasoner-base-7BandAbsolute "
          },
          {
            "section": "sections/sec_6ba6439f",
            "context": "esulting inAbsolute Zero Reasoner-base-7BandAbsolute "
          },
          {
            "section": "sections/sec_6ba6439f",
            "context": "esulting inAbsolute Zero Reasoner-base-7BandAbsolute "
          },
          {
            "section": "sections/sec_ba8c62bf",
            "context": "esulting inAbsolute Zero Reasoner-base-7BandAbsolute "
          },
          {
            "section": "sections/sec_ba8c62bf",
            "context": "esulting inAbsolute Zero Reasoner-base-7BandAbsolute "
          },
          {
            "section": "sections/sec_56cabe86",
            "context": "1. Notably,Absolute Zero Reasoner-Coder-7Bachieves st"
          },
          {
            "section": "sections/sec_56cabe86",
            "context": "1. Notably,Absolute Zero Reasoner-Coder-7Bachieves st"
          },
          {
            "section": "sections/sec_72c37985",
            "context": "patterns inAbsolute Zero Reasoner-Llama3.1-8B, simila"
          },
          {
            "section": "sections/sec_94b98c7f",
            "context": " using onlyAbsolute Zero Reasoner-Base-7B. We begin b"
          }
        ]
      },
      {
        "_key": "ent_b3043682",
        "_id": "entities/ent_b3043682",
        "name": "Despite",
        "type": "unknown",
        "mentions": [
          {
            "section": "sections/sec_b3c1564c",
            "context": " proposed approach. Despite being trained entir"
          },
          {
            "section": "sections/sec_5c55d4bc",
            "context": "average categories. Despite being entirely out-"
          },
          {
            "section": "sections/sec_56cabe86",
            "context": "average categories. Despite being entirely out-"
          },
          {
            "section": "sections/sec_773a923f",
            "context": "average categories. Despite being entirely out-"
          }
        ]
      },
      {
        "_key": "ent_37341076",
        "_id": "entities/ent_37341076",
        "name": "Besides",
        "type": "unknown",
        "mentions": [
          {
            "section": "sections/sec_b3c1564c",
            "context": " pivotal milestone. Besides the remarkable resu"
          }
        ]
      },
      {
        "_key": "ent_ca0dbad9",
        "_id": "entities/ent_ca0dbad9",
        "name": "Code",
        "type": "unknown",
        "mentions": [
          {
            "section": "sections/sec_b3c1564c",
            "context": "s summarized below:\u2022Code priors amplify reas"
          }
        ]
      },
      {
        "_key": "ent_14c0f98e",
        "_id": "entities/ent_14c0f98e",
        "name": "Coder",
        "type": "unknown",
        "mentions": [
          {
            "section": "sections/sec_b3c1564c",
            "context": "soning.The baseQwen-Coder-7bmodel started wit"
          },
          {
            "section": "sections/sec_b3c1564c",
            "context": "soning.The baseQwen-Coder-7bmodel started wit"
          },
          {
            "section": "sections/sec_5c55d4bc",
            "context": "2.5-7BandQwen2.5-7B-Coder, resulting inAbsolu"
          },
          {
            "section": "sections/sec_5c55d4bc",
            "context": "2.5-7BandQwen2.5-7B-Coder, resulting inAbsolu"
          },
          {
            "section": "sections/sec_5c55d4bc",
            "context": "2.5-7BandQwen2.5-7B-Coder, resulting inAbsolu"
          },
          {
            "section": "sections/sec_5c55d4bc",
            "context": "2.5-7BandQwen2.5-7B-Coder, resulting inAbsolu"
          },
          {
            "section": "sections/sec_5c55d4bc",
            "context": "2.5-7BandQwen2.5-7B-Coder, resulting inAbsolu"
          },
          {
            "section": "sections/sec_5c55d4bc",
            "context": "2.5-7BandQwen2.5-7B-Coder, resulting inAbsolu"
          },
          {
            "section": "sections/sec_5c55d4bc",
            "context": "2.5-7BandQwen2.5-7B-Coder, resulting inAbsolu"
          },
          {
            "section": "sections/sec_5c55d4bc",
            "context": "2.5-7BandQwen2.5-7B-Coder, resulting inAbsolu"
          },
          {
            "section": "sections/sec_5c55d4bc",
            "context": "2.5-7BandQwen2.5-7B-Coder, resulting inAbsolu"
          },
          {
            "section": "sections/sec_5c55d4bc",
            "context": "2.5-7BandQwen2.5-7B-Coder, resulting inAbsolu"
          },
          {
            "section": "sections/sec_5c55d4bc",
            "context": "2.5-7BandQwen2.5-7B-Coder, resulting inAbsolu"
          },
          {
            "section": "sections/sec_6ba6439f",
            "context": "2.5-7BandQwen2.5-7B-Coder, resulting inAbsolu"
          },
          {
            "section": "sections/sec_6ba6439f",
            "context": "2.5-7BandQwen2.5-7B-Coder, resulting inAbsolu"
          },
          {
            "section": "sections/sec_6ba6439f",
            "context": "2.5-7BandQwen2.5-7B-Coder, resulting inAbsolu"
          },
          {
            "section": "sections/sec_6ba6439f",
            "context": "2.5-7BandQwen2.5-7B-Coder, resulting inAbsolu"
          },
          {
            "section": "sections/sec_6ba6439f",
            "context": "2.5-7BandQwen2.5-7B-Coder, resulting inAbsolu"
          },
          {
            "section": "sections/sec_ba8c62bf",
            "context": "2.5-7BandQwen2.5-7B-Coder, resulting inAbsolu"
          },
          {
            "section": "sections/sec_ba8c62bf",
            "context": "2.5-7BandQwen2.5-7B-Coder, resulting inAbsolu"
          },
          {
            "section": "sections/sec_ba8c62bf",
            "context": "2.5-7BandQwen2.5-7B-Coder, resulting inAbsolu"
          },
          {
            "section": "sections/sec_ba8c62bf",
            "context": "2.5-7BandQwen2.5-7B-Coder, resulting inAbsolu"
          },
          {
            "section": "sections/sec_f6a941fe",
            "context": "variants:Qwen2.5-7B-Coder,Qwen2.5-7B-Instruct"
          },
          {
            "section": "sections/sec_56cabe86",
            "context": "337.046.7Qwen2.5-7B-Coder[26]--80.569.319.96."
          },
          {
            "section": "sections/sec_56cabe86",
            "context": "337.046.7Qwen2.5-7B-Coder[26]--80.569.319.96."
          },
          {
            "section": "sections/sec_56cabe86",
            "context": "337.046.7Qwen2.5-7B-Coder[26]--80.569.319.96."
          },
          {
            "section": "sections/sec_56cabe86",
            "context": "337.046.7Qwen2.5-7B-Coder[26]--80.569.319.96."
          },
          {
            "section": "sections/sec_56cabe86",
            "context": "337.046.7Qwen2.5-7B-Coder[26]--80.569.319.96."
          },
          {
            "section": "sections/sec_56cabe86",
            "context": "337.046.7Qwen2.5-7B-Coder[26]--80.569.319.96."
          },
          {
            "section": "sections/sec_773a923f",
            "context": "olute Zero Reasoner-Coder-7Bachieves state-of"
          },
          {
            "section": "sections/sec_9cc89151",
            "context": "variants:Qwen2.5-3B-CoderandQwen2.5-14B-Coder"
          },
          {
            "section": "sections/sec_9cc89151",
            "context": "variants:Qwen2.5-3B-CoderandQwen2.5-14B-Coder"
          },
          {
            "section": "sections/sec_9cc89151",
            "context": "variants:Qwen2.5-3B-CoderandQwen2.5-14B-Coder"
          },
          {
            "section": "sections/sec_9cc89151",
            "context": "variants:Qwen2.5-3B-CoderandQwen2.5-14B-Coder"
          }
        ]
      },
      {
        "_key": "ent_e76b449b",
        "_id": "entities/ent_e76b449b",
        "name": "Cross",
        "type": "unknown",
        "mentions": [
          {
            "section": "sections/sec_b3c1564c",
            "context": "after AZR training.\u2022Cross domain transfer is "
          }
        ]
      },
      {
        "_key": "ent_7bfcadb5",
        "_id": "entities/ent_7bfcadb5",
        "name": "After",
        "type": "unknown",
        "mentions": [
          {
            "section": "sections/sec_b3c1564c",
            "context": " pronounced for AZR.After RLVR, expert code m"
          },
          {
            "section": "sections/sec_5c55d4bc",
            "context": "oding environments. After training, most expe"
          },
          {
            "section": "sections/sec_56cabe86",
            "context": "oding environments. After training, most expe"
          },
          {
            "section": "sections/sec_773a923f",
            "context": "oding environments. After training, most expe"
          }
        ]
      },
      {
        "_key": "ent_095a1b43",
        "_id": "entities/ent_095a1b43",
        "name": "Base",
        "type": "unknown",
        "mentions": [
          {
            "section": "sections/sec_b3c1564c",
            "context": "average, whereasAZR-Base-7BandAZR-Coder-7Btr"
          },
          {
            "section": "sections/sec_5c55d4bc",
            "context": "ure reproducibility.Baselines.For our main r"
          },
          {
            "section": "sections/sec_56cabe86",
            "context": "ModelBase#dataHEval+MBPP+LCBv"
          },
          {
            "section": "sections/sec_94b98c7f",
            "context": "olute Zero Reasoner-Base-7B. We begin by tes"
          }
        ]
      },
      {
        "_key": "ent_a2890fe0",
        "_id": "entities/ent_a2890fe0",
        "name": "Bigger",
        "type": "unknown",
        "mentions": [
          {
            "section": "sections/sec_b3c1564c",
            "context": "g capability gains.\u2022Bigger bases yield bigger "
          }
        ]
      },
      {
        "_key": "ent_9446a98a",
        "_id": "entities/ent_9446a98a",
        "name": "Performance",
        "type": "unknown",
        "mentions": [
          {
            "section": "sections/sec_b3c1564c",
            "context": " yield bigger gains.Performance improvements scale "
          },
          {
            "section": "sections/sec_5c55d4bc",
            "context": "RIPT end_ARGTable 1:Performance of RL-Trained Reaso"
          },
          {
            "section": "sections/sec_5c55d4bc",
            "context": "RIPT end_ARGTable 1:Performance of RL-Trained Reaso"
          },
          {
            "section": "sections/sec_56cabe86",
            "context": "RIPT end_ARGTable 1:Performance of RL-Trained Reaso"
          },
          {
            "section": "sections/sec_56cabe86",
            "context": "RIPT end_ARGTable 1:Performance of RL-Trained Reaso"
          }
        ]
      },
      {
        "_key": "ent_8413c683",
        "_id": "entities/ent_8413c683",
        "name": "Comments",
        "type": "unknown",
        "mentions": [
          {
            "section": "sections/sec_b3c1564c",
            "context": "vantageous for AZR.\u2022Comments as intermediate pla"
          }
        ]
      },
      {
        "_key": "ent_4e97aeea",
        "_id": "entities/ent_4e97aeea",
        "name": "When",
        "type": "unknown",
        "mentions": [
          {
            "section": "sections/sec_b3c1564c",
            "context": "ns emerge naturally.When solving code induct"
          },
          {
            "section": "sections/sec_f9e77f68",
            "context": "stainable training. When proposing,z\ud835\udc67zitalic"
          },
          {
            "section": "sections/sec_0af4c861",
            "context": "stainable training. When proposing,z\ud835\udc67zitalic"
          },
          {
            "section": "sections/sec_5c55d4bc",
            "context": "es the given input. When predicting outputs,"
          },
          {
            "section": "sections/sec_5c55d4bc",
            "context": "es the given input. When predicting outputs,"
          },
          {
            "section": "sections/sec_56cabe86",
            "context": "es the given input. When predicting outputs,"
          },
          {
            "section": "sections/sec_56cabe86",
            "context": "es the given input. When predicting outputs,"
          },
          {
            "section": "sections/sec_72c37985",
            "context": "es the given input. When predicting outputs,"
          },
          {
            "section": "sections/sec_72c37985",
            "context": "es the given input. When predicting outputs,"
          }
        ]
      },
      {
        "_key": "ent_26dcda57",
        "_id": "entities/ent_26dcda57",
        "name": "Prover",
        "type": "unknown",
        "mentions": [
          {
            "section": "sections/sec_b3c1564c",
            "context": "ls such as DeepSeek Prover v2 (671B)(Ren et\u00a0al"
          },
          {
            "section": "sections/sec_5c55d4bc",
            "context": "ls, such asDeepSeek Prover v2, which is signif"
          },
          {
            "section": "sections/sec_56cabe86",
            "context": "ls, such asDeepSeek Prover v2, which is signif"
          },
          {
            "section": "sections/sec_72c37985",
            "context": "ls, such asDeepSeek Prover v2, which is signif"
          },
          {
            "section": "sections/sec_95e6043e",
            "context": "er et\u00a0al.(2024)uses Prover-Verifier Game for i"
          },
          {
            "section": "sections/sec_247e121e",
            "context": "er et\u00a0al.(2024)uses Prover-Verifier Game for i"
          }
        ]
      },
      {
        "_key": "ent_5f4fea76",
        "_id": "entities/ent_5f4fea76",
        "name": "Cognitive Behaviors",
        "type": "unknown",
        "mentions": [
          {
            "section": "sections/sec_b3c1564c",
            "context": "er domains as well.\u2022Cognitive Behaviors and Token length de"
          }
        ]
      },
      {
        "_key": "ent_459a6f79",
        "_id": "entities/ent_459a6f79",
        "name": "Token",
        "type": "unknown",
        "mentions": [
          {
            "section": "sections/sec_b3c1564c",
            "context": "itive Behaviors and Token length depends on r"
          }
        ]
      },
      {
        "_key": "ent_41516cd0",
        "_id": "entities/ent_41516cd0",
        "name": "Distinct",
        "type": "unknown",
        "mentions": [
          {
            "section": "sections/sec_b3c1564c",
            "context": "s on reasoning mode.Distinct cognitive behaviors"
          }
        ]
      },
      {
        "_key": "ent_6472ce41",
        "_id": "entities/ent_6472ce41",
        "name": "Safety",
        "type": "unknown",
        "mentions": [
          {
            "section": "sections/sec_b3c1564c",
            "context": "tion grow modestly.\u2022Safety alarms ringing.We o"
          }
        ]
      },
      {
        "_key": "ent_96641e4a",
        "_id": "entities/ent_96641e4a",
        "name": "Zhang",
        "type": "unknown",
        "mentions": [
          {
            "section": "sections/sec_b3c1564c",
            "context": "fety-aware training(Zhang et\u00a0al.,2025a)."
          },
          {
            "section": "sections/sec_1a5d9820",
            "context": "ment learning setup(Zhang & Yang,2021;Zhao et"
          },
          {
            "section": "sections/sec_3d319639",
            "context": "ment learning setup(Zhang & Yang,2021;Zhao et"
          },
          {
            "section": "sections/sec_730b34d8",
            "context": "ment learning setup(Zhang & Yang,2021;Zhao et"
          },
          {
            "section": "sections/sec_5c55d4bc",
            "context": "tCodeR1models(Liu & Zhang,2025). For math dat"
          },
          {
            "section": "sections/sec_6ba6439f",
            "context": "tCodeR1models(Liu & Zhang,2025). For math dat"
          },
          {
            "section": "sections/sec_f6a941fe",
            "context": "tCodeR1models(Liu & Zhang,2025). For math dat"
          },
          {
            "section": "sections/sec_95e6043e",
            "context": "TTRL(Xu et\u00a0al.,2025;Zhang et\u00a0al.,2025b;Zuo et"
          },
          {
            "section": "sections/sec_247e121e",
            "context": "TTRL(Xu et\u00a0al.,2025;Zhang et\u00a0al.,2025b;Zuo et"
          }
        ]
      },
      {
        "_key": "ent_5999b890",
        "_id": "entities/ent_5999b890",
        "name": "Fine",
        "type": "unknown",
        "mentions": [
          {
            "section": "sections/sec_f9e77f68",
            "context": "iminariesSupervised Fine-Tuning (SFT).SFT re"
          }
        ]
      },
      {
        "_key": "ent_89dd2948",
        "_id": "entities/ent_89dd2948",
        "name": "Tuning",
        "type": "unknown",
        "mentions": [
          {
            "section": "sections/sec_f9e77f68",
            "context": "riesSupervised Fine-Tuning (SFT).SFT requires "
          },
          {
            "section": "sections/sec_157180aa",
            "context": "Supervised Fine-Tuning (SFT).SFT requires "
          }
        ]
      },
      {
        "_key": "ent_3826805b",
        "_id": "entities/ent_3826805b",
        "name": "Ouyang",
        "type": "unknown",
        "mentions": [
          {
            "section": "sections/sec_f9e77f68",
            "context": "tive log-likelihood(Ouyang et\u00a0al.,2022):\u2112SFT\u2062("
          },
          {
            "section": "sections/sec_157180aa",
            "context": "tive log-likelihood(Ouyang et\u00a0al.,2022):\u2112SFT\u2062("
          },
          {
            "section": "sections/sec_ef8e3d10",
            "context": "tive log-likelihood(Ouyang et\u00a0al.,2022): \u2112SFT\u2062"
          }
        ]
      },
      {
        "_key": "ent_97f3c113",
        "_id": "entities/ent_97f3c113",
        "name": "The Absolute Zero",
        "type": "unknown",
        "mentions": [
          {
            "section": "sections/sec_f9e77f68",
            "context": " limit scalability. The Absolute Zero paradigm removes th"
          },
          {
            "section": "sections/sec_f9e77f68",
            "context": " limit scalability. The Absolute Zero paradigm removes th"
          },
          {
            "section": "sections/sec_157180aa",
            "context": " limit scalability. The Absolute Zero paradigm removes th"
          },
          {
            "section": "sections/sec_90f30199",
            "context": " limit scalability. The Absolute Zero paradigm removes th"
          },
          {
            "section": "sections/sec_0af4c861",
            "context": " training. Figure 3:The Absolute Zero Loop.The Absolute Z"
          }
        ]
      },
      {
        "_key": "ent_666df2f4",
        "_id": "entities/ent_666df2f4",
        "name": "Figure",
        "type": "unknown",
        "mentions": [
          {
            "section": "sections/sec_f9e77f68",
            "context": "ate this paradigm inFigure2, which contrasts A"
          },
          {
            "section": "sections/sec_0af4c861",
            "context": "ate this paradigm inFigure2, which contrasts A"
          },
          {
            "section": "sections/sec_1a5d9820",
            "context": "Reasoner approach inFigure4. To expedite futur"
          },
          {
            "section": "sections/sec_1a5d9820",
            "context": "Reasoner approach inFigure4. To expedite futur"
          },
          {
            "section": "sections/sec_6d8d3b93",
            "context": " end_CELL end_ROW(4)Figure 4:Absolute Zero Rea"
          },
          {
            "section": "sections/sec_2f0cfe08",
            "context": "end_CELL end_ROW(4) Figure 4:Absolute Zero Rea"
          },
          {
            "section": "sections/sec_0d24aa19",
            "context": "eralized induction. Figure 5:The Seed AZR Zero"
          },
          {
            "section": "sections/sec_5c55d4bc",
            "context": "tribution results inFigure6(a) and (b), respec"
          },
          {
            "section": "sections/sec_5c55d4bc",
            "context": "tribution results inFigure6(a) and (b), respec"
          },
          {
            "section": "sections/sec_56cabe86",
            "context": "tribution results inFigure6(a) and (b), respec"
          },
          {
            "section": "sections/sec_56cabe86",
            "context": "tribution results inFigure6(a) and (b), respec"
          },
          {
            "section": "sections/sec_9cc89151",
            "context": "tribution results inFigure6(a) and (b), respec"
          },
          {
            "section": "sections/sec_04cca2bb",
            "context": "as the base shown inFigure6. Unlike the 3B and"
          }
        ]
      },
      {
        "_key": "ent_214ecbca",
        "_id": "entities/ent_214ecbca",
        "name": "The Absolute Zero Loop",
        "type": "unknown",
        "mentions": [
          {
            "section": "sections/sec_f9e77f68",
            "context": "g training.Figure 3:The Absolute Zero Loop.The Absolute Zero l"
          },
          {
            "section": "sections/sec_0af4c861",
            "context": " training. Figure 3:The Absolute Zero Loop.The Absolute Zero l"
          }
        ]
      },
      {
        "_key": "ent_d48a5cda",
        "_id": "entities/ent_d48a5cda",
        "name": "Then",
        "type": "unknown",
        "mentions": [
          {
            "section": "sections/sec_f9e77f68",
            "context": "PTfor learnability. Then, a standard RL step"
          },
          {
            "section": "sections/sec_f9e77f68",
            "context": "PTfor learnability. Then, a standard RL step"
          },
          {
            "section": "sections/sec_0af4c861",
            "context": "PTfor learnability. Then, a standard RL step"
          },
          {
            "section": "sections/sec_0af4c861",
            "context": "PTfor learnability. Then, a standard RL step"
          },
          {
            "section": "sections/sec_1a5d9820",
            "context": "reference examples. Then we executesp\u2062(i)\ud835\udc5d\ud835\udc56p"
          },
          {
            "section": "sections/sec_0d24aa19",
            "context": "reference examples. Then we executesp\u2062(i)\ud835\udc5d\ud835\udc56p"
          }
        ]
      },
      {
        "_key": "ent_265b922d",
        "_id": "entities/ent_265b922d",
        "name": "Each",
        "type": "unknown",
        "mentions": [
          {
            "section": "sections/sec_f9e77f68",
            "context": "T ( \u22c5 \u2223 italic_x ). Each proposed task\u03c4\ud835\udf0f\\tau"
          },
          {
            "section": "sections/sec_0af4c861",
            "context": "T ( \u22c5 \u2223 italic_x ). Each proposed task\u03c4\ud835\udf0f\\tau"
          },
          {
            "section": "sections/sec_1a5d9820",
            "context": "he simplest program.Each reasoning task type"
          },
          {
            "section": "sections/sec_1a5d9820",
            "context": "he simplest program.Each reasoning task type"
          },
          {
            "section": "sections/sec_0d24aa19",
            "context": "e simplest program. Each reasoning task type"
          },
          {
            "section": "sections/sec_3d319639",
            "context": "ase language model. Each prompt samples up t"
          },
          {
            "section": "sections/sec_4af9d86a",
            "context": "ase language model. Each prompt samples up t"
          }
        ]
      },
      {
        "_key": "ent_b27dae22",
        "_id": "entities/ent_b27dae22",
        "name": "Moreover",
        "type": "unknown",
        "mentions": [
          {
            "section": "sections/sec_f9e77f68",
            "context": "k queryx\ud835\udc65xitalic_x. Moreover, the same policy al"
          },
          {
            "section": "sections/sec_f9e77f68",
            "context": "k queryx\ud835\udc65xitalic_x. Moreover, the same policy al"
          },
          {
            "section": "sections/sec_0af4c861",
            "context": "k queryx\ud835\udc65xitalic_x. Moreover, the same policy al"
          },
          {
            "section": "sections/sec_0af4c861",
            "context": "k queryx\ud835\udc65xitalic_x. Moreover, the same policy al"
          },
          {
            "section": "sections/sec_1a5d9820",
            "context": "s shown inFigure33. Moreover, for the proposer, "
          },
          {
            "section": "sections/sec_6d8d3b93",
            "context": "s shown inFigure33. Moreover, for the proposer, "
          },
          {
            "section": "sections/sec_2f0cfe08",
            "context": "s shown inFigure33. Moreover, for the proposer, "
          },
          {
            "section": "sections/sec_95e6043e",
            "context": "irely through RLVR. Moreover, our goal is not to"
          },
          {
            "section": "sections/sec_95e6043e",
            "context": "irely through RLVR. Moreover, our goal is not to"
          },
          {
            "section": "sections/sec_485ba230",
            "context": "irely through RLVR. Moreover, our goal is not to"
          },
          {
            "section": "sections/sec_247e121e",
            "context": " in the game of Go. Moreover, methods such as as"
          }
        ]
      },
      {
        "_key": "ent_b98186a9",
        "_id": "entities/ent_b98186a9",
        "name": "Bigg",
        "type": "unknown",
        "mentions": [
          {
            "section": "sections/sec_f9e77f68",
            "context": "b{E}_{z\\sim p(%\nz)}\\Bigg{[}\\;\\mathbb{E}_{{\\c"
          },
          {
            "section": "sections/sec_f9e77f68",
            "context": "b{E}_{z\\sim p(%\nz)}\\Bigg{[}\\;\\mathbb{E}_{{\\c"
          },
          {
            "section": "sections/sec_0af4c861",
            "context": "b{E}_{z\\sim p(%\nz)}\\Bigg{[}\\;\\mathbb{E}_{{\\c"
          },
          {
            "section": "sections/sec_0af4c861",
            "context": "b{E}_{z\\sim p(%\nz)}\\Bigg{[}\\;\\mathbb{E}_{{\\c"
          }
        ]
      },
      {
        "_key": "ent_24efa7ee",
        "_id": "entities/ent_24efa7ee",
        "name": "Notice",
        "type": "unknown",
        "mentions": [
          {
            "section": "sections/sec_f9e77f68",
            "context": "RSCRIPT ) ] ] ] .(3)Notice that we shift the b"
          },
          {
            "section": "sections/sec_0af4c861",
            "context": "SCRIPT ) ] ] ] .(3) Notice that we shift the b"
          }
        ]
      },
      {
        "_key": "ent_8a923c72",
        "_id": "entities/ent_8a923c72",
        "name": "Practically",
        "type": "unknown",
        "mentions": [
          {
            "section": "sections/sec_f9e77f68",
            "context": "eneration of tasks. Practically,z\ud835\udc67zitalic_zcan be i"
          },
          {
            "section": "sections/sec_0af4c861",
            "context": "eneration of tasks. Practically,z\ud835\udc67zitalic_zcan be i"
          }
        ]
      },
      {
        "_key": "ent_95d83e98",
        "_id": "entities/ent_95d83e98",
        "name": "Together",
        "type": "unknown",
        "mentions": [
          {
            "section": "sections/sec_f9e77f68",
            "context": "the model\u2019s output. Together, these two signals "
          },
          {
            "section": "sections/sec_0af4c861",
            "context": "the model\u2019s output. Together, these two signals "
          }
        ]
      },
      {
        "_key": "ent_ab4d6983",
        "_id": "entities/ent_ab4d6983",
        "name": "Supervised Fine",
        "type": "unknown",
        "mentions": [
          {
            "section": "sections/sec_157180aa",
            "context": "Supervised Fine-Tuning (SFT).SFT re"
          }
        ]
      },
      {
        "_key": "ent_90cb35ef",
        "_id": "entities/ent_90cb35ef",
        "name": "Absolute Zero Paradigm",
        "type": "unknown",
        "mentions": [
          {
            "section": "sections/sec_1a5d9820",
            "context": "empt to embrace the Absolute Zero Paradigm. In AZR, an unified"
          },
          {
            "section": "sections/sec_1a5d9820",
            "context": "empt to embrace the Absolute Zero Paradigm. In AZR, an unified"
          },
          {
            "section": "sections/sec_0d24aa19",
            "context": ", aligning with the Absolute Zero Paradigm\u2019s goals of fully se"
          }
        ]
      },
      {
        "_key": "ent_37bac6dc",
        "_id": "entities/ent_37bac6dc",
        "name": "Within",
        "type": "unknown",
        "mentions": [
          {
            "section": "sections/sec_1a5d9820",
            "context": "ively\u00a0(Section3.1). Within this self-play trai"
          }
        ]
      },
      {
        "_key": "ent_3f05d6f3",
        "_id": "entities/ent_3f05d6f3",
        "name": "Using",
        "type": "unknown",
        "mentions": [
          {
            "section": "sections/sec_1a5d9820",
            "context": "ction\u00a0(Section3.2). Using coding tasks is mot"
          },
          {
            "section": "sections/sec_95e6043e",
            "context": "Reasoning with RL.Using RL to enhance reaso"
          },
          {
            "section": "sections/sec_485ba230",
            "context": "Using RL to enhance reaso"
          }
        ]
      },
      {
        "_key": "ent_bbe51039",
        "_id": "entities/ent_bbe51039",
        "name": "Turing",
        "type": "unknown",
        "mentions": [
          {
            "section": "sections/sec_1a5d9820",
            "context": "is motivated by the Turing-completeness of pro"
          }
        ]
      },
      {
        "_key": "ent_892098dc",
        "_id": "entities/ent_892098dc",
        "name": "Stuart",
        "type": "unknown",
        "mentions": [
          {
            "section": "sections/sec_1a5d9820",
            "context": "ogramming languages(Stuart,2015)and empirical "
          },
          {
            "section": "sections/sec_1a5d9820",
            "context": "ogramming languages(Stuart,2015)and empirical "
          },
          {
            "section": "sections/sec_0d24aa19",
            "context": "ode reasoning tasks(Stuart,2015;Aryabumi et\u00a0al"
          }
        ]
      },
      {
        "_key": "ent_a1982ba4",
        "_id": "entities/ent_a1982ba4",
        "name": "Aryabumi",
        "type": "unknown",
        "mentions": [
          {
            "section": "sections/sec_1a5d9820",
            "context": " improves reasoning(Aryabumi et\u00a0al.,2024). We ad"
          },
          {
            "section": "sections/sec_1a5d9820",
            "context": " improves reasoning(Aryabumi et\u00a0al.,2024). We ad"
          },
          {
            "section": "sections/sec_0d24aa19",
            "context": "g tasks(Stuart,2015;Aryabumi et\u00a0al.,2024). Give "
          }
        ]
      },
      {
        "_key": "ent_5f12a065",
        "_id": "entities/ent_5f12a065",
        "name": "Finally",
        "type": "unknown",
        "mentions": [
          {
            "section": "sections/sec_1a5d9820",
            "context": "ation\u00a0(Section3.3). Finally, the model is updat"
          },
          {
            "section": "sections/sec_1a5d9820",
            "context": "ation\u00a0(Section3.3). Finally, the model is updat"
          },
          {
            "section": "sections/sec_6d8d3b93",
            "context": "cribed inEquation5. Finally, the Absolute Zero "
          },
          {
            "section": "sections/sec_2f0cfe08",
            "context": "cribed inEquation5. Finally, the Absolute Zero "
          },
          {
            "section": "sections/sec_5c55d4bc",
            "context": "t parameter scales. Finally, we compare ourLlam"
          },
          {
            "section": "sections/sec_5c55d4bc",
            "context": "t parameter scales. Finally, we compare ourLlam"
          },
          {
            "section": "sections/sec_5c55d4bc",
            "context": "t parameter scales. Finally, we compare ourLlam"
          },
          {
            "section": "sections/sec_5c55d4bc",
            "context": "t parameter scales. Finally, we compare ourLlam"
          },
          {
            "section": "sections/sec_6ba6439f",
            "context": "t parameter scales. Finally, we compare ourLlam"
          },
          {
            "section": "sections/sec_f6a941fe",
            "context": "t parameter scales. Finally, we compare ourLlam"
          },
          {
            "section": "sections/sec_56cabe86",
            "context": "epends on Task Type.Finally, we observed that t"
          },
          {
            "section": "sections/sec_56cabe86",
            "context": "epends on Task Type.Finally, we observed that t"
          },
          {
            "section": "sections/sec_56cabe86",
            "context": "epends on Task Type.Finally, we observed that t"
          },
          {
            "section": "sections/sec_72c37985",
            "context": "epends on Task Type.Finally, we observed that t"
          },
          {
            "section": "sections/sec_bb5ac41e",
            "context": "ning problem space. Finally, we consider a case"
          },
          {
            "section": "sections/sec_985245d2",
            "context": "e model inFigure14. Finally, we invite interest"
          },
          {
            "section": "sections/sec_95e6043e",
            "context": " task distribution. Finally, Minimo(Poesia et\u00a0a"
          },
          {
            "section": "sections/sec_247e121e",
            "context": " task distribution. Finally, Minimo(Poesia et\u00a0a"
          }
        ]
      },
      {
        "_key": "ent_456ab015",
        "_id": "entities/ent_456ab015",
        "name": "Absolute Zero Reasoner",
        "type": "unknown",
        "mentions": [
          {
            "section": "sections/sec_1a5d9820",
            "context": " section, we presentAbsolute Zero Reasoner(AZR) as the first a"
          },
          {
            "section": "sections/sec_1a5d9820",
            "context": " section, we presentAbsolute Zero Reasoner(AZR) as the first a"
          },
          {
            "section": "sections/sec_1a5d9820",
            "context": " section, we presentAbsolute Zero Reasoner(AZR) as the first a"
          },
          {
            "section": "sections/sec_1a5d9820",
            "context": " section, we presentAbsolute Zero Reasoner(AZR) as the first a"
          },
          {
            "section": "sections/sec_6d8d3b93",
            "context": " end_ROW(4)Figure 4:Absolute Zero Reasoner Training Overview.A"
          },
          {
            "section": "sections/sec_6d8d3b93",
            "context": " end_ROW(4)Figure 4:Absolute Zero Reasoner Training Overview.A"
          },
          {
            "section": "sections/sec_2f0cfe08",
            "context": "end_ROW(4) Figure 4:Absolute Zero Reasoner Training Overview.A"
          },
          {
            "section": "sections/sec_2f0cfe08",
            "context": "end_ROW(4) Figure 4:Absolute Zero Reasoner Training Overview.A"
          },
          {
            "section": "sections/sec_3d319639",
            "context": "lf-Play Training of Absolute Zero Reasoner (AZR)1:Pretrained b"
          },
          {
            "section": "sections/sec_1020a1e3",
            "context": "lf-Play Training of Absolute Zero Reasoner (AZR)1:Pretrained b"
          },
          {
            "section": "sections/sec_5c55d4bc",
            "context": "-Coder, resulting inAbsolute Zero Reasoner-base-7BandAbsolute "
          },
          {
            "section": "sections/sec_5c55d4bc",
            "context": "-Coder, resulting inAbsolute Zero Reasoner-base-7BandAbsolute "
          },
          {
            "section": "sections/sec_5c55d4bc",
            "context": "-Coder, resulting inAbsolute Zero Reasoner-base-7BandAbsolute "
          },
          {
            "section": "sections/sec_56cabe86",
            "context": "s inTable1. Notably,Absolute Zero Reasoner-Coder-7Bachieves st"
          },
          {
            "section": "sections/sec_56cabe86",
            "context": "s inTable1. Notably,Absolute Zero Reasoner-Coder-7Bachieves st"
          },
          {
            "section": "sections/sec_56cabe86",
            "context": "s inTable1. Notably,Absolute Zero Reasoner-Coder-7Bachieves st"
          },
          {
            "section": "sections/sec_773a923f",
            "context": "s inTable1. Notably,Absolute Zero Reasoner-Coder-7Bachieves st"
          },
          {
            "section": "sections/sec_b69f3870",
            "context": "bilities within the Absolute Zero Reasoner approach."
          },
          {
            "section": "sections/sec_94b98c7f",
            "context": " the next using onlyAbsolute Zero Reasoner-Base-7B. We begin b"
          },
          {
            "section": "sections/sec_ab2bd446",
            "context": " instantiation, the Absolute Zero Reasoner (AZR), which is tra"
          },
          {
            "section": "sections/sec_97b161c9",
            "context": " instantiation, the Absolute Zero Reasoner (AZR), which is tra"
          }
        ]
      },
      {
        "_key": "ent_a5cd3ed1",
        "_id": "entities/ent_a5cd3ed1",
        "name": "Roles",
        "type": "unknown",
        "mentions": [
          {
            "section": "sections/sec_1a5d9820",
            "context": "inAppendixD. 3.1Two Roles in One: Proposer an"
          }
        ]
      },
      {
        "_key": "ent_e77d2db6",
        "_id": "entities/ent_e77d2db6",
        "name": "Proposer",
        "type": "unknown",
        "mentions": [
          {
            "section": "sections/sec_1a5d9820",
            "context": ".1Two Roles in One: Proposer and SolverLarge lan"
          }
        ]
      },
      {
        "_key": "ent_79777c39",
        "_id": "entities/ent_79777c39",
        "name": "Radford",
        "type": "unknown",
        "mentions": [
          {
            "section": "sections/sec_1a5d9820",
            "context": "sk learning context(Radford et\u00a0al.,2019), as bo"
          },
          {
            "section": "sections/sec_6d8d3b93",
            "context": "sk learning context(Radford et\u00a0al.,2019), as bo"
          }
        ]
      },
      {
        "_key": "ent_130c5b34",
        "_id": "entities/ent_130c5b34",
        "name": "Both",
        "type": "unknown",
        "mentions": [
          {
            "section": "sections/sec_1a5d9820",
            "context": "ts model responses. Both task proposal and p"
          },
          {
            "section": "sections/sec_6d8d3b93",
            "context": "ts model responses. Both task proposal and p"
          }
        ]
      },
      {
        "_key": "ent_8e4661a2",
        "_id": "entities/ent_8e4661a2",
        "name": "Reward Design",
        "type": "unknown",
        "mentions": [
          {
            "section": "sections/sec_1a5d9820",
            "context": " used for each role.Reward Design.Prior work has show"
          },
          {
            "section": "sections/sec_6d8d3b93",
            "context": "used for each role. Reward Design.Prior work has show"
          }
        ]
      },
      {
        "_key": "ent_e3d5e887",
        "_id": "entities/ent_e3d5e887",
        "name": "Prior",
        "type": "unknown",
        "mentions": [
          {
            "section": "sections/sec_1a5d9820",
            "context": " role.Reward Design.Prior work has shown that"
          },
          {
            "section": "sections/sec_6d8d3b93",
            "context": "role. Reward Design.Prior work has shown that"
          },
          {
            "section": "sections/sec_2f0cfe08",
            "context": "Prior work has shown that"
          }
        ]
      },
      {
        "_key": "ent_244a92ec",
        "_id": "entities/ent_244a92ec",
        "name": "Zeng",
        "type": "unknown",
        "mentions": [
          {
            "section": "sections/sec_1a5d9820",
            "context": "n reasoning systems(Zeng et\u00a0al.,2025b). Moti"
          },
          {
            "section": "sections/sec_6d8d3b93",
            "context": "n reasoning systems(Zeng et\u00a0al.,2025b). Moti"
          },
          {
            "section": "sections/sec_2f0cfe08",
            "context": "n reasoning systems(Zeng et\u00a0al.,2025b). Moti"
          },
          {
            "section": "sections/sec_5c55d4bc",
            "context": "ants of theAceCoder(Zeng et\u00a0al.,2025a)and tw"
          },
          {
            "section": "sections/sec_5c55d4bc",
            "context": "ants of theAceCoder(Zeng et\u00a0al.,2025a)and tw"
          },
          {
            "section": "sections/sec_5c55d4bc",
            "context": "ants of theAceCoder(Zeng et\u00a0al.,2025a)and tw"
          },
          {
            "section": "sections/sec_5c55d4bc",
            "context": "ants of theAceCoder(Zeng et\u00a0al.,2025a)and tw"
          },
          {
            "section": "sections/sec_6ba6439f",
            "context": "ants of theAceCoder(Zeng et\u00a0al.,2025a)and tw"
          },
          {
            "section": "sections/sec_6ba6439f",
            "context": "ants of theAceCoder(Zeng et\u00a0al.,2025a)and tw"
          },
          {
            "section": "sections/sec_6ba6439f",
            "context": "ants of theAceCoder(Zeng et\u00a0al.,2025a)and tw"
          },
          {
            "section": "sections/sec_f6a941fe",
            "context": "ants of theAceCoder(Zeng et\u00a0al.,2025a)and tw"
          },
          {
            "section": "sections/sec_f6a941fe",
            "context": "ants of theAceCoder(Zeng et\u00a0al.,2025a)and tw"
          },
          {
            "section": "sections/sec_f6a941fe",
            "context": "ants of theAceCoder(Zeng et\u00a0al.,2025a)and tw"
          },
          {
            "section": "sections/sec_56cabe86",
            "context": "g baseline,SimpleRL(Zeng et\u00a0al.,2025b), whic"
          },
          {
            "section": "sections/sec_04cca2bb",
            "context": "g baseline,SimpleRL(Zeng et\u00a0al.,2025b), whic"
          },
          {
            "section": "sections/sec_95e6043e",
            "context": " learning algorithm(Zeng et\u00a0al.,2025b;Liu et"
          },
          {
            "section": "sections/sec_485ba230",
            "context": " learning algorithm(Zeng et\u00a0al.,2025b;Liu et"
          }
        ]
      },
      {
        "_key": "ent_827b1b3d",
        "_id": "entities/ent_827b1b3d",
        "name": "Motivated",
        "type": "unknown",
        "mentions": [
          {
            "section": "sections/sec_1a5d9820",
            "context": "Zeng et\u00a0al.,2025b). Motivated by this, we design "
          },
          {
            "section": "sections/sec_6d8d3b93",
            "context": "Zeng et\u00a0al.,2025b). Motivated by this, we design "
          },
          {
            "section": "sections/sec_2f0cfe08",
            "context": "Zeng et\u00a0al.,2025b). Motivated by this, we design "
          }
        ]
      },
      {
        "_key": "ent_fb778167",
        "_id": "entities/ent_fb778167",
        "name": "Concretely",
        "type": "unknown",
        "mentions": [
          {
            "section": "sections/sec_1a5d9820",
            "context": "the current solver. Concretely, we use the same la"
          },
          {
            "section": "sections/sec_6d8d3b93",
            "context": "the current solver. Concretely, we use the same la"
          },
          {
            "section": "sections/sec_2f0cfe08",
            "context": "the current solver. Concretely, we use the same la"
          }
        ]
      },
      {
        "_key": "ent_40deab2d",
        "_id": "entities/ent_40deab2d",
        "name": "Sukhbaatar",
        "type": "unknown",
        "mentions": [
          {
            "section": "sections/sec_1a5d9820",
            "context": "t design literature(Sukhbaatar et\u00a0al.,2018). We pe"
          },
          {
            "section": "sections/sec_6d8d3b93",
            "context": "t design literature(Sukhbaatar et\u00a0al.,2018). We pe"
          },
          {
            "section": "sections/sec_2f0cfe08",
            "context": "t design literature(Sukhbaatar et\u00a0al.,2018). We pe"
          },
          {
            "section": "sections/sec_95e6043e",
            "context": "symmetric self-play(Sukhbaatar et\u00a0al.,2018;OpenAI "
          },
          {
            "section": "sections/sec_247e121e",
            "context": "symmetric self-play(Sukhbaatar et\u00a0al.,2018;OpenAI "
          }
        ]
      },
      {
        "_key": "ent_2a5a93ca",
        "_id": "entities/ent_2a5a93ca",
        "name": "Carlo",
        "type": "unknown",
        "mentions": [
          {
            "section": "sections/sec_1a5d9820",
            "context": "ormn\ud835\udc5bnitalic_nMonte Carlo rollouts of the sol"
          },
          {
            "section": "sections/sec_6d8d3b93",
            "context": "ormn\ud835\udc5bnitalic_nMonte Carlo rollouts of the sol"
          },
          {
            "section": "sections/sec_2f0cfe08",
            "context": "ormn\ud835\udc5bnitalic_nMonte Carlo rollouts of the sol"
          }
        ]
      },
      {
        "_key": "ent_34e6e3d1",
        "_id": "entities/ent_34e6e3d1",
        "name": "Absolute Zero Reasoner Training Overview",
        "type": "unknown",
        "mentions": [
          {
            "section": "sections/sec_1a5d9820",
            "context": " end_ROW(4)Figure 4:Absolute Zero Reasoner Training Overview.At every iteration,"
          },
          {
            "section": "sections/sec_6d8d3b93",
            "context": " end_ROW(4)Figure 4:Absolute Zero Reasoner Training Overview.At every iteration,"
          },
          {
            "section": "sections/sec_2f0cfe08",
            "context": "end_ROW(4) Figure 4:Absolute Zero Reasoner Training Overview.At every iteration,"
          }
        ]
      },
      {
        "_key": "ent_5da618e8",
        "_id": "entities/ent_5da618e8",
        "name": "From",
        "type": "unknown",
        "mentions": [
          {
            "section": "sections/sec_1a5d9820",
            "context": "ction\u00a0(Section3.2). From these generated tas"
          },
          {
            "section": "sections/sec_6d8d3b93",
            "context": "ction\u00a0(Section3.2). From these generated tas"
          },
          {
            "section": "sections/sec_2f0cfe08",
            "context": "ction\u00a0(Section3.2). From these generated tas"
          }
        ]
      },
      {
        "_key": "ent_a7f5f354",
        "_id": "entities/ent_a7f5f354",
        "name": "Python",
        "type": "unknown",
        "mentions": [
          {
            "section": "sections/sec_1a5d9820",
            "context": "se generated tasks, Python is used to filter a"
          },
          {
            "section": "sections/sec_1a5d9820",
            "context": "se generated tasks, Python is used to filter a"
          },
          {
            "section": "sections/sec_1a5d9820",
            "context": "se generated tasks, Python is used to filter a"
          },
          {
            "section": "sections/sec_1a5d9820",
            "context": "se generated tasks, Python is used to filter a"
          },
          {
            "section": "sections/sec_1a5d9820",
            "context": "se generated tasks, Python is used to filter a"
          },
          {
            "section": "sections/sec_6d8d3b93",
            "context": "se generated tasks, Python is used to filter a"
          },
          {
            "section": "sections/sec_6d8d3b93",
            "context": "se generated tasks, Python is used to filter a"
          },
          {
            "section": "sections/sec_6d8d3b93",
            "context": "se generated tasks, Python is used to filter a"
          },
          {
            "section": "sections/sec_2f0cfe08",
            "context": "se generated tasks, Python is used to filter a"
          },
          {
            "section": "sections/sec_2f0cfe08",
            "context": "se generated tasks, Python is used to filter a"
          },
          {
            "section": "sections/sec_2f0cfe08",
            "context": "se generated tasks, Python is used to filter a"
          },
          {
            "section": "sections/sec_3d319639",
            "context": "egrity.We first use Python to run the programp"
          },
          {
            "section": "sections/sec_3d319639",
            "context": "egrity.We first use Python to run the programp"
          },
          {
            "section": "sections/sec_ff7baeac",
            "context": "egrity.We first use Python to run the programp"
          },
          {
            "section": "sections/sec_ff7baeac",
            "context": "egrity.We first use Python to run the programp"
          },
          {
            "section": "sections/sec_95e6043e",
            "context": " problem space as a Python input/output/functi"
          },
          {
            "section": "sections/sec_247e121e",
            "context": " problem space as a Python input/output/functi"
          }
        ]
      },
      {
        "_key": "ent_e60f3fbe",
        "_id": "entities/ent_e60f3fbe",
        "name": "The Absolute Zero Reasoner",
        "type": "unknown",
        "mentions": [
          {
            "section": "sections/sec_1a5d9820",
            "context": "efined inEquation4. The Absolute Zero Reasoner thenSOLVESthe batch"
          },
          {
            "section": "sections/sec_6d8d3b93",
            "context": "efined inEquation4. The Absolute Zero Reasoner thenSOLVESthe batch"
          },
          {
            "section": "sections/sec_2f0cfe08",
            "context": "efined inEquation4. The Absolute Zero Reasoner thenSOLVESthe batch"
          }
        ]
      },
      {
        "_key": "ent_370964ee",
        "_id": "entities/ent_370964ee",
        "name": "With",
        "type": "unknown",
        "mentions": [
          {
            "section": "sections/sec_1a5d9820",
            "context": "ively\u00a0(Section3.1). Within this self-play tr"
          },
          {
            "section": "sections/sec_6d8d3b93",
            "context": " equality in Python.With the primary rewards"
          },
          {
            "section": "sections/sec_2f0cfe08",
            "context": "equality in Python. With the primary rewards"
          }
        ]
      },
      {
        "_key": "ent_76bdbc44",
        "_id": "entities/ent_76bdbc44",
        "name": "Different Modes",
        "type": "unknown",
        "mentions": [
          {
            "section": "sections/sec_1a5d9820",
            "context": "matted. 3.2Learning Different Modes of Reasoning: Deduc"
          }
        ]
      },
      {
        "_key": "ent_87a22257",
        "_id": "entities/ent_87a22257",
        "name": "Reasoning",
        "type": "unknown",
        "mentions": [
          {
            "section": "sections/sec_1a5d9820",
            "context": " Different Modes of Reasoning: Deduction, Inducti"
          },
          {
            "section": "sections/sec_95e6043e",
            "context": "Reasoning with RL.Using RL to"
          }
        ]
      },
      {
        "_key": "ent_bf05fbc5",
        "_id": "entities/ent_bf05fbc5",
        "name": "Deduction",
        "type": "unknown",
        "mentions": [
          {
            "section": "sections/sec_1a5d9820",
            "context": "Modes of Reasoning: Deduction, Induction, and Abd"
          },
          {
            "section": "sections/sec_1a5d9820",
            "context": "Modes of Reasoning: Deduction, Induction, and Abd"
          },
          {
            "section": "sections/sec_0d24aa19",
            "context": "given the others: 1.Deduction: predicting the out"
          },
          {
            "section": "sections/sec_5c55d4bc",
            "context": "ath Avg.Overall Avg.Deduction onlyDed//54.632.043"
          },
          {
            "section": "sections/sec_56cabe86",
            "context": "ath Avg.Overall Avg.Deduction onlyDed//54.632.043"
          },
          {
            "section": "sections/sec_94b98c7f",
            "context": "ath Avg.Overall Avg.Deduction onlyDed//54.632.043"
          }
        ]
      },
      {
        "_key": "ent_5f76baee",
        "_id": "entities/ent_5f76baee",
        "name": "Induction",
        "type": "unknown",
        "mentions": [
          {
            "section": "sections/sec_1a5d9820",
            "context": "asoning: Deduction, Induction, and AbductionAZR u"
          },
          {
            "section": "sections/sec_1a5d9820",
            "context": "asoning: Deduction, Induction, and AbductionAZR u"
          },
          {
            "section": "sections/sec_0d24aa19",
            "context": "act input matches.3.Induction:synthesizing a prog"
          }
        ]
      },
      {
        "_key": "ent_2f355d9f",
        "_id": "entities/ent_2f355d9f",
        "name": "Give",
        "type": "unknown",
        "mentions": [
          {
            "section": "sections/sec_1a5d9820",
            "context": "abumi et\u00a0al.,2024). Give program space\ud835\udcab\ud835\udcab\\mat"
          },
          {
            "section": "sections/sec_0d24aa19",
            "context": "abumi et\u00a0al.,2024). Give program space\ud835\udcab\ud835\udcab\\mat"
          }
        ]
      },
      {
        "_key": "ent_aaa405a4",
        "_id": "entities/ent_aaa405a4",
        "name": "Abduction",
        "type": "unknown",
        "mentions": [
          {
            "section": "sections/sec_1a5d9820",
            "context": "ion, Induction, and AbductionAZR uses code execut"
          },
          {
            "section": "sections/sec_0d24aa19",
            "context": "ing or fractions).2.Abduction: inferring a plausi"
          }
        ]
      },
      {
        "_key": "ent_38c50b73",
        "_id": "entities/ent_38c50b73",
        "name": "Since",
        "type": "unknown",
        "mentions": [
          {
            "section": "sections/sec_1a5d9820",
            "context": "CRIPT ) = italic_o. Since programs may not be"
          },
          {
            "section": "sections/sec_1a5d9820",
            "context": "CRIPT ) = italic_o. Since programs may not be"
          },
          {
            "section": "sections/sec_1a5d9820",
            "context": "CRIPT ) = italic_o. Since programs may not be"
          },
          {
            "section": "sections/sec_1a5d9820",
            "context": "CRIPT ) = italic_o. Since programs may not be"
          },
          {
            "section": "sections/sec_0d24aa19",
            "context": "CRIPT ) = italic_o. Since programs may not be"
          },
          {
            "section": "sections/sec_0d24aa19",
            "context": "CRIPT ) = italic_o. Since programs may not be"
          },
          {
            "section": "sections/sec_3d319639",
            "context": "c end_POSTSUBSCRIPT.Since the output of proba"
          },
          {
            "section": "sections/sec_3d319639",
            "context": "c end_POSTSUBSCRIPT.Since the output of proba"
          },
          {
            "section": "sections/sec_ff7baeac",
            "context": "c end_POSTSUBSCRIPT.Since the output of proba"
          },
          {
            "section": "sections/sec_730b34d8",
            "context": "Since AZR trains the comb"
          }
        ]
      },
      {
        "_key": "ent_4bd71603",
        "_id": "entities/ent_4bd71603",
        "name": "The Seed",
        "type": "unknown",
        "mentions": [
          {
            "section": "sections/sec_1a5d9820",
            "context": " induction.Figure 5:The Seed AZR Zero Triplet.Th"
          },
          {
            "section": "sections/sec_0d24aa19",
            "context": "induction. Figure 5:The Seed AZR Zero Triplet.Th"
          }
        ]
      },
      {
        "_key": "ent_9be306c4",
        "_id": "entities/ent_9be306c4",
        "name": "Zero Triplet",
        "type": "unknown",
        "mentions": [
          {
            "section": "sections/sec_1a5d9820",
            "context": "gure 5:The Seed AZR Zero Triplet.The above identity "
          },
          {
            "section": "sections/sec_0d24aa19",
            "context": "gure 5:The Seed AZR Zero Triplet.The above identity "
          }
        ]
      },
      {
        "_key": "ent_10ac3d04",
        "_id": "entities/ent_10ac3d04",
        "name": "Next",
        "type": "unknown",
        "mentions": [
          {
            "section": "sections/sec_1a5d9820",
            "context": "6,34,35,39,37and38. Next, we outline exact d"
          },
          {
            "section": "sections/sec_0d24aa19",
            "context": "6,34,35,39,37and38. Next, we outline exact d"
          },
          {
            "section": "sections/sec_5c55d4bc",
            "context": "formance (Ablation)?Next, we ablate two comp"
          },
          {
            "section": "sections/sec_56cabe86",
            "context": "formance (Ablation)?Next, we ablate two comp"
          },
          {
            "section": "sections/sec_bb5ac41e",
            "context": "Next, we ablate two comp"
          }
        ]
      },
      {
        "_key": "ent_04333d3a",
        "_id": "entities/ent_04333d3a",
        "name": "Zero Reasoner Learning",
        "type": "unknown",
        "mentions": [
          {
            "section": "sections/sec_1a5d9820",
            "context": "orithm. 3.3Absolute Zero Reasoner Learning AlgorithmIn this se"
          }
        ]
      },
      {
        "_key": "ent_6bff1838",
        "_id": "entities/ent_6bff1838",
        "name": "During",
        "type": "unknown",
        "mentions": [
          {
            "section": "sections/sec_1a5d9820",
            "context": "let show inFigure5. During the seeding stage, "
          },
          {
            "section": "sections/sec_3d319639",
            "context": "let show inFigure5. During the seeding stage, "
          },
          {
            "section": "sections/sec_4af9d86a",
            "context": "let show inFigure5. During the seeding stage, "
          },
          {
            "section": "sections/sec_1020a1e3",
            "context": "During the actual self-pla"
          }
        ]
      },
      {
        "_key": "ent_7fb55ed0",
        "_id": "entities/ent_7fb55ed0",
        "name": "First",
        "type": "unknown",
        "mentions": [
          {
            "section": "sections/sec_1a5d9820",
            "context": "inFigures34,35and36.First, for deduction and "
          },
          {
            "section": "sections/sec_1a5d9820",
            "context": "inFigures34,35and36.First, for deduction and "
          },
          {
            "section": "sections/sec_3d319639",
            "context": "inFigures34,35and36.First, for deduction and "
          },
          {
            "section": "sections/sec_3d319639",
            "context": "inFigures34,35and36.First, for deduction and "
          },
          {
            "section": "sections/sec_4af9d86a",
            "context": "nFigures34,35and36. First, for deduction and "
          },
          {
            "section": "sections/sec_1020a1e3",
            "context": "uffer in three ways.First, for the proposer o"
          },
          {
            "section": "sections/sec_5c55d4bc",
            "context": "e results inTable2. First, we examine whether"
          },
          {
            "section": "sections/sec_56cabe86",
            "context": "e results inTable2. First, we examine whether"
          },
          {
            "section": "sections/sec_bb5ac41e",
            "context": "e results inTable2. First, we examine whether"
          }
        ]
      },
      {
        "_key": "ent_e31d55ba",
        "_id": "entities/ent_e31d55ba",
        "name": "Similarly",
        "type": "unknown",
        "mentions": [
          {
            "section": "sections/sec_1a5d9820",
            "context": " during this phase. Similarly, to initialize the "
          },
          {
            "section": "sections/sec_1a5d9820",
            "context": " during this phase. Similarly, to initialize the "
          },
          {
            "section": "sections/sec_3d319639",
            "context": " during this phase. Similarly, to initialize the "
          },
          {
            "section": "sections/sec_3d319639",
            "context": " during this phase. Similarly, to initialize the "
          },
          {
            "section": "sections/sec_4af9d86a",
            "context": " during this phase. Similarly, to initialize the "
          },
          {
            "section": "sections/sec_1020a1e3",
            "context": "ts any task reward. Similarly, for induction task"
          },
          {
            "section": "sections/sec_5c55d4bc",
            "context": "oning improvements. Similarly, although also out-"
          },
          {
            "section": "sections/sec_56cabe86",
            "context": "oning improvements. Similarly, although also out-"
          },
          {
            "section": "sections/sec_773a923f",
            "context": "oning improvements. Similarly, although also out-"
          }
        ]
      },
      {
        "_key": "ent_57d70f17",
        "_id": "entities/ent_57d70f17",
        "name": "Proposal Inputs",
        "type": "unknown",
        "mentions": [
          {
            "section": "sections/sec_1a5d9820",
            "context": " italic_S.3.3.2Task Proposal Inputs and Buffer Manageme"
          },
          {
            "section": "sections/sec_3d319639",
            "context": "italic_S. 3.3.2Task Proposal Inputs and Buffer Manageme"
          }
        ]
      },
      {
        "_key": "ent_7e62bc34",
        "_id": "entities/ent_7e62bc34",
        "name": "Buffer",
        "type": "unknown",
        "mentions": [
          {
            "section": "sections/sec_1a5d9820",
            "context": "R inAlgorithm1.3.3.1Buffer InitializationTo in"
          },
          {
            "section": "sections/sec_3d319639",
            "context": " inAlgorithm1. 3.3.1Buffer InitializationTo in"
          }
        ]
      },
      {
        "_key": "ent_c7d42e3d",
        "_id": "entities/ent_c7d42e3d",
        "name": "Zhao",
        "type": "unknown",
        "mentions": [
          {
            "section": "sections/sec_1a5d9820",
            "context": "o promote diversity(Zhao et\u00a0al.,2025a).Secon"
          },
          {
            "section": "sections/sec_1a5d9820",
            "context": "o promote diversity(Zhao et\u00a0al.,2025a).Secon"
          },
          {
            "section": "sections/sec_3d319639",
            "context": "o promote diversity(Zhao et\u00a0al.,2025a).Secon"
          },
          {
            "section": "sections/sec_3d319639",
            "context": "o promote diversity(Zhao et\u00a0al.,2025a).Secon"
          },
          {
            "section": "sections/sec_1020a1e3",
            "context": "o promote diversity(Zhao et\u00a0al.,2025a).Secon"
          },
          {
            "section": "sections/sec_730b34d8",
            "context": "p(Zhang & Yang,2021;Zhao et\u00a0al.,2022;Wang et"
          },
          {
            "section": "sections/sec_95e6043e",
            "context": "(Laskin et\u00a0al.,2021;Zhao et\u00a0al.,2022;2025b),"
          },
          {
            "section": "sections/sec_247e121e",
            "context": "(Laskin et\u00a0al.,2021;Zhao et\u00a0al.,2022;2025b),"
          }
        ]
      },
      {
        "_key": "ent_c22cf837",
        "_id": "entities/ent_c22cf837",
        "name": "Second",
        "type": "unknown",
        "mentions": [
          {
            "section": "sections/sec_1a5d9820",
            "context": "(Zhao et\u00a0al.,2025a).Second, we sample one trip"
          },
          {
            "section": "sections/sec_3d319639",
            "context": "(Zhao et\u00a0al.,2025a).Second, we sample one trip"
          },
          {
            "section": "sections/sec_1020a1e3",
            "context": "(Zhao et\u00a0al.,2025a).Second, we sample one trip"
          }
        ]
      },
      {
        "_key": "ent_98fef2d5",
        "_id": "entities/ent_98fef2d5",
        "name": "Lastly",
        "type": "unknown",
        "mentions": [
          {
            "section": "sections/sec_1a5d9820",
            "context": " messagem\ud835\udc5amitalic_m.Lastly, to maintain stable"
          },
          {
            "section": "sections/sec_3d319639",
            "context": " messagem\ud835\udc5amitalic_m.Lastly, to maintain stable"
          },
          {
            "section": "sections/sec_1020a1e3",
            "context": " messagem\ud835\udc5amitalic_m.Lastly, to maintain stable"
          }
        ]
      },
      {
        "_key": "ent_4afa80e7",
        "_id": "entities/ent_4afa80e7",
        "name": "Algorithm",
        "type": "unknown",
        "mentions": [
          {
            "section": "sections/sec_1a5d9820",
            "context": "overall algorithm inAlgorithm1and highlight an il"
          },
          {
            "section": "sections/sec_3d319639",
            "context": " procedure of AZR inAlgorithm1. 3.3.1Buffer Initi"
          },
          {
            "section": "sections/sec_1020a1e3",
            "context": "dded to the buffer. Algorithm 1Self-Play Training"
          }
        ]
      },
      {
        "_key": "ent_d994b6e9",
        "_id": "entities/ent_d994b6e9",
        "name": "Play Training",
        "type": "unknown",
        "mentions": [
          {
            "section": "sections/sec_1a5d9820",
            "context": "fer.Algorithm 1Self-Play Training of Absolute Zero Re"
          },
          {
            "section": "sections/sec_3d319639",
            "context": "fer.Algorithm 1Self-Play Training of Absolute Zero Re"
          },
          {
            "section": "sections/sec_1020a1e3",
            "context": "er. Algorithm 1Self-Play Training of Absolute Zero Re"
          }
        ]
      },
      {
        "_key": "ent_8296e3db",
        "_id": "entities/ent_8296e3db",
        "name": "Pretrained",
        "type": "unknown",
        "mentions": [
          {
            "section": "sections/sec_1a5d9820",
            "context": "ero Reasoner (AZR)1:Pretrained base LLM\u03c0\u03b8subscript"
          },
          {
            "section": "sections/sec_3d319639",
            "context": "ero Reasoner (AZR)1:Pretrained base LLM\u03c0\u03b8subscript"
          },
          {
            "section": "sections/sec_1020a1e3",
            "context": "ero Reasoner (AZR)1:Pretrained base LLM\u03c0\u03b8subscript"
          }
        ]
      },
      {
        "_key": "ent_35281ac0",
        "_id": "entities/ent_35281ac0",
        "name": "Reward",
        "type": "unknown",
        "mentions": [
          {
            "section": "sections/sec_1a5d9820",
            "context": " used for each role.Reward Design.Prior work h"
          },
          {
            "section": "sections/sec_3d319639",
            "context": "RIPT ( italic_x )17:Reward:Use proposed task t"
          },
          {
            "section": "sections/sec_1020a1e3",
            "context": "RIPT ( italic_x )17:Reward:Use proposed task t"
          }
        ]
      },
      {
        "_key": "ent_e9be9e95",
        "_id": "entities/ent_e9be9e95",
        "name": "Task Relative",
        "type": "unknown",
        "mentions": [
          {
            "section": "sections/sec_1a5d9820",
            "context": "3.118:RL update:use Task Relative REINFORCE++ to upda"
          },
          {
            "section": "sections/sec_3d319639",
            "context": "3.118:RL update:use Task Relative REINFORCE++ to upda"
          },
          {
            "section": "sections/sec_1020a1e3",
            "context": "3.118:RL update:use Task Relative REINFORCE++ to upda"
          }
        ]
      },
      {
        "_key": "ent_3ac705f2",
        "_id": "entities/ent_3ac705f2",
        "name": "Valid",
        "type": "unknown",
        "mentions": [
          {
            "section": "sections/sec_1a5d9820",
            "context": "7:if{(i\u03c0n,o\u03c0n)}n=1N\u2190ValidateByExecuting\u2062(p,{i"
          },
          {
            "section": "sections/sec_3d319639",
            "context": "7:if{(i\u03c0n,o\u03c0n)}n=1N\u2190ValidateByExecuting\u2062(p,{i"
          }
        ]
      },
      {
        "_key": "ent_ea2da2ac",
        "_id": "entities/ent_ea2da2ac",
        "name": "Task Validation",
        "type": "unknown",
        "mentions": [
          {
            "section": "sections/sec_1a5d9820",
            "context": "Valid TasksProposal Task Validation.We first describe h"
          },
          {
            "section": "sections/sec_3d319639",
            "context": "Valid TasksProposal Task Validation.We first describe h"
          }
        ]
      },
      {
        "_key": "ent_9c674ba8",
        "_id": "entities/ent_9c674ba8",
        "name": "Fordeduction",
        "type": "unknown",
        "mentions": [
          {
            "section": "sections/sec_1a5d9820",
            "context": "olicy\u03c0\ud835\udf0b\\piitalic_\u03c0. Fordeduction and abductiontasks,"
          },
          {
            "section": "sections/sec_3d319639",
            "context": "olicy\u03c0\ud835\udf0b\\piitalic_\u03c0. Fordeduction and abductiontasks,"
          },
          {
            "section": "sections/sec_ff7baeac",
            "context": "olicy\u03c0\ud835\udf0b\\piitalic_\u03c0. Fordeduction and abductiontasks,"
          }
        ]
      },
      {
        "_key": "ent_8cd58a62",
        "_id": "entities/ent_8cd58a62",
        "name": "Forinductiontasks",
        "type": "unknown",
        "mentions": [
          {
            "section": "sections/sec_1a5d9820",
            "context": "lic_i , italic_o ). Forinductiontasks, given a programp\ud835\udc5dp"
          },
          {
            "section": "sections/sec_3d319639",
            "context": "lic_i , italic_o ). Forinductiontasks, given a programp\ud835\udc5dp"
          },
          {
            "section": "sections/sec_ff7baeac",
            "context": "lic_i , italic_o ). Forinductiontasks, given a programp\ud835\udc5dp"
          }
        ]
      },
      {
        "_key": "ent_c37ac867",
        "_id": "entities/ent_c37ac867",
        "name": "Thetask",
        "type": "unknown",
        "mentions": [
          {
            "section": "sections/sec_1a5d9820",
            "context": "ents are satisfied. Thetask validation procedur"
          },
          {
            "section": "sections/sec_3d319639",
            "context": "ents are satisfied. Thetask validation procedur"
          },
          {
            "section": "sections/sec_ff7baeac",
            "context": "ents are satisfied. Thetask validation procedur"
          }
        ]
      },
      {
        "_key": "ent_298afc25",
        "_id": "entities/ent_298afc25",
        "name": "Program Integrity",
        "type": "unknown",
        "mentions": [
          {
            "section": "sections/sec_1a5d9820",
            "context": " procedureentails:1.Program Integrity.We first use Python"
          },
          {
            "section": "sections/sec_3d319639",
            "context": " procedureentails:1.Program Integrity.We first use Python"
          },
          {
            "section": "sections/sec_ff7baeac",
            "context": "procedureentails: 1.Program Integrity.We first use Python"
          }
        ]
      },
      {
        "_key": "ent_5d3a70a7",
        "_id": "entities/ent_5d3a70a7",
        "name": "Program Safety",
        "type": "unknown",
        "mentions": [
          {
            "section": "sections/sec_1a5d9820",
            "context": " has valid syntax.2.Program Safety.We also check wheth"
          },
          {
            "section": "sections/sec_3d319639",
            "context": " has valid syntax.2.Program Safety.We also check wheth"
          },
          {
            "section": "sections/sec_ff7baeac",
            "context": " has valid syntax.2.Program Safety.We also check wheth"
          }
        ]
      },
      {
        "_key": "ent_060bf2d5",
        "_id": "entities/ent_060bf2d5",
        "name": "Check",
        "type": "unknown",
        "mentions": [
          {
            "section": "sections/sec_1a5d9820",
            "context": "Figures34,35and36.3.Check for Determinism.In "
          },
          {
            "section": "sections/sec_3d319639",
            "context": "Figures34,35and36.3.Check for Determinism.In "
          },
          {
            "section": "sections/sec_ff7baeac",
            "context": "Figures34,35and36.3.Check for Determinism.In "
          }
        ]
      },
      {
        "_key": "ent_700de0d7",
        "_id": "entities/ent_700de0d7",
        "name": "Determinism",
        "type": "unknown",
        "mentions": [
          {
            "section": "sections/sec_1a5d9820",
            "context": "35and36.3.Check for Determinism.In our setting, we "
          },
          {
            "section": "sections/sec_3d319639",
            "context": "35and36.3.Check for Determinism.In our setting, we "
          },
          {
            "section": "sections/sec_ff7baeac",
            "context": "35and36.3.Check for Determinism.In our setting, we "
          }
        ]
      },
      {
        "_key": "ent_70dc9df8",
        "_id": "entities/ent_70dc9df8",
        "name": "Avalid",
        "type": "unknown",
        "mentions": [
          {
            "section": "sections/sec_1a5d9820",
            "context": "ion of the program. Avalid program/input/outpu"
          },
          {
            "section": "sections/sec_3d319639",
            "context": "ion of the program. Avalid program/input/outpu"
          },
          {
            "section": "sections/sec_ff7baeac",
            "context": "ion of the program. Avalid program/input/outpu"
          }
        ]
      },
      {
        "_key": "ent_1f4771f8",
        "_id": "entities/ent_1f4771f8",
        "name": "Therefore",
        "type": "unknown",
        "mentions": [
          {
            "section": "sections/sec_1a5d9820",
            "context": "tness of an answer. Therefore, to keep the verifi"
          },
          {
            "section": "sections/sec_3d319639",
            "context": "tness of an answer. Therefore, to keep the verifi"
          },
          {
            "section": "sections/sec_ff7baeac",
            "context": "tness of an answer. Therefore, to keep the verifi"
          },
          {
            "section": "sections/sec_5c55d4bc",
            "context": "ance final answers. Therefore, it may be benefici"
          },
          {
            "section": "sections/sec_56cabe86",
            "context": "ance final answers. Therefore, it may be benefici"
          },
          {
            "section": "sections/sec_72c37985",
            "context": "ance final answers. Therefore, it may be benefici"
          }
        ]
      },
      {
        "_key": "ent_c05d7d4f",
        "_id": "entities/ent_c05d7d4f",
        "name": "Solving Task Construction",
        "type": "unknown",
        "mentions": [
          {
            "section": "sections/sec_1a5d9820",
            "context": "for all experiments.Solving Task Construction.If a task proposal "
          },
          {
            "section": "sections/sec_3d319639",
            "context": "for all experiments.Solving Task Construction.If a task proposal "
          },
          {
            "section": "sections/sec_ff7baeac",
            "context": "or all experiments. Solving Task Construction.If a task proposal "
          }
        ]
      },
      {
        "_key": "ent_29b5a122",
        "_id": "entities/ent_29b5a122",
        "name": "Specifically",
        "type": "unknown",
        "mentions": [
          {
            "section": "sections/sec_1a5d9820",
            "context": "plet to the solver. Specifically, we setx=(p,i)\ud835\udc65\ud835\udc5d\ud835\udc56x="
          },
          {
            "section": "sections/sec_3d319639",
            "context": "plet to the solver. Specifically, we setx=(p,i)\ud835\udc65\ud835\udc5d\ud835\udc56x="
          },
          {
            "section": "sections/sec_ff7baeac",
            "context": "plet to the solver. Specifically, we setx=(p,i)\ud835\udc65\ud835\udc5d\ud835\udc56x="
          }
        ]
      },
      {
        "_key": "ent_2ca94698",
        "_id": "entities/ent_2ca94698",
        "name": "Relative",
        "type": "unknown",
        "mentions": [
          {
            "section": "sections/sec_1a5d9820",
            "context": ":RL update:use Task Relative REINFORCE++ to upda"
          },
          {
            "section": "sections/sec_1a5d9820",
            "context": ":RL update:use Task Relative REINFORCE++ to upda"
          },
          {
            "section": "sections/sec_3d319639",
            "context": ":RL update:use Task Relative REINFORCE++ to upda"
          },
          {
            "section": "sections/sec_3d319639",
            "context": ":RL update:use Task Relative REINFORCE++ to upda"
          },
          {
            "section": "sections/sec_730b34d8",
            "context": "this variant asTask-Relative REINFORCE++ (TRR++)"
          }
        ]
      },
      {
        "_key": "ent_2422f0f0",
        "_id": "entities/ent_2422f0f0",
        "name": "Yang",
        "type": "unknown",
        "mentions": [
          {
            "section": "sections/sec_1a5d9820",
            "context": "rning setup(Zhang & Yang,2021;Zhao et\u00a0al.,20"
          },
          {
            "section": "sections/sec_3d319639",
            "context": "rning setup(Zhang & Yang,2021;Zhao et\u00a0al.,20"
          },
          {
            "section": "sections/sec_730b34d8",
            "context": "rning setup(Zhang & Yang,2021;Zhao et\u00a0al.,20"
          },
          {
            "section": "sections/sec_5c55d4bc",
            "context": ".5-14B,Llama-3.1-8B(Yang et\u00a0al.,2024a;Hui et"
          },
          {
            "section": "sections/sec_5c55d4bc",
            "context": ".5-14B,Llama-3.1-8B(Yang et\u00a0al.,2024a;Hui et"
          },
          {
            "section": "sections/sec_5c55d4bc",
            "context": ".5-14B,Llama-3.1-8B(Yang et\u00a0al.,2024a;Hui et"
          },
          {
            "section": "sections/sec_6ba6439f",
            "context": ".5-14B,Llama-3.1-8B(Yang et\u00a0al.,2024a;Hui et"
          },
          {
            "section": "sections/sec_6ba6439f",
            "context": ".5-14B,Llama-3.1-8B(Yang et\u00a0al.,2024a;Hui et"
          },
          {
            "section": "sections/sec_6ba6439f",
            "context": ".5-14B,Llama-3.1-8B(Yang et\u00a0al.,2024a;Hui et"
          },
          {
            "section": "sections/sec_ba8c62bf",
            "context": ".5-14B,Llama-3.1-8B(Yang et\u00a0al.,2024a;Hui et"
          },
          {
            "section": "sections/sec_f6a941fe",
            "context": " andQwen2.5-Math-7B(Yang et\u00a0al.,2024a;Hui et"
          },
          {
            "section": "sections/sec_f6a941fe",
            "context": " andQwen2.5-Math-7B(Yang et\u00a0al.,2024a;Hui et"
          }
        ]
      },
      {
        "_key": "ent_957b05eb",
        "_id": "entities/ent_957b05eb",
        "name": "Wang",
        "type": "unknown",
        "mentions": [
          {
            "section": "sections/sec_1a5d9820",
            "context": "21;Zhao et\u00a0al.,2022;Wang et\u00a0al.,2023;Yue et\u00a0"
          },
          {
            "section": "sections/sec_3d319639",
            "context": "21;Zhao et\u00a0al.,2022;Wang et\u00a0al.,2023;Yue et\u00a0"
          },
          {
            "section": "sections/sec_730b34d8",
            "context": "21;Zhao et\u00a0al.,2022;Wang et\u00a0al.,2023;Yue et\u00a0"
          },
          {
            "section": "sections/sec_95e6043e",
            "context": "rmance of thousands(Wang et\u00a0al.,2025b). We e"
          },
          {
            "section": "sections/sec_95e6043e",
            "context": "rmance of thousands(Wang et\u00a0al.,2025b). We e"
          },
          {
            "section": "sections/sec_485ba230",
            "context": "rmance of thousands(Wang et\u00a0al.,2025b). We e"
          },
          {
            "section": "sections/sec_247e121e",
            "context": " environment design(Wang et\u00a0al.,2019;Dennis "
          }
        ]
      },
      {
        "_key": "ent_4c4a9cf4",
        "_id": "entities/ent_4c4a9cf4",
        "name": "Instead",
        "type": "unknown",
        "mentions": [
          {
            "section": "sections/sec_1a5d9820",
            "context": "3;Yue et\u00a0al.,2023). Instead of computing a sing"
          },
          {
            "section": "sections/sec_3d319639",
            "context": "3;Yue et\u00a0al.,2023). Instead of computing a sing"
          },
          {
            "section": "sections/sec_730b34d8",
            "context": "3;Yue et\u00a0al.,2023). Instead of computing a sing"
          },
          {
            "section": "sections/sec_5c55d4bc",
            "context": "he proposer at all. Instead, we only prompt it "
          },
          {
            "section": "sections/sec_56cabe86",
            "context": "he proposer at all. Instead, we only prompt it "
          },
          {
            "section": "sections/sec_bb5ac41e",
            "context": "he proposer at all. Instead, we only prompt it "
          }
        ]
      },
      {
        "_key": "ent_c2860167",
        "_id": "entities/ent_c2860167",
        "name": "Shao",
        "type": "unknown",
        "mentions": [
          {
            "section": "sections/sec_1a5d9820",
            "context": "selines, as in GRPO(Shao et\u00a0al.,2024), and a"
          },
          {
            "section": "sections/sec_3d319639",
            "context": "selines, as in GRPO(Shao et\u00a0al.,2024), and a"
          },
          {
            "section": "sections/sec_730b34d8",
            "context": "selines, as in GRPO(Shao et\u00a0al.,2024), and a"
          }
        ]
      },
      {
        "_key": "ent_6513376e",
        "_id": "entities/ent_6513376e",
        "name": "Atask",
        "type": "unknown",
        "mentions": [
          {
            "section": "sections/sec_1a5d9820",
            "context": "CRIPTis computed as:Atask,rolenorm=r\u2212\u03bctask,ro"
          },
          {
            "section": "sections/sec_3d319639",
            "context": "CRIPTis computed as:Atask,rolenorm=r\u2212\u03bctask,ro"
          },
          {
            "section": "sections/sec_730b34d8",
            "context": "CRIPTis computed as:Atask,rolenorm=r\u2212\u03bctask,ro"
          }
        ]
      },
      {
        "_key": "ent_3caac635",
        "_id": "entities/ent_3caac635",
        "name": "Proposal Task Validation",
        "type": "unknown",
        "mentions": [
          {
            "section": "sections/sec_ff7baeac",
            "context": "Proposal Task Validation.We first describe h"
          }
        ]
      },
      {
        "_key": "ent_3ec365dd",
        "_id": "entities/ent_3ec365dd",
        "name": "Details",
        "type": "unknown",
        "mentions": [
          {
            "section": "sections/sec_5c55d4bc",
            "context": "iment SetupTraining Details.For all experiments"
          }
        ]
      },
      {
        "_key": "ent_bbb8cd10",
        "_id": "entities/ent_bbb8cd10",
        "name": "Loshchilov",
        "type": "unknown",
        "mentions": [
          {
            "section": "sections/sec_5c55d4bc",
            "context": "the AdamW optimizer(Loshchilov & Hutter,2019). Com"
          },
          {
            "section": "sections/sec_6ba6439f",
            "context": "the AdamW optimizer(Loshchilov & Hutter,2019). Com"
          },
          {
            "section": "sections/sec_ba8c62bf",
            "context": "the AdamW optimizer(Loshchilov & Hutter,2019). Com"
          }
        ]
      },
      {
        "_key": "ent_300ba426",
        "_id": "entities/ent_300ba426",
        "name": "Hutter",
        "type": "unknown",
        "mentions": [
          {
            "section": "sections/sec_5c55d4bc",
            "context": "imizer(Loshchilov & Hutter,2019). Complete lis"
          },
          {
            "section": "sections/sec_6ba6439f",
            "context": "imizer(Loshchilov & Hutter,2019). Complete lis"
          },
          {
            "section": "sections/sec_ba8c62bf",
            "context": "imizer(Loshchilov & Hutter,2019). Complete lis"
          }
        ]
      },
      {
        "_key": "ent_ae94f80b",
        "_id": "entities/ent_ae94f80b",
        "name": "Complete",
        "type": "unknown",
        "mentions": [
          {
            "section": "sections/sec_5c55d4bc",
            "context": "lov & Hutter,2019). Complete list of hyperparame"
          },
          {
            "section": "sections/sec_6ba6439f",
            "context": "lov & Hutter,2019). Complete list of hyperparame"
          },
          {
            "section": "sections/sec_ba8c62bf",
            "context": "lov & Hutter,2019). Complete list of hyperparame"
          }
        ]
      },
      {
        "_key": "ent_27b948ac",
        "_id": "entities/ent_27b948ac",
        "name": "Additional",
        "type": "unknown",
        "mentions": [
          {
            "section": "sections/sec_5c55d4bc",
            "context": "r-7B, respectively. Additional experiments include"
          },
          {
            "section": "sections/sec_6ba6439f",
            "context": "r-7B, respectively. Additional experiments include"
          },
          {
            "section": "sections/sec_ba8c62bf",
            "context": "r-7B, respectively. Additional experiments include"
          }
        ]
      },
      {
        "_key": "ent_9ef4f785",
        "_id": "entities/ent_9ef4f785",
        "name": "Llama",
        "type": "unknown",
        "mentions": [
          {
            "section": "sections/sec_5c55d4bc",
            "context": "der-14B,Qwen2.5-14B,Llama-3.1-8B(Yang et\u00a0al.,"
          },
          {
            "section": "sections/sec_5c55d4bc",
            "context": "der-14B,Qwen2.5-14B,Llama-3.1-8B(Yang et\u00a0al.,"
          },
          {
            "section": "sections/sec_5c55d4bc",
            "context": "der-14B,Qwen2.5-14B,Llama-3.1-8B(Yang et\u00a0al.,"
          },
          {
            "section": "sections/sec_6ba6439f",
            "context": "der-14B,Qwen2.5-14B,Llama-3.1-8B(Yang et\u00a0al.,"
          },
          {
            "section": "sections/sec_ba8c62bf",
            "context": "der-14B,Qwen2.5-14B,Llama-3.1-8B(Yang et\u00a0al.,"
          },
          {
            "section": "sections/sec_56cabe86",
            "context": "AvgMath AvgTotal AvgLlama3.1-8b28.53.416.0Lla"
          },
          {
            "section": "sections/sec_56cabe86",
            "context": "AvgMath AvgTotal AvgLlama3.1-8b28.53.416.0Lla"
          },
          {
            "section": "sections/sec_72c37985",
            "context": "gnitive Behavior in Llama.Interestingly, we a"
          },
          {
            "section": "sections/sec_72c37985",
            "context": "gnitive Behavior in Llama.Interestingly, we a"
          }
        ]
      },
      {
        "_key": "ent_52560fd5",
        "_id": "entities/ent_52560fd5",
        "name": "Dubey",
        "type": "unknown",
        "mentions": [
          {
            "section": "sections/sec_5c55d4bc",
            "context": "24a;Hui et\u00a0al.,2024;Dubey et\u00a0al.,2024).Evalua"
          },
          {
            "section": "sections/sec_6ba6439f",
            "context": "24a;Hui et\u00a0al.,2024;Dubey et\u00a0al.,2024). Evalu"
          },
          {
            "section": "sections/sec_ba8c62bf",
            "context": "24a;Hui et\u00a0al.,2024;Dubey et\u00a0al.,2024)."
          }
        ]
      },
      {
        "_key": "ent_aaefd6f8",
        "_id": "entities/ent_aaefd6f8",
        "name": "Evaluation Protocol",
        "type": "unknown",
        "mentions": [
          {
            "section": "sections/sec_5c55d4bc",
            "context": ";Dubey et\u00a0al.,2024).Evaluation Protocol.To evaluate our mod"
          },
          {
            "section": "sections/sec_6ba6439f",
            "context": "Dubey et\u00a0al.,2024). Evaluation Protocol.To evaluate our mod"
          }
        ]
      },
      {
        "_key": "ent_03aa8029",
        "_id": "entities/ent_03aa8029",
        "name": "Evalplus",
        "type": "unknown",
        "mentions": [
          {
            "section": "sections/sec_5c55d4bc",
            "context": ", we evaluate using Evalplus(Liu et\u00a0al.,2023)on "
          },
          {
            "section": "sections/sec_6ba6439f",
            "context": ", we evaluate using Evalplus(Liu et\u00a0al.,2023)on "
          },
          {
            "section": "sections/sec_4b5715ec",
            "context": ", we evaluate using Evalplus(Liu et\u00a0al.,2023)on "
          }
        ]
      },
      {
        "_key": "ent_e6a79fd8",
        "_id": "entities/ent_e6a79fd8",
        "name": "Generation",
        "type": "unknown",
        "mentions": [
          {
            "section": "sections/sec_5c55d4bc",
            "context": "ll as LiveCodeBench Generation (v1-5, May 23-Feb 2"
          },
          {
            "section": "sections/sec_6ba6439f",
            "context": "ll as LiveCodeBench Generation (v1-5, May 23-Feb 2"
          },
          {
            "section": "sections/sec_4b5715ec",
            "context": "ll as LiveCodeBench Generation (v1-5, May 23-Feb 2"
          }
        ]
      },
      {
        "_key": "ent_3c5ba135",
        "_id": "entities/ent_3c5ba135",
        "name": "Jain",
        "type": "unknown",
        "mentions": [
          {
            "section": "sections/sec_5c55d4bc",
            "context": "1-5, May 23-Feb 25)(Jain et\u00a0al.,2024). For m"
          },
          {
            "section": "sections/sec_5c55d4bc",
            "context": "1-5, May 23-Feb 25)(Jain et\u00a0al.,2024). For m"
          },
          {
            "section": "sections/sec_6ba6439f",
            "context": "1-5, May 23-Feb 25)(Jain et\u00a0al.,2024). For m"
          },
          {
            "section": "sections/sec_6ba6439f",
            "context": "1-5, May 23-Feb 25)(Jain et\u00a0al.,2024). For m"
          },
          {
            "section": "sections/sec_4b5715ec",
            "context": "1-5, May 23-Feb 25)(Jain et\u00a0al.,2024). For m"
          },
          {
            "section": "sections/sec_4b5715ec",
            "context": "1-5, May 23-Feb 25)(Jain et\u00a0al.,2024). For m"
          }
        ]
      },
      {
        "_key": "ent_931603f1",
        "_id": "entities/ent_931603f1",
        "name": "Minerva",
        "type": "unknown",
        "mentions": [
          {
            "section": "sections/sec_5c55d4bc",
            "context": "ch(He et\u00a0al.,2024), Minerva, Math500(Hendrycks "
          },
          {
            "section": "sections/sec_5c55d4bc",
            "context": "ch(He et\u00a0al.,2024), Minerva, Math500(Hendrycks "
          },
          {
            "section": "sections/sec_6ba6439f",
            "context": "ch(He et\u00a0al.,2024), Minerva, Math500(Hendrycks "
          },
          {
            "section": "sections/sec_4b5715ec",
            "context": "ch(He et\u00a0al.,2024), Minerva, Math500(Hendrycks "
          },
          {
            "section": "sections/sec_56cabe86",
            "context": "5, AMC\u201923, MATH500, Minerva, OlympiadBench). Av"
          }
        ]
      },
      {
        "_key": "ent_8543783d",
        "_id": "entities/ent_8543783d",
        "name": "Hendrycks",
        "type": "unknown",
        "mentions": [
          {
            "section": "sections/sec_5c55d4bc",
            "context": "), Minerva, Math500(Hendrycks et\u00a0al.,2021), and A"
          },
          {
            "section": "sections/sec_6ba6439f",
            "context": "), Minerva, Math500(Hendrycks et\u00a0al.,2021), and A"
          },
          {
            "section": "sections/sec_4b5715ec",
            "context": "), Minerva, Math500(Hendrycks et\u00a0al.,2021), and A"
          }
        ]
      },
      {
        "_key": "ent_8f44785c",
        "_id": "entities/ent_8f44785c",
        "name": "Execution",
        "type": "unknown",
        "mentions": [
          {
            "section": "sections/sec_5c55d4bc",
            "context": ", and LiveCodeBench-Execution(Gu et\u00a0al.,2024;Jain"
          },
          {
            "section": "sections/sec_5c55d4bc",
            "context": ", and LiveCodeBench-Execution(Gu et\u00a0al.,2024;Jain"
          },
          {
            "section": "sections/sec_6ba6439f",
            "context": ", and LiveCodeBench-Execution(Gu et\u00a0al.,2024;Jain"
          },
          {
            "section": "sections/sec_4b5715ec",
            "context": ", and LiveCodeBench-Execution(Gu et\u00a0al.,2024;Jain"
          },
          {
            "section": "sections/sec_56cabe86",
            "context": ", and LiveCodeBench-Execution, which correspond t"
          },
          {
            "section": "sections/sec_9cc89151",
            "context": ", and LiveCodeBench-Execution, which correspond t"
          }
        ]
      },
      {
        "_key": "ent_bb6c5ecb",
        "_id": "entities/ent_bb6c5ecb",
        "name": "Greedy",
        "type": "unknown",
        "mentions": [
          {
            "section": "sections/sec_5c55d4bc",
            "context": "ams(Li et\u00a0al.,2025).Greedy decodingis used for"
          },
          {
            "section": "sections/sec_6ba6439f",
            "context": "ams(Li et\u00a0al.,2025).Greedy decodingis used for"
          },
          {
            "section": "sections/sec_4b5715ec",
            "context": "ams(Li et\u00a0al.,2025).Greedy decodingis used for"
          }
        ]
      },
      {
        "_key": "ent_e6165364",
        "_id": "entities/ent_e6165364",
        "name": "Baselines",
        "type": "unknown",
        "mentions": [
          {
            "section": "sections/sec_5c55d4bc",
            "context": "ure reproducibility.Baselines.For our main result"
          },
          {
            "section": "sections/sec_6ba6439f",
            "context": "re reproducibility. Baselines.For our main result"
          }
        ]
      },
      {
        "_key": "ent_fbc39220",
        "_id": "entities/ent_fbc39220",
        "name": "Instruct",
        "type": "unknown",
        "mentions": [
          {
            "section": "sections/sec_5c55d4bc",
            "context": "7B-Coder,Qwen2.5-7B-Instruct, andQwen2.5-Math-7B"
          },
          {
            "section": "sections/sec_6ba6439f",
            "context": "7B-Coder,Qwen2.5-7B-Instruct, andQwen2.5-Math-7B"
          },
          {
            "section": "sections/sec_f6a941fe",
            "context": "7B-Coder,Qwen2.5-7B-Instruct, andQwen2.5-Math-7B"
          }
        ]
      },
      {
        "_key": "ent_a49950aa",
        "_id": "entities/ent_a49950aa",
        "name": "Math",
        "type": "unknown",
        "mentions": [
          {
            "section": "sections/sec_5c55d4bc",
            "context": "al.,2024), Minerva, Math500(Hendrycks et\u00a0al."
          },
          {
            "section": "sections/sec_5c55d4bc",
            "context": "al.,2024), Minerva, Math500(Hendrycks et\u00a0al."
          },
          {
            "section": "sections/sec_5c55d4bc",
            "context": "al.,2024), Minerva, Math500(Hendrycks et\u00a0al."
          },
          {
            "section": "sections/sec_6ba6439f",
            "context": "al.,2024), Minerva, Math500(Hendrycks et\u00a0al."
          },
          {
            "section": "sections/sec_6ba6439f",
            "context": "al.,2024), Minerva, Math500(Hendrycks et\u00a0al."
          },
          {
            "section": "sections/sec_f6a941fe",
            "context": "nstruct, andQwen2.5-Math-7B(Yang et\u00a0al.,2024"
          },
          {
            "section": "sections/sec_f6a941fe",
            "context": "nstruct, andQwen2.5-Math-7B(Yang et\u00a0al.,2024"
          },
          {
            "section": "sections/sec_56cabe86",
            "context": "623.940.2Qwen2.5-7B-Math[74]--61.057.916.210"
          }
        ]
      },
      {
        "_key": "ent_d7ed4ee1",
        "_id": "entities/ent_d7ed4ee1",
        "name": "Zero",
        "type": "unknown",
        "mentions": [
          {
            "section": "sections/sec_5c55d4bc",
            "context": "esulting inAbsolute Zero Reasoner-base-7Band"
          },
          {
            "section": "sections/sec_5c55d4bc",
            "context": "esulting inAbsolute Zero Reasoner-base-7Band"
          },
          {
            "section": "sections/sec_5c55d4bc",
            "context": "esulting inAbsolute Zero Reasoner-base-7Band"
          },
          {
            "section": "sections/sec_5c55d4bc",
            "context": "esulting inAbsolute Zero Reasoner-base-7Band"
          },
          {
            "section": "sections/sec_5c55d4bc",
            "context": "esulting inAbsolute Zero Reasoner-base-7Band"
          },
          {
            "section": "sections/sec_6ba6439f",
            "context": "esulting inAbsolute Zero Reasoner-base-7Band"
          },
          {
            "section": "sections/sec_6ba6439f",
            "context": "esulting inAbsolute Zero Reasoner-base-7Band"
          },
          {
            "section": "sections/sec_6ba6439f",
            "context": "esulting inAbsolute Zero Reasoner-base-7Band"
          },
          {
            "section": "sections/sec_f6a941fe",
            "context": "nlyEurus-2-7B-PRIME-Zero(Cui et\u00a0al.,2025)was"
          },
          {
            "section": "sections/sec_f6a941fe",
            "context": "nlyEurus-2-7B-PRIME-Zero(Cui et\u00a0al.,2025)was"
          },
          {
            "section": "sections/sec_f6a941fe",
            "context": "nlyEurus-2-7B-PRIME-Zero(Cui et\u00a0al.,2025)was"
          },
          {
            "section": "sections/sec_56cabe86",
            "context": "15.428.045.029.537.3Zero-Style Reasoners Tra"
          },
          {
            "section": "sections/sec_56cabe86",
            "context": "15.428.045.029.537.3Zero-Style Reasoners Tra"
          }
        ]
      },
      {
        "_key": "ent_c3bf447e",
        "_id": "entities/ent_c3bf447e",
        "name": "Open",
        "type": "unknown",
        "mentions": [
          {
            "section": "sections/sec_5c55d4bc",
            "context": "ro(Liu et\u00a0al.,2025),Open-Reasoner-Zero-7B(OR"
          },
          {
            "section": "sections/sec_6ba6439f",
            "context": "ro(Liu et\u00a0al.,2025),Open-Reasoner-Zero-7B(OR"
          },
          {
            "section": "sections/sec_f6a941fe",
            "context": "ro(Liu et\u00a0al.,2025),Open-Reasoner-Zero-7B(OR"
          }
        ]
      },
      {
        "_key": "ent_fc64a2b6",
        "_id": "entities/ent_fc64a2b6",
        "name": "Reasoner",
        "type": "unknown",
        "mentions": [
          {
            "section": "sections/sec_5c55d4bc",
            "context": "ing inAbsolute Zero Reasoner-base-7BandAbsolute "
          },
          {
            "section": "sections/sec_6ba6439f",
            "context": "ing inAbsolute Zero Reasoner-base-7BandAbsolute "
          },
          {
            "section": "sections/sec_f6a941fe",
            "context": "u et\u00a0al.,2025),Open-Reasoner-Zero-7B(ORZ)(Hu et\u00a0"
          }
        ]
      },
      {
        "_key": "ent_fb22fe09",
        "_id": "entities/ent_fb22fe09",
        "name": "Qwen",
        "type": "unknown",
        "mentions": [
          {
            "section": "sections/sec_5c55d4bc",
            "context": " train AZR models onQwen2.5-7BandQwen2.5-7B-"
          },
          {
            "section": "sections/sec_6ba6439f",
            "context": " train AZR models onQwen2.5-7BandQwen2.5-7B-"
          },
          {
            "section": "sections/sec_f6a941fe",
            "context": "main results, we useQwen2.5-7Bas the base mo"
          }
        ]
      },
      {
        "_key": "ent_4c082ef7",
        "_id": "entities/ent_4c082ef7",
        "name": "Style Reasoners Trained",
        "type": "unknown",
        "mentions": [
          {
            "section": "sections/sec_5c55d4bc",
            "context": "8.045.029.537.3Zero-Style Reasoners Trained on Curated Coding D"
          },
          {
            "section": "sections/sec_5c55d4bc",
            "context": "8.045.029.537.3Zero-Style Reasoners Trained on Curated Coding D"
          },
          {
            "section": "sections/sec_56cabe86",
            "context": "8.045.029.537.3Zero-Style Reasoners Trained on Curated Coding D"
          },
          {
            "section": "sections/sec_56cabe86",
            "context": "8.045.029.537.3Zero-Style Reasoners Trained on Curated Coding D"
          }
        ]
      },
      {
        "_key": "ent_c283a720",
        "_id": "entities/ent_c283a720",
        "name": "Curated Coding",
        "type": "unknown",
        "mentions": [
          {
            "section": "sections/sec_5c55d4bc",
            "context": "easoners Trained on Curated Coding DataAceCoder-RM[84]"
          },
          {
            "section": "sections/sec_56cabe86",
            "context": "easoners Trained on Curated Coding DataAceCoder-RM[84]"
          }
        ]
      },
      {
        "_key": "ent_ab7a485e",
        "_id": "entities/ent_ab7a485e",
        "name": "Rule",
        "type": "unknown",
        "mentions": [
          {
            "section": "sections/sec_5c55d4bc",
            "context": "8.337.447.9AceCoder-Rule[84]Ins22k77.469.019"
          },
          {
            "section": "sections/sec_5c55d4bc",
            "context": "8.337.447.9AceCoder-Rule[84]Ins22k77.469.019"
          },
          {
            "section": "sections/sec_56cabe86",
            "context": "8.337.447.9AceCoder-Rule[84]Ins22k77.469.019"
          },
          {
            "section": "sections/sec_56cabe86",
            "context": "8.337.447.9AceCoder-Rule[84]Ins22k77.469.019"
          }
        ]
      },
      {
        "_key": "ent_ed09eab4",
        "_id": "entities/ent_ed09eab4",
        "name": "Curated Math",
        "type": "unknown",
        "mentions": [
          {
            "section": "sections/sec_5c55d4bc",
            "context": "easoners Trained on Curated Math DataPRIME-Zero[9]Co"
          },
          {
            "section": "sections/sec_56cabe86",
            "context": "easoners Trained on Curated Math DataPRIME-Zero[9]Co"
          }
        ]
      },
      {
        "_key": "ent_2d9a7bb6",
        "_id": "entities/ent_2d9a7bb6",
        "name": "Zero Training",
        "type": "unknown",
        "mentions": [
          {
            "section": "sections/sec_5c55d4bc",
            "context": "5.641.648.6Absolute Zero Training w/ No Curated Data "
          },
          {
            "section": "sections/sec_56cabe86",
            "context": "5.641.648.6Absolute Zero Training w/ No Curated Data "
          }
        ]
      },
      {
        "_key": "ent_a2a36d51",
        "_id": "entities/ent_a2a36d51",
        "name": "No Curated Data",
        "type": "unknown",
        "mentions": [
          {
            "section": "sections/sec_5c55d4bc",
            "context": "te Zero Training w/ No Curated Data (Ours)AZR (Ours)Bas"
          },
          {
            "section": "sections/sec_56cabe86",
            "context": "te Zero Training w/ No Curated Data (Ours)AZR (Ours)Bas"
          }
        ]
      },
      {
        "_key": "ent_b7b4497a",
        "_id": "entities/ent_b7b4497a",
        "name": "Ours",
        "type": "unknown",
        "mentions": [
          {
            "section": "sections/sec_5c55d4bc",
            "context": "w/ No Curated Data (Ours)AZR (Ours)Base071.3"
          },
          {
            "section": "sections/sec_5c55d4bc",
            "context": "w/ No Curated Data (Ours)AZR (Ours)Base071.3"
          },
          {
            "section": "sections/sec_5c55d4bc",
            "context": "w/ No Curated Data (Ours)AZR (Ours)Base071.3"
          },
          {
            "section": "sections/sec_5c55d4bc",
            "context": "w/ No Curated Data (Ours)AZR (Ours)Base071.3"
          },
          {
            "section": "sections/sec_5c55d4bc",
            "context": "w/ No Curated Data (Ours)AZR (Ours)Base071.3"
          },
          {
            "section": "sections/sec_5c55d4bc",
            "context": "w/ No Curated Data (Ours)AZR (Ours)Base071.3"
          },
          {
            "section": "sections/sec_5c55d4bc",
            "context": "w/ No Curated Data (Ours)AZR (Ours)Base071.3"
          },
          {
            "section": "sections/sec_56cabe86",
            "context": "w/ No Curated Data (Ours)AZR (Ours)Base071.3"
          },
          {
            "section": "sections/sec_56cabe86",
            "context": "w/ No Curated Data (Ours)AZR (Ours)Base071.3"
          },
          {
            "section": "sections/sec_56cabe86",
            "context": "w/ No Curated Data (Ours)AZR (Ours)Base071.3"
          },
          {
            "section": "sections/sec_56cabe86",
            "context": "w/ No Curated Data (Ours)AZR (Ours)Base071.3"
          },
          {
            "section": "sections/sec_56cabe86",
            "context": "w/ No Curated Data (Ours)AZR (Ours)Base071.3"
          },
          {
            "section": "sections/sec_56cabe86",
            "context": "w/ No Curated Data (Ours)AZR (Ours)Base071.3"
          },
          {
            "section": "sections/sec_56cabe86",
            "context": "w/ No Curated Data (Ours)AZR (Ours)Base071.3"
          },
          {
            "section": "sections/sec_9cc89151",
            "context": "RGLlama3.1-8b+ AZR (Ours)31.6+3.131.6\\mathrl"
          },
          {
            "section": "sections/sec_9cc89151",
            "context": "RGLlama3.1-8b+ AZR (Ours)31.6+3.131.6\\mathrl"
          },
          {
            "section": "sections/sec_9cc89151",
            "context": "RGLlama3.1-8b+ AZR (Ours)31.6+3.131.6\\mathrl"
          },
          {
            "section": "sections/sec_9cc89151",
            "context": "RGLlama3.1-8b+ AZR (Ours)31.6+3.131.6\\mathrl"
          }
        ]
      },
      {
        "_key": "ent_b2b928f0",
        "_id": "entities/ent_b2b928f0",
        "name": "Trained Reasoner",
        "type": "unknown",
        "mentions": [
          {
            "section": "sections/sec_5c55d4bc",
            "context": "1:Performance of RL-Trained Reasoner on Reasoning Benchm"
          },
          {
            "section": "sections/sec_56cabe86",
            "context": "1:Performance of RL-Trained Reasoner on Reasoning Benchm"
          }
        ]
      },
      {
        "_key": "ent_49291bd3",
        "_id": "entities/ent_49291bd3",
        "name": "Reasoning Benchmarks Based",
        "type": "unknown",
        "mentions": [
          {
            "section": "sections/sec_5c55d4bc",
            "context": "Trained Reasoner on Reasoning Benchmarks Based on Qwen2.5-7B Model"
          },
          {
            "section": "sections/sec_56cabe86",
            "context": "Trained Reasoner on Reasoning Benchmarks Based on Qwen2.5-7B Model"
          }
        ]
      },
      {
        "_key": "ent_25ac429f",
        "_id": "entities/ent_25ac429f",
        "name": "Models",
        "type": "unknown",
        "mentions": [
          {
            "section": "sections/sec_5c55d4bc",
            "context": "piadCAvgMAvgAVGBase ModelsQwen2.5-7B[73]--73.2"
          },
          {
            "section": "sections/sec_56cabe86",
            "context": "piadCAvgMAvgAVGBase ModelsQwen2.5-7B[73]--73.2"
          }
        ]
      },
      {
        "_key": "ent_b1897515",
        "_id": "entities/ent_b1897515",
        "name": "Average",
        "type": "unknown",
        "mentions": [
          {
            "section": "sections/sec_5c55d4bc",
            "context": "va, OlympiadBench). Average performance across "
          },
          {
            "section": "sections/sec_56cabe86",
            "context": "va, OlympiadBench). Average performance across "
          }
        ]
      },
      {
        "_key": "ent_a97ea56b",
        "_id": "entities/ent_a97ea56b",
        "name": "Question",
        "type": "unknown",
        "mentions": [
          {
            "section": "sections/sec_5c55d4bc",
            "context": "ed inTable4Research Question 1: How does AZR com"
          }
        ]
      },
      {
        "_key": "ent_31ad45a6",
        "_id": "entities/ent_31ad45a6",
        "name": "Notably",
        "type": "unknown",
        "mentions": [
          {
            "section": "sections/sec_5c55d4bc",
            "context": " settings inTable1. Notably,Absolute Zero Reaso"
          },
          {
            "section": "sections/sec_56cabe86",
            "context": " settings inTable1. Notably,Absolute Zero Reaso"
          },
          {
            "section": "sections/sec_773a923f",
            "context": " settings inTable1. Notably,Absolute Zero Reaso"
          }
        ]
      },
      {
        "_key": "ent_35537fbc",
        "_id": "entities/ent_35537fbc",
        "name": "Even",
        "type": "unknown",
        "mentions": [
          {
            "section": "sections/sec_5c55d4bc",
            "context": "solute percentages. Even more strikingly, it"
          },
          {
            "section": "sections/sec_56cabe86",
            "context": "solute percentages. Even more strikingly, it"
          },
          {
            "section": "sections/sec_773a923f",
            "context": "solute percentages. Even more strikingly, it"
          }
        ]
      },
      {
        "_key": "ent_9c0502f5",
        "_id": "entities/ent_9c0502f5",
        "name": "Strong Cross",
        "type": "unknown",
        "mentions": [
          {
            "section": "sections/sec_5c55d4bc",
            "context": "to such data itself.Strong Cross-domain Generalizati"
          },
          {
            "section": "sections/sec_56cabe86",
            "context": "to such data itself.Strong Cross-domain Generalizati"
          },
          {
            "section": "sections/sec_773a923f",
            "context": "o such data itself. Strong Cross-domain Generalizati"
          }
        ]
      },
      {
        "_key": "ent_e60de48d",
        "_id": "entities/ent_e60de48d",
        "name": "Generalization",
        "type": "unknown",
        "mentions": [
          {
            "section": "sections/sec_5c55d4bc",
            "context": "Strong Cross-domain Generalization.To assess cross-dom"
          },
          {
            "section": "sections/sec_56cabe86",
            "context": "Strong Cross-domain Generalization.To assess cross-dom"
          },
          {
            "section": "sections/sec_773a923f",
            "context": "Strong Cross-domain Generalization.To assess cross-dom"
          }
        ]
      },
      {
        "_key": "ent_9c831ae0",
        "_id": "entities/ent_9c831ae0",
        "name": "Overall",
        "type": "unknown",
        "mentions": [
          {
            "section": "sections/sec_5c55d4bc",
            "context": "g (+2.0 on average).Overall, these results high"
          },
          {
            "section": "sections/sec_5c55d4bc",
            "context": "g (+2.0 on average).Overall, these results high"
          },
          {
            "section": "sections/sec_5c55d4bc",
            "context": "g (+2.0 on average).Overall, these results high"
          },
          {
            "section": "sections/sec_56cabe86",
            "context": "g (+2.0 on average).Overall, these results high"
          },
          {
            "section": "sections/sec_56cabe86",
            "context": "g (+2.0 on average).Overall, these results high"
          },
          {
            "section": "sections/sec_56cabe86",
            "context": "g (+2.0 on average).Overall, these results high"
          },
          {
            "section": "sections/sec_773a923f",
            "context": " (+2.0 on average). Overall, these results high"
          },
          {
            "section": "sections/sec_72c37985",
            "context": "gh trial-and-error. Overall, the models trained"
          },
          {
            "section": "sections/sec_94b98c7f",
            "context": "esCode Avg.Math Avg.Overall Avg.Deduction onlyD"
          }
        ]
      },
      {
        "_key": "ent_01456a90",
        "_id": "entities/ent_01456a90",
        "name": "Research Question",
        "type": "unknown",
        "mentions": [
          {
            "section": "sections/sec_5c55d4bc",
            "context": "ails listed inTable4Research Question 1: How does AZR com"
          },
          {
            "section": "sections/sec_5c55d4bc",
            "context": "ails listed inTable4Research Question 1: How does AZR com"
          },
          {
            "section": "sections/sec_5c55d4bc",
            "context": "ails listed inTable4Research Question 1: How does AZR com"
          },
          {
            "section": "sections/sec_5c55d4bc",
            "context": "ails listed inTable4Research Question 1: How does AZR com"
          },
          {
            "section": "sections/sec_5c55d4bc",
            "context": "ails listed inTable4Research Question 1: How does AZR com"
          },
          {
            "section": "sections/sec_5c55d4bc",
            "context": "ails listed inTable4Research Question 1: How does AZR com"
          },
          {
            "section": "sections/sec_56cabe86",
            "context": "ils listed inTable4 Research Question 1: How does AZR com"
          },
          {
            "section": "sections/sec_56cabe86",
            "context": "ils listed inTable4 Research Question 1: How does AZR com"
          },
          {
            "section": "sections/sec_56cabe86",
            "context": "ils listed inTable4 Research Question 1: How does AZR com"
          },
          {
            "section": "sections/sec_56cabe86",
            "context": "ils listed inTable4 Research Question 1: How does AZR com"
          },
          {
            "section": "sections/sec_56cabe86",
            "context": "ils listed inTable4 Research Question 1: How does AZR com"
          },
          {
            "section": "sections/sec_56cabe86",
            "context": "ils listed inTable4 Research Question 1: How does AZR com"
          },
          {
            "section": "sections/sec_56cabe86",
            "context": "ils listed inTable4 Research Question 1: How does AZR com"
          }
        ]
      },
      {
        "_key": "ent_0762465d",
        "_id": "entities/ent_0762465d",
        "name": "Strikingly",
        "type": "unknown",
        "mentions": [
          {
            "section": "sections/sec_5c55d4bc",
            "context": " self-play process. Strikingly, although the coder"
          },
          {
            "section": "sections/sec_56cabe86",
            "context": " self-play process. Strikingly, although the coder"
          },
          {
            "section": "sections/sec_b69f3870",
            "context": " self-play process. Strikingly, although the coder"
          }
        ]
      },
      {
        "_key": "ent_0dfcf23e",
        "_id": "entities/ent_0dfcf23e",
        "name": "Given",
        "type": "unknown",
        "mentions": [
          {
            "section": "sections/sec_5c55d4bc",
            "context": " (b), respectively. Given the strong performa"
          },
          {
            "section": "sections/sec_56cabe86",
            "context": " (b), respectively. Given the strong performa"
          },
          {
            "section": "sections/sec_9cc89151",
            "context": " (b), respectively. Given the strong performa"
          }
        ]
      },
      {
        "_key": "ent_a559b870",
        "_id": "entities/ent_a559b870",
        "name": "Model",
        "type": "unknown",
        "mentions": [
          {
            "section": "sections/sec_5c55d4bc",
            "context": "se model. 4.2ResultsModelBase#dataHEval+MBPP+"
          },
          {
            "section": "sections/sec_5c55d4bc",
            "context": "se model. 4.2ResultsModelBase#dataHEval+MBPP+"
          },
          {
            "section": "sections/sec_56cabe86",
            "context": "ModelBase#dataHEval+MBPP+"
          },
          {
            "section": "sections/sec_56cabe86",
            "context": "ModelBase#dataHEval+MBPP+"
          },
          {
            "section": "sections/sec_9cc89151",
            "context": "e Zero paradigm. (a)Model FamilyVariantCode A"
          },
          {
            "section": "sections/sec_04cca2bb",
            "context": "gure 7:Example of a Model-Proposed Task and I"
          }
        ]
      },
      {
        "_key": "ent_f0bac093",
        "_id": "entities/ent_f0bac093",
        "name": "Distribution",
        "type": "unknown",
        "mentions": [
          {
            "section": "sections/sec_5c55d4bc",
            "context": "G(b)Figure 6:(a) In-Distribution & (b) Out-of-Distri"
          },
          {
            "section": "sections/sec_56cabe86",
            "context": "G(b)Figure 6:(a) In-Distribution & (b) Out-of-Distri"
          },
          {
            "section": "sections/sec_9cc89151",
            "context": "G(b)Figure 6:(a) In-Distribution & (b) Out-of-Distri"
          }
        ]
      },
      {
        "_key": "ent_92453493",
        "_id": "entities/ent_92453493",
        "name": "Distribution Reasoning Task Performances",
        "type": "unknown",
        "mentions": [
          {
            "section": "sections/sec_5c55d4bc",
            "context": "bution & (b) Out-of-Distribution Reasoning Task Performances.(a)Scores on CruxEv"
          },
          {
            "section": "sections/sec_56cabe86",
            "context": "bution & (b) Out-of-Distribution Reasoning Task Performances.(a)Scores on CruxEv"
          },
          {
            "section": "sections/sec_9cc89151",
            "context": "bution & (b) Out-of-Distribution Reasoning Task Performances.(a)Scores on CruxEv"
          }
        ]
      },
      {
        "_key": "ent_6660e1da",
        "_id": "entities/ent_6660e1da",
        "name": "Scores",
        "type": "unknown",
        "mentions": [
          {
            "section": "sections/sec_5c55d4bc",
            "context": "ask Performances.(a)Scores on CruxEval-I, Crux"
          },
          {
            "section": "sections/sec_56cabe86",
            "context": "ask Performances.(a)Scores on CruxEval-I, Crux"
          },
          {
            "section": "sections/sec_9cc89151",
            "context": "ask Performances.(a)Scores on CruxEval-I, Crux"
          }
        ]
      },
      {
        "_key": "ent_0a527305",
        "_id": "entities/ent_0a527305",
        "name": "Example",
        "type": "unknown",
        "mentions": [
          {
            "section": "sections/sec_5c55d4bc",
            "context": "el potency.Figure 7:Example of a Model-Proposed"
          },
          {
            "section": "sections/sec_56cabe86",
            "context": "el potency.Figure 7:Example of a Model-Proposed"
          },
          {
            "section": "sections/sec_04cca2bb",
            "context": "l potency. Figure 7:Example of a Model-Proposed"
          }
        ]
      },
      {
        "_key": "ent_1ed77a55",
        "_id": "entities/ent_1ed77a55",
        "name": "Proposed Task",
        "type": "unknown",
        "mentions": [
          {
            "section": "sections/sec_5c55d4bc",
            "context": ":Example of a Model-Proposed Task and Its Response fo"
          },
          {
            "section": "sections/sec_56cabe86",
            "context": ":Example of a Model-Proposed Task and Its Response fo"
          },
          {
            "section": "sections/sec_04cca2bb",
            "context": ":Example of a Model-Proposed Task and Its Response fo"
          }
        ]
      },
      {
        "_key": "ent_44afea25",
        "_id": "entities/ent_44afea25",
        "name": "Its Response",
        "type": "unknown",
        "mentions": [
          {
            "section": "sections/sec_5c55d4bc",
            "context": "l-Proposed Task and Its Response for Solving an Abdu"
          },
          {
            "section": "sections/sec_56cabe86",
            "context": "l-Proposed Task and Its Response for Solving an Abdu"
          },
          {
            "section": "sections/sec_04cca2bb",
            "context": "l-Proposed Task and Its Response for Solving an Abdu"
          }
        ]
      },
      {
        "_key": "ent_3b6e51cc",
        "_id": "entities/ent_3b6e51cc",
        "name": "Solving",
        "type": "unknown",
        "mentions": [
          {
            "section": "sections/sec_5c55d4bc",
            "context": "nd Its Response for Solving an Abduction Task.("
          },
          {
            "section": "sections/sec_56cabe86",
            "context": "nd Its Response for Solving an Abduction Task.("
          },
          {
            "section": "sections/sec_04cca2bb",
            "context": "nd Its Response for Solving an Abduction Task.("
          }
        ]
      },
      {
        "_key": "ent_99616d94",
        "_id": "entities/ent_99616d94",
        "name": "Abduction Task",
        "type": "unknown",
        "mentions": [
          {
            "section": "sections/sec_5c55d4bc",
            "context": "onse for Solving an Abduction Task.(Left) The model au"
          },
          {
            "section": "sections/sec_56cabe86",
            "context": "onse for Solving an Abduction Task.(Left) The model au"
          },
          {
            "section": "sections/sec_04cca2bb",
            "context": "onse for Solving an Abduction Task.(Left) The model au"
          }
        ]
      },
      {
        "_key": "ent_945d5e23",
        "_id": "entities/ent_945d5e23",
        "name": "Left",
        "type": "unknown",
        "mentions": [
          {
            "section": "sections/sec_5c55d4bc",
            "context": " an Abduction Task.(Left) The model autonomo"
          },
          {
            "section": "sections/sec_56cabe86",
            "context": " an Abduction Task.(Left) The model autonomo"
          },
          {
            "section": "sections/sec_04cca2bb",
            "context": " an Abduction Task.(Left) The model autonomo"
          }
        ]
      },
      {
        "_key": "ent_92b09c7c",
        "_id": "entities/ent_92b09c7c",
        "name": "Right",
        "type": "unknown",
        "mentions": [
          {
            "section": "sections/sec_5c55d4bc",
            "context": "responding output. (Right) The model\u2019s reason"
          },
          {
            "section": "sections/sec_56cabe86",
            "context": "responding output. (Right) The model\u2019s reason"
          },
          {
            "section": "sections/sec_04cca2bb",
            "context": "responding output. (Right) The model\u2019s reason"
          }
        ]
      },
      {
        "_key": "ent_64cb339c",
        "_id": "entities/ent_64cb339c",
        "name": "Interestingly",
        "type": "unknown",
        "mentions": [
          {
            "section": "sections/sec_5c55d4bc",
            "context": "matches the target. Interestingly, the agent arrives "
          },
          {
            "section": "sections/sec_5c55d4bc",
            "context": "matches the target. Interestingly, the agent arrives "
          },
          {
            "section": "sections/sec_5c55d4bc",
            "context": "matches the target. Interestingly, the agent arrives "
          },
          {
            "section": "sections/sec_56cabe86",
            "context": "matches the target. Interestingly, the agent arrives "
          },
          {
            "section": "sections/sec_56cabe86",
            "context": "matches the target. Interestingly, the agent arrives "
          },
          {
            "section": "sections/sec_56cabe86",
            "context": "matches the target. Interestingly, the agent arrives "
          },
          {
            "section": "sections/sec_04cca2bb",
            "context": "matches the target. Interestingly, the agent arrives "
          },
          {
            "section": "sections/sec_72c37985",
            "context": "e Behavior in Llama.Interestingly, we also observed s"
          },
          {
            "section": "sections/sec_72c37985",
            "context": "e Behavior in Llama.Interestingly, we also observed s"
          }
        ]
      },
      {
        "_key": "ent_2dde8f4a",
        "_id": "entities/ent_2dde8f4a",
        "name": "Heron",
        "type": "unknown",
        "mentions": [
          {
            "section": "sections/sec_5c55d4bc",
            "context": "iangle\u2019s area using Heron\u2019s formula). We show"
          },
          {
            "section": "sections/sec_56cabe86",
            "context": "iangle\u2019s area using Heron\u2019s formula). We show"
          },
          {
            "section": "sections/sec_72c37985",
            "context": "iangle\u2019s area using Heron\u2019s formula). We show"
          }
        ]
      },
      {
        "_key": "ent_5dc13067",
        "_id": "entities/ent_5dc13067",
        "name": "Sudoku",
        "type": "unknown",
        "mentions": [
          {
            "section": "sections/sec_5c55d4bc",
            "context": "ks\u201d such as solving Sudoku and solving thesum-"
          },
          {
            "section": "sections/sec_56cabe86",
            "context": "ks\u201d such as solving Sudoku and solving thesum-"
          },
          {
            "section": "sections/sec_72c37985",
            "context": "ks\u201d such as solving Sudoku and solving thesum-"
          }
        ]
      },
      {
        "_key": "ent_c62cf525",
        "_id": "entities/ent_c62cf525",
        "name": "Intermediate Planning During Code Response",
        "type": "unknown",
        "mentions": [
          {
            "section": "sections/sec_5c55d4bc",
            "context": "ameinFigures40and41.Intermediate Planning During Code Response.Another interesting"
          },
          {
            "section": "sections/sec_56cabe86",
            "context": "ameinFigures40and41.Intermediate Planning During Code Response.Another interesting"
          },
          {
            "section": "sections/sec_72c37985",
            "context": "meinFigures40and41. Intermediate Planning During Code Response.Another interesting"
          }
        ]
      },
      {
        "_key": "ent_442c0184",
        "_id": "entities/ent_442c0184",
        "name": "Another",
        "type": "unknown",
        "mentions": [
          {
            "section": "sections/sec_5c55d4bc",
            "context": "uring Code Response.Another interesting pattern"
          },
          {
            "section": "sections/sec_56cabe86",
            "context": "uring Code Response.Another interesting pattern"
          },
          {
            "section": "sections/sec_72c37985",
            "context": "uring Code Response.Another interesting pattern"
          }
        ]
      },
      {
        "_key": "ent_c1eef20b",
        "_id": "entities/ent_c1eef20b",
        "name": "Cognitive Behavior",
        "type": "unknown",
        "mentions": [
          {
            "section": "sections/sec_5c55d4bc",
            "context": "cross other domains.Cognitive Behavior in Llama.Interestin"
          },
          {
            "section": "sections/sec_56cabe86",
            "context": "cross other domains.Cognitive Behavior in Llama.Interestin"
          },
          {
            "section": "sections/sec_72c37985",
            "context": "ross other domains. Cognitive Behavior in Llama.Interestin"
          }
        ]
      },
      {
        "_key": "ent_d7379224",
        "_id": "entities/ent_d7379224",
        "name": "Token Length Increase Depends",
        "type": "unknown",
        "mentions": [
          {
            "section": "sections/sec_5c55d4bc",
            "context": "ential implications.Token Length Increase Depends on Task Type.Finall"
          },
          {
            "section": "sections/sec_56cabe86",
            "context": "ential implications.Token Length Increase Depends on Task Type.Finall"
          },
          {
            "section": "sections/sec_72c37985",
            "context": "ntial implications. Token Length Increase Depends on Task Type.Finall"
          }
        ]
      },
      {
        "_key": "ent_9dd5fda3",
        "_id": "entities/ent_9dd5fda3",
        "name": "Task Type",
        "type": "unknown",
        "mentions": [
          {
            "section": "sections/sec_5c55d4bc",
            "context": "Increase Depends on Task Type.Finally, we observe"
          },
          {
            "section": "sections/sec_56cabe86",
            "context": "Increase Depends on Task Type.Finally, we observe"
          },
          {
            "section": "sections/sec_72c37985",
            "context": "Increase Depends on Task Type.Finally, we observe"
          }
        ]
      },
      {
        "_key": "ent_9002eb99",
        "_id": "entities/ent_9002eb99",
        "name": "Ablation",
        "type": "unknown",
        "mentions": [
          {
            "section": "sections/sec_5c55d4bc",
            "context": "r good performance (Ablation)?Due to resource co"
          },
          {
            "section": "sections/sec_5c55d4bc",
            "context": "r good performance (Ablation)?Due to resource co"
          },
          {
            "section": "sections/sec_56cabe86",
            "context": "r good performance (Ablation)?Due to resource co"
          },
          {
            "section": "sections/sec_56cabe86",
            "context": "r good performance (Ablation)?Due to resource co"
          }
        ]
      },
      {
        "_key": "ent_74369c56",
        "_id": "entities/ent_74369c56",
        "name": "Math Avg",
        "type": "unknown",
        "mentions": [
          {
            "section": "sections/sec_5c55d4bc",
            "context": "amilyVariantCode AvgMath AvgTotal AvgLlama3.1-8b"
          },
          {
            "section": "sections/sec_56cabe86",
            "context": "amilyVariantCode AvgMath AvgTotal AvgLlama3.1-8b"
          },
          {
            "section": "sections/sec_94b98c7f",
            "context": "ained RolesCode Avg.Math Avg.Overall Avg.Deducti"
          }
        ]
      },
      {
        "_key": "ent_e39c8281",
        "_id": "entities/ent_e39c8281",
        "name": "Overall Avg",
        "type": "unknown",
        "mentions": [
          {
            "section": "sections/sec_5c55d4bc",
            "context": "esCode Avg.Math Avg.Overall Avg.Deduction onlyDed//"
          },
          {
            "section": "sections/sec_56cabe86",
            "context": "esCode Avg.Math Avg.Overall Avg.Deduction onlyDed//"
          },
          {
            "section": "sections/sec_94b98c7f",
            "context": "esCode Avg.Math Avg.Overall Avg.Deduction onlyDed//"
          }
        ]
      },
      {
        "_key": "ent_72839bf5",
        "_id": "entities/ent_72839bf5",
        "name": "Gen Reference",
        "type": "unknown",
        "mentions": [
          {
            "section": "sections/sec_5c55d4bc",
            "context": ".ExperimentTask TypeGen ReferenceTrained RolesCode Av"
          },
          {
            "section": "sections/sec_56cabe86",
            "context": ".ExperimentTask TypeGen ReferenceTrained RolesCode Av"
          },
          {
            "section": "sections/sec_94b98c7f",
            "context": " ExperimentTask TypeGen ReferenceTrained RolesCode Av"
          }
        ]
      },
      {
        "_key": "ent_f6030637",
        "_id": "entities/ent_f6030637",
        "name": "Solver Only",
        "type": "unknown",
        "mentions": [
          {
            "section": "sections/sec_5c55d4bc",
            "context": "0/54.433.143.8Train Solver Only//Solve Only54.836.0"
          },
          {
            "section": "sections/sec_56cabe86",
            "context": "0/54.433.143.8Train Solver Only//Solve Only54.836.0"
          },
          {
            "section": "sections/sec_94b98c7f",
            "context": "0/54.433.143.8Train Solver Only//Solve Only54.836.0"
          }
        ]
      },
      {
        "_key": "ent_97817e09",
        "_id": "entities/ent_97817e09",
        "name": "Solve",
        "type": "unknown",
        "mentions": [
          {
            "section": "sections/sec_5c55d4bc",
            "context": "0/54.433.143.8Train Solver Only//Solve Only54"
          },
          {
            "section": "sections/sec_56cabe86",
            "context": "0/54.433.143.8Train Solver Only//Solve Only54"
          },
          {
            "section": "sections/sec_94b98c7f",
            "context": "0/54.433.143.8Train Solver Only//Solve Only54"
          }
        ]
      },
      {
        "_key": "ent_2ccaf84f",
        "_id": "entities/ent_2ccaf84f",
        "name": "Ablation Results",
        "type": "unknown",
        "mentions": [
          {
            "section": "sections/sec_5c55d4bc",
            "context": "55.238.446.8Table 2:Ablation Results.We ablate task type"
          },
          {
            "section": "sections/sec_56cabe86",
            "context": "55.238.446.8Table 2:Ablation Results.We ablate task type"
          },
          {
            "section": "sections/sec_94b98c7f",
            "context": "55.238.446.8Table 2:Ablation Results.We ablate task type"
          }
        ]
      },
      {
        "_key": "ent_e44b66d2",
        "_id": "entities/ent_e44b66d2",
        "name": "Removing",
        "type": "unknown",
        "mentions": [
          {
            "section": "sections/sec_5c55d4bc",
            "context": "standard AZR setup. Removing induction or using "
          },
          {
            "section": "sections/sec_56cabe86",
            "context": "standard AZR setup. Removing induction or using "
          },
          {
            "section": "sections/sec_94b98c7f",
            "context": "standard AZR setup. Removing induction or using "
          }
        ]
      },
      {
        "_key": "ent_115edd9d",
        "_id": "entities/ent_115edd9d",
        "name": "Suteu",
        "type": "unknown",
        "mentions": [
          {
            "section": "sections/sec_5c55d4bc",
            "context": "learning literature(Suteu & Guo,2019). Thus, "
          },
          {
            "section": "sections/sec_56cabe86",
            "context": "learning literature(Suteu & Guo,2019). Thus, "
          },
          {
            "section": "sections/sec_bb5ac41e",
            "context": "learning literature(Suteu & Guo,2019). Thus, "
          }
        ]
      },
      {
        "_key": "ent_fb55ffe3",
        "_id": "entities/ent_fb55ffe3",
        "name": "Thus",
        "type": "unknown",
        "mentions": [
          {
            "section": "sections/sec_5c55d4bc",
            "context": "(Suteu & Guo,2019). Thus, we believe that fu"
          },
          {
            "section": "sections/sec_56cabe86",
            "context": "(Suteu & Guo,2019). Thus, we believe that fu"
          },
          {
            "section": "sections/sec_bb5ac41e",
            "context": "(Suteu & Guo,2019). Thus, we believe that fu"
          }
        ]
      },
      {
        "_key": "ent_a5a514e8",
        "_id": "entities/ent_a5a514e8",
        "name": "Additional Results",
        "type": "unknown",
        "mentions": [
          {
            "section": "sections/sec_5c55d4bc",
            "context": "promising direction.Additional Results.Beyond the core res"
          },
          {
            "section": "sections/sec_56cabe86",
            "context": "romising direction. Additional Results.Beyond the core res"
          }
        ]
      },
      {
        "_key": "ent_4f991fd3",
        "_id": "entities/ent_4f991fd3",
        "name": "Beyond",
        "type": "unknown",
        "mentions": [
          {
            "section": "sections/sec_5c55d4bc",
            "context": ".Additional Results.Beyond the core research q"
          },
          {
            "section": "sections/sec_56cabe86",
            "context": " Additional Results.Beyond the core research q"
          },
          {
            "section": "sections/sec_985245d2",
            "context": "Beyond the core research q"
          }
        ]
      },
      {
        "_key": "ent_37391eed",
        "_id": "entities/ent_37391eed",
        "name": "Training Details",
        "type": "unknown",
        "mentions": [
          {
            "section": "sections/sec_6ba6439f",
            "context": "Training Details.For all experiments"
          }
        ]
      },
      {
        "_key": "ent_d3da97e2",
        "_id": "entities/ent_d3da97e2",
        "name": "More",
        "type": "unknown",
        "mentions": [
          {
            "section": "sections/sec_95e6043e",
            "context": "he time of release. More recently, the R1 mo"
          },
          {
            "section": "sections/sec_485ba230",
            "context": "he time of release. More recently, the R1 mo"
          }
        ]
      },
      {
        "_key": "ent_08781b29",
        "_id": "entities/ent_08781b29",
        "name": "Most",
        "type": "unknown",
        "mentions": [
          {
            "section": "sections/sec_95e6043e",
            "context": " performance of o1. Most notably, the zero s"
          },
          {
            "section": "sections/sec_95e6043e",
            "context": " performance of o1. Most notably, the zero s"
          },
          {
            "section": "sections/sec_485ba230",
            "context": " performance of o1. Most notably, the zero s"
          },
          {
            "section": "sections/sec_247e121e",
            "context": " the discriminator. Most recently, SPIN and "
          }
        ]
      },
      {
        "_key": "ent_3d088ce7",
        "_id": "entities/ent_3d088ce7",
        "name": "Yuan",
        "type": "unknown",
        "mentions": [
          {
            "section": "sections/sec_95e6043e",
            "context": "2025;Yu et\u00a0al.,2025;Yuan et\u00a0al.,2025). Recen"
          },
          {
            "section": "sections/sec_95e6043e",
            "context": "2025;Yu et\u00a0al.,2025;Yuan et\u00a0al.,2025). Recen"
          },
          {
            "section": "sections/sec_485ba230",
            "context": "2025;Yu et\u00a0al.,2025;Yuan et\u00a0al.,2025). Recen"
          },
          {
            "section": "sections/sec_247e121e",
            "context": "ls(Chen et\u00a0al.,2024;Yuan et\u00a0al.,2024)use the"
          }
        ]
      },
      {
        "_key": "ent_dae52b80",
        "_id": "entities/ent_dae52b80",
        "name": "Recent",
        "type": "unknown",
        "mentions": [
          {
            "section": "sections/sec_95e6043e",
            "context": ";Yuan et\u00a0al.,2025). Recent work explored RL on"
          },
          {
            "section": "sections/sec_485ba230",
            "context": ";Yuan et\u00a0al.,2025). Recent work explored RL on"
          }
        ]
      },
      {
        "_key": "ent_ad6e7652",
        "_id": "entities/ent_ad6e7652",
        "name": "Self",
        "type": "unknown",
        "mentions": [
          {
            "section": "sections/sec_95e6043e",
            "context": "em in the long run. Self-play.The self-play "
          },
          {
            "section": "sections/sec_95e6043e",
            "context": "em in the long run. Self-play.The self-play "
          },
          {
            "section": "sections/sec_247e121e",
            "context": " recently, SPIN and Self-Rewarding Language "
          }
        ]
      },
      {
        "_key": "ent_3f8bcd1d",
        "_id": "entities/ent_3f8bcd1d",
        "name": "Schaul",
        "type": "unknown",
        "mentions": [
          {
            "section": "sections/sec_95e6043e",
            "context": "ver-ending progress(Schaul,2024). AlphaGo and "
          },
          {
            "section": "sections/sec_247e121e",
            "context": "ver-ending progress(Schaul,2024). AlphaGo and "
          }
        ]
      },
      {
        "_key": "ent_d0f7423e",
        "_id": "entities/ent_d0f7423e",
        "name": "Dennis",
        "type": "unknown",
        "mentions": [
          {
            "section": "sections/sec_95e6043e",
            "context": "gn(Wang et\u00a0al.,2019;Dennis et\u00a0al.,2020), unsup"
          },
          {
            "section": "sections/sec_247e121e",
            "context": "gn(Wang et\u00a0al.,2019;Dennis et\u00a0al.,2020), unsup"
          }
        ]
      },
      {
        "_key": "ent_39c0691f",
        "_id": "entities/ent_39c0691f",
        "name": "Laskin",
        "type": "unknown",
        "mentions": [
          {
            "section": "sections/sec_95e6043e",
            "context": "nforcement learning(Laskin et\u00a0al.,2021;Zhao et"
          },
          {
            "section": "sections/sec_247e121e",
            "context": "nforcement learning(Laskin et\u00a0al.,2021;Zhao et"
          }
        ]
      },
      {
        "_key": "ent_1098c710",
        "_id": "entities/ent_1098c710",
        "name": "Florensa",
        "type": "unknown",
        "mentions": [
          {
            "section": "sections/sec_95e6043e",
            "context": "tic goal generation(Florensa et\u00a0al.,2018)all cen"
          },
          {
            "section": "sections/sec_247e121e",
            "context": "tic goal generation(Florensa et\u00a0al.,2018)all cen"
          }
        ]
      },
      {
        "_key": "ent_da6b6361",
        "_id": "entities/ent_da6b6361",
        "name": "Generative",
        "type": "unknown",
        "mentions": [
          {
            "section": "sections/sec_95e6043e",
            "context": "tinuously evolving. Generative adversarial network"
          },
          {
            "section": "sections/sec_247e121e",
            "context": "tinuously evolving. Generative adversarial network"
          }
        ]
      },
      {
        "_key": "ent_9065df87",
        "_id": "entities/ent_9065df87",
        "name": "Goodfellow",
        "type": "unknown",
        "mentions": [
          {
            "section": "sections/sec_95e6043e",
            "context": "dversarial networks(Goodfellow et\u00a0al.,2020), also "
          },
          {
            "section": "sections/sec_247e121e",
            "context": "dversarial networks(Goodfellow et\u00a0al.,2020), also "
          }
        ]
      },
      {
        "_key": "ent_90b74dd3",
        "_id": "entities/ent_90b74dd3",
        "name": "Rewarding Language Models",
        "type": "unknown",
        "mentions": [
          {
            "section": "sections/sec_95e6043e",
            "context": "ntly, SPIN and Self-Rewarding Language Models(Chen et\u00a0al.,2024;Yu"
          },
          {
            "section": "sections/sec_247e121e",
            "context": "ntly, SPIN and Self-Rewarding Language Models(Chen et\u00a0al.,2024;Yu"
          }
        ]
      },
      {
        "_key": "ent_428648f9",
        "_id": "entities/ent_428648f9",
        "name": "Kirchner",
        "type": "unknown",
        "mentions": [
          {
            "section": "sections/sec_95e6043e",
            "context": "e LLM for alignment.Kirchner et\u00a0al.(2024)uses Pr"
          },
          {
            "section": "sections/sec_247e121e",
            "context": "e LLM for alignment.Kirchner et\u00a0al.(2024)uses Pr"
          }
        ]
      },
      {
        "_key": "ent_8beb8be3",
        "_id": "entities/ent_8beb8be3",
        "name": "Verifier Game",
        "type": "unknown",
        "mentions": [
          {
            "section": "sections/sec_95e6043e",
            "context": "l.(2024)uses Prover-Verifier Game for increasing legi"
          },
          {
            "section": "sections/sec_247e121e",
            "context": "l.(2024)uses Prover-Verifier Game for increasing legi"
          }
        ]
      },
      {
        "_key": "ent_1e693308",
        "_id": "entities/ent_1e693308",
        "name": "Adversarial Taboo",
        "type": "unknown",
        "mentions": [
          {
            "section": "sections/sec_95e6043e",
            "context": "in specific game of Adversarial Taboo. Concurrent works\u2014G"
          },
          {
            "section": "sections/sec_247e121e",
            "context": "in specific game of Adversarial Taboo. Concurrent works\u2014G"
          }
        ]
      },
      {
        "_key": "ent_3aee7460",
        "_id": "entities/ent_3aee7460",
        "name": "Concurrent",
        "type": "unknown",
        "mentions": [
          {
            "section": "sections/sec_95e6043e",
            "context": " Adversarial Taboo. Concurrent works\u2014Genius, EMPO,"
          },
          {
            "section": "sections/sec_247e121e",
            "context": " Adversarial Taboo. Concurrent works\u2014Genius, EMPO,"
          }
        ]
      },
      {
        "_key": "ent_7ec5b99e",
        "_id": "entities/ent_7ec5b99e",
        "name": "Genius",
        "type": "unknown",
        "mentions": [
          {
            "section": "sections/sec_95e6043e",
            "context": "o. Concurrent works\u2014Genius, EMPO, and TTRL(Xu "
          },
          {
            "section": "sections/sec_247e121e",
            "context": "o. Concurrent works\u2014Genius, EMPO, and TTRL(Xu "
          }
        ]
      },
      {
        "_key": "ent_a603e92e",
        "_id": "entities/ent_a603e92e",
        "name": "Minimo",
        "type": "unknown",
        "mentions": [
          {
            "section": "sections/sec_95e6043e",
            "context": "tribution. Finally, Minimo(Poesia et\u00a0al.,2024)"
          },
          {
            "section": "sections/sec_247e121e",
            "context": "tribution. Finally, Minimo(Poesia et\u00a0al.,2024)"
          }
        ]
      },
      {
        "_key": "ent_4b7e8830",
        "_id": "entities/ent_4b7e8830",
        "name": "Poesia",
        "type": "unknown",
        "mentions": [
          {
            "section": "sections/sec_95e6043e",
            "context": "on. Finally, Minimo(Poesia et\u00a0al.,2024)extends"
          },
          {
            "section": "sections/sec_247e121e",
            "context": "on. Finally, Minimo(Poesia et\u00a0al.,2024)extends"
          }
        ]
      },
      {
        "_key": "ent_7324e372",
        "_id": "entities/ent_7324e372",
        "name": "Weak",
        "type": "unknown",
        "mentions": [
          {
            "section": "sections/sec_95e6043e",
            "context": "to facilitate RLVR. Weak-to-Strong Supervisi"
          }
        ]
      },
      {
        "_key": "ent_db9a2167",
        "_id": "entities/ent_db9a2167",
        "name": "Strong Supervision",
        "type": "unknown",
        "mentions": [
          {
            "section": "sections/sec_95e6043e",
            "context": "itate RLVR. Weak-to-Strong Supervision.The concept of weak"
          }
        ]
      },
      {
        "_key": "ent_590f62b3",
        "_id": "entities/ent_590f62b3",
        "name": "Burns",
        "type": "unknown",
        "mentions": [
          {
            "section": "sections/sec_95e6043e",
            "context": "des useful guidance(Burns et\u00a0al.,2024;Hinton "
          },
          {
            "section": "sections/sec_5aa2a6bb",
            "context": "des useful guidance(Burns et\u00a0al.,2024;Hinton "
          }
        ]
      },
      {
        "_key": "ent_98d2ef46",
        "_id": "entities/ent_98d2ef46",
        "name": "Hinton",
        "type": "unknown",
        "mentions": [
          {
            "section": "sections/sec_95e6043e",
            "context": "e(Burns et\u00a0al.,2024;Hinton et\u00a0al.,2015;Christi"
          },
          {
            "section": "sections/sec_5aa2a6bb",
            "context": "e(Burns et\u00a0al.,2024;Hinton et\u00a0al.,2015;Christi"
          }
        ]
      },
      {
        "_key": "ent_8f470864",
        "_id": "entities/ent_8f470864",
        "name": "Christiano",
        "type": "unknown",
        "mentions": [
          {
            "section": "sections/sec_95e6043e",
            "context": ";Hinton et\u00a0al.,2015;Christiano,2018;2019;Demski & "
          },
          {
            "section": "sections/sec_5aa2a6bb",
            "context": ";Hinton et\u00a0al.,2015;Christiano,2018;2019;Demski & "
          }
        ]
      },
      {
        "_key": "ent_197db0da",
        "_id": "entities/ent_197db0da",
        "name": "Demski",
        "type": "unknown",
        "mentions": [
          {
            "section": "sections/sec_95e6043e",
            "context": "hristiano,2018;2019;Demski & Garrabrant,2019;L"
          },
          {
            "section": "sections/sec_5aa2a6bb",
            "context": "hristiano,2018;2019;Demski & Garrabrant,2019;L"
          }
        ]
      },
      {
        "_key": "ent_a0aace70",
        "_id": "entities/ent_a0aace70",
        "name": "Garrabrant",
        "type": "unknown",
        "mentions": [
          {
            "section": "sections/sec_95e6043e",
            "context": ",2018;2019;Demski & Garrabrant,2019;Leike & Sutske"
          },
          {
            "section": "sections/sec_5aa2a6bb",
            "context": ",2018;2019;Demski & Garrabrant,2019;Leike & Sutske"
          }
        ]
      },
      {
        "_key": "ent_8321eb6d",
        "_id": "entities/ent_8321eb6d",
        "name": "Leike",
        "type": "unknown",
        "mentions": [
          {
            "section": "sections/sec_95e6043e",
            "context": "i & Garrabrant,2019;Leike & Sutskever,2023;Hu"
          },
          {
            "section": "sections/sec_5aa2a6bb",
            "context": "i & Garrabrant,2019;Leike & Sutskever,2023;Hu"
          }
        ]
      },
      {
        "_key": "ent_61b9dceb",
        "_id": "entities/ent_61b9dceb",
        "name": "Hubinger",
        "type": "unknown",
        "mentions": [
          {
            "section": "sections/sec_95e6043e",
            "context": "ke & Sutskever,2023;Hubinger et\u00a0al.,2019). We co"
          },
          {
            "section": "sections/sec_5aa2a6bb",
            "context": "ke & Sutskever,2023;Hubinger et\u00a0al.,2019). We co"
          }
        ]
      },
      {
        "_key": "ent_6f8b794f",
        "_id": "entities/ent_6f8b794f",
        "name": "Conclusion",
        "type": "unknown",
        "mentions": [
          {
            "section": "sections/sec_ab2bd446",
            "context": "Conclusion.In this work, we pr"
          }
        ]
      },
      {
        "_key": "ent_a0da16a9",
        "_id": "entities/ent_a0da16a9",
        "name": "Remarkably",
        "type": "unknown",
        "mentions": [
          {
            "section": "sections/sec_ab2bd446",
            "context": " reasoning domains. Remarkably, even though our mo"
          },
          {
            "section": "sections/sec_97b161c9",
            "context": " reasoning domains. Remarkably, even though our mo"
          }
        ]
      }
    ]
  },
  "edges": {
    "contains": [
      {
        "_from": "documents/doc_0f099f71",
        "_to": "sections/sec_b3c1564c",
        "type": "section"
      },
      {
        "_from": "documents/doc_0f099f71",
        "_to": "sections/sec_f9e77f68",
        "type": "section"
      },
      {
        "_from": "sections/sec_f9e77f68",
        "_to": "sections/sec_157180aa",
        "type": "subsection"
      },
      {
        "_from": "sections/sec_157180aa",
        "_to": "sections/sec_ef8e3d10",
        "type": "subsection"
      },
      {
        "_from": "sections/sec_157180aa",
        "_to": "sections/sec_90f30199",
        "type": "subsection"
      },
      {
        "_from": "sections/sec_f9e77f68",
        "_to": "sections/sec_0af4c861",
        "type": "subsection"
      },
      {
        "_from": "documents/doc_0f099f71",
        "_to": "sections/sec_1a5d9820",
        "type": "section"
      },
      {
        "_from": "sections/sec_1a5d9820",
        "_to": "sections/sec_6d8d3b93",
        "type": "subsection"
      },
      {
        "_from": "sections/sec_6d8d3b93",
        "_to": "sections/sec_2f0cfe08",
        "type": "subsection"
      },
      {
        "_from": "sections/sec_1a5d9820",
        "_to": "sections/sec_0d24aa19",
        "type": "subsection"
      },
      {
        "_from": "sections/sec_1a5d9820",
        "_to": "sections/sec_3d319639",
        "type": "subsection"
      },
      {
        "_from": "sections/sec_3d319639",
        "_to": "sections/sec_4af9d86a",
        "type": "subsection"
      },
      {
        "_from": "sections/sec_3d319639",
        "_to": "sections/sec_1020a1e3",
        "type": "subsection"
      },
      {
        "_from": "sections/sec_3d319639",
        "_to": "sections/sec_ff7baeac",
        "type": "subsection"
      },
      {
        "_from": "sections/sec_3d319639",
        "_to": "sections/sec_bc334225",
        "type": "subsection"
      },
      {
        "_from": "sections/sec_3d319639",
        "_to": "sections/sec_730b34d8",
        "type": "subsection"
      },
      {
        "_from": "documents/doc_0f099f71",
        "_to": "sections/sec_5c55d4bc",
        "type": "section"
      },
      {
        "_from": "sections/sec_5c55d4bc",
        "_to": "sections/sec_6ba6439f",
        "type": "subsection"
      },
      {
        "_from": "sections/sec_6ba6439f",
        "_to": "sections/sec_ba8c62bf",
        "type": "subsection"
      },
      {
        "_from": "sections/sec_6ba6439f",
        "_to": "sections/sec_4b5715ec",
        "type": "subsection"
      },
      {
        "_from": "sections/sec_6ba6439f",
        "_to": "sections/sec_f6a941fe",
        "type": "subsection"
      },
      {
        "_from": "sections/sec_5c55d4bc",
        "_to": "sections/sec_56cabe86",
        "type": "subsection"
      },
      {
        "_from": "sections/sec_56cabe86",
        "_to": "sections/sec_773a923f",
        "type": "subsection"
      },
      {
        "_from": "sections/sec_56cabe86",
        "_to": "sections/sec_b69f3870",
        "type": "subsection"
      },
      {
        "_from": "sections/sec_56cabe86",
        "_to": "sections/sec_9cc89151",
        "type": "subsection"
      },
      {
        "_from": "sections/sec_56cabe86",
        "_to": "sections/sec_04cca2bb",
        "type": "subsection"
      },
      {
        "_from": "sections/sec_56cabe86",
        "_to": "sections/sec_72c37985",
        "type": "subsection"
      },
      {
        "_from": "sections/sec_56cabe86",
        "_to": "sections/sec_94b98c7f",
        "type": "subsection"
      },
      {
        "_from": "sections/sec_56cabe86",
        "_to": "sections/sec_bb5ac41e",
        "type": "subsection"
      },
      {
        "_from": "sections/sec_56cabe86",
        "_to": "sections/sec_985245d2",
        "type": "subsection"
      },
      {
        "_from": "documents/doc_0f099f71",
        "_to": "sections/sec_95e6043e",
        "type": "section"
      },
      {
        "_from": "sections/sec_95e6043e",
        "_to": "sections/sec_485ba230",
        "type": "subsection"
      },
      {
        "_from": "sections/sec_95e6043e",
        "_to": "sections/sec_247e121e",
        "type": "subsection"
      },
      {
        "_from": "sections/sec_95e6043e",
        "_to": "sections/sec_5aa2a6bb",
        "type": "subsection"
      },
      {
        "_from": "documents/doc_0f099f71",
        "_to": "sections/sec_ab2bd446",
        "type": "section"
      },
      {
        "_from": "sections/sec_ab2bd446",
        "_to": "sections/sec_97b161c9",
        "type": "subsection"
      }
    ],
    "references": [],
    "mentions": [
      {
        "_from": "sections/sec_b3c1564c",
        "_to": "entities/ent_3a69b34c",
        "context": "Large language models (LL"
      },
      {
        "_from": "sections/sec_6d8d3b93",
        "_to": "entities/ent_3a69b34c",
        "context": "Large language models are"
      },
      {
        "_from": "sections/sec_b3c1564c",
        "_to": "entities/ent_44f89957",
        "context": "lities by employing Reinforcement Learning with Verifiable Rew"
      },
      {
        "_from": "sections/sec_f9e77f68",
        "_to": "entities/ent_44f89957",
        "context": " doesn\u2019t scale well.Reinforcement Learning with Verifiable Rew"
      },
      {
        "_from": "sections/sec_157180aa",
        "_to": "entities/ent_44f89957",
        "context": "doesn\u2019t scale well. Reinforcement Learning with Verifiable Rew"
      },
      {
        "_from": "sections/sec_b3c1564c",
        "_to": "entities/ent_54a18906",
        "context": "ement Learning with Verifiable Rewards (RLVR)(Lambert et\u00a0a"
      },
      {
        "_from": "sections/sec_f9e77f68",
        "_to": "entities/ent_54a18906",
        "context": "ement Learning with Verifiable Rewards (RLVR).To move beyo"
      },
      {
        "_from": "sections/sec_157180aa",
        "_to": "entities/ent_54a18906",
        "context": "ement Learning with Verifiable Rewards (RLVR).To move beyo"
      },
      {
        "_from": "sections/sec_b3c1564c",
        "_to": "entities/ent_26cd1429",
        "context": "able Rewards (RLVR)(Lambert et\u00a0al.,2024). Unlik"
      },
      {
        "_from": "sections/sec_1a5d9820",
        "_to": "entities/ent_26cd1429",
        "context": "Seek-AI et\u00a0al.,2025;Lambert et\u00a0al.,2024). All p"
      },
      {
        "_from": "sections/sec_0d24aa19",
        "_to": "entities/ent_26cd1429",
        "context": "Seek-AI et\u00a0al.,2025;Lambert et\u00a0al.,2024). All p"
      },
      {
        "_from": "sections/sec_95e6043e",
        "_to": "entities/ent_26cd1429",
        "context": "rge language models(Lambert et\u00a0al.,2024). One o"
      },
      {
        "_from": "sections/sec_95e6043e",
        "_to": "entities/ent_26cd1429",
        "context": "rge language models(Lambert et\u00a0al.,2024). One o"
      },
      {
        "_from": "sections/sec_485ba230",
        "_to": "entities/ent_26cd1429",
        "context": "rge language models(Lambert et\u00a0al.,2024). One o"
      },
      {
        "_from": "sections/sec_247e121e",
        "_to": "entities/ent_26cd1429",
        "context": "for reasoning tasks(Lambert et\u00a0al.,2024). SPCCh"
      },
      {
        "_from": "sections/sec_b3c1564c",
        "_to": "entities/ent_2e54a377",
        "context": "mbert et\u00a0al.,2024). Unlike methods that explic"
      },
      {
        "_from": "sections/sec_5c55d4bc",
        "_to": "entities/ent_2e54a377",
        "context": "ss of our approach. Unlike other RLVR models t"
      },
      {
        "_from": "sections/sec_5c55d4bc",
        "_to": "entities/ent_2e54a377",
        "context": "ss of our approach. Unlike other RLVR models t"
      },
      {
        "_from": "sections/sec_56cabe86",
        "_to": "entities/ent_2e54a377",
        "context": "ss of our approach. Unlike other RLVR models t"
      },
      {
        "_from": "sections/sec_56cabe86",
        "_to": "entities/ent_2e54a377",
        "context": "ss of our approach. Unlike other RLVR models t"
      },
      {
        "_from": "sections/sec_773a923f",
        "_to": "entities/ent_2e54a377",
        "context": "ss of our approach. Unlike other RLVR models t"
      },
      {
        "_from": "sections/sec_04cca2bb",
        "_to": "entities/ent_2e54a377",
        "context": "se shown inFigure6. Unlike the 3B and 14B cate"
      },
      {
        "_from": "sections/sec_b3c1564c",
        "_to": "entities/ent_ac848fa2",
        "context": "Seek-AI et\u00a0al.,2025;Team et\u00a0al.,2025;Jaech e"
      },
      {
        "_from": "sections/sec_b3c1564c",
        "_to": "entities/ent_b46299bb",
        "context": "25;Team et\u00a0al.,2025;Jaech et\u00a0al.,2024;OpenAI,"
      },
      {
        "_from": "sections/sec_95e6043e",
        "_to": "entities/ent_b46299bb",
        "context": "monumental work, o1(Jaech et\u00a0al.,2024), was a"
      },
      {
        "_from": "sections/sec_485ba230",
        "_to": "entities/ent_b46299bb",
        "context": "monumental work, o1(Jaech et\u00a0al.,2024), was a"
      },
      {
        "_from": "sections/sec_b3c1564c",
        "_to": "entities/ent_691f9cea",
        "context": " with task rewards. However, these methods stil"
      },
      {
        "_from": "sections/sec_f9e77f68",
        "_to": "entities/ent_691f9cea",
        "context": "PT \u2223 italic_x ) .(1)However, at the frontier le"
      },
      {
        "_from": "sections/sec_f9e77f68",
        "_to": "entities/ent_691f9cea",
        "context": "PT \u2223 italic_x ) .(1)However, at the frontier le"
      },
      {
        "_from": "sections/sec_157180aa",
        "_to": "entities/ent_691f9cea",
        "context": "PT \u2223 italic_x ) .(1)However, at the frontier le"
      },
      {
        "_from": "sections/sec_157180aa",
        "_to": "entities/ent_691f9cea",
        "context": "PT \u2223 italic_x ) .(1)However, at the frontier le"
      },
      {
        "_from": "sections/sec_ef8e3d10",
        "_to": "entities/ent_691f9cea",
        "context": "T \u2223 italic_x ) .(1) However, at the frontier le"
      },
      {
        "_from": "sections/sec_90f30199",
        "_to": "entities/ent_691f9cea",
        "context": "_POSTSUPERSCRIPT ). However, the learning task "
      },
      {
        "_from": "sections/sec_5c55d4bc",
        "_to": "entities/ent_691f9cea",
        "context": "vely weaker models. However, these gains appear"
      },
      {
        "_from": "sections/sec_56cabe86",
        "_to": "entities/ent_691f9cea",
        "context": "vely weaker models. However, these gains appear"
      },
      {
        "_from": "sections/sec_04cca2bb",
        "_to": "entities/ent_691f9cea",
        "context": "vely weaker models. However, these gains appear"
      },
      {
        "_from": "sections/sec_95e6043e",
        "_to": "entities/ent_691f9cea",
        "context": "human capabilities. However, rather than relyin"
      },
      {
        "_from": "sections/sec_5aa2a6bb",
        "_to": "entities/ent_691f9cea",
        "context": "human capabilities. However, rather than relyin"
      },
      {
        "_from": "sections/sec_b3c1564c",
        "_to": "entities/ent_d5c32474",
        "context": "ng-term scalability(Villalobos et\u00a0al.,2024). As re"
      },
      {
        "_from": "sections/sec_b3c1564c",
        "_to": "entities/ent_d233558d",
        "context": " of LLM pretraining(Sutskever et\u00a0al.,2024). Furth"
      },
      {
        "_from": "sections/sec_95e6043e",
        "_to": "entities/ent_d233558d",
        "context": "abrant,2019;Leike & Sutskever,2023;Hubinger et\u00a0al"
      },
      {
        "_from": "sections/sec_5aa2a6bb",
        "_to": "entities/ent_d233558d",
        "context": "abrant,2019;Leike & Sutskever,2023;Hubinger et\u00a0al"
      },
      {
        "_from": "sections/sec_b3c1564c",
        "_to": "entities/ent_1dc492cd",
        "context": "kever et\u00a0al.,2024). Furthermore, as AI systems cont"
      },
      {
        "_from": "sections/sec_b3c1564c",
        "_to": "entities/ent_1dc492cd",
        "context": "kever et\u00a0al.,2024). Furthermore, as AI systems cont"
      },
      {
        "_from": "sections/sec_b3c1564c",
        "_to": "entities/ent_1dc492cd",
        "context": "kever et\u00a0al.,2024). Furthermore, as AI systems cont"
      },
      {
        "_from": "sections/sec_5c55d4bc",
        "_to": "entities/ent_1dc492cd",
        "context": "Yang et\u00a0al.,2024b). Furthermore, the zero-style mod"
      },
      {
        "_from": "sections/sec_6ba6439f",
        "_to": "entities/ent_1dc492cd",
        "context": "Yang et\u00a0al.,2024b). Furthermore, the zero-style mod"
      },
      {
        "_from": "sections/sec_f6a941fe",
        "_to": "entities/ent_1dc492cd",
        "context": "Yang et\u00a0al.,2024b). Furthermore, the zero-style mod"
      },
      {
        "_from": "sections/sec_95e6043e",
        "_to": "entities/ent_1dc492cd",
        "context": "le learning signal. Furthermore, in our proposed me"
      },
      {
        "_from": "sections/sec_5aa2a6bb",
        "_to": "entities/ent_1dc492cd",
        "context": "le learning signal. Furthermore, in our proposed me"
      },
      {
        "_from": "sections/sec_ab2bd446",
        "_to": "entities/ent_1dc492cd",
        "context": "ific training data. Furthermore, we showed that AZR"
      },
      {
        "_from": "sections/sec_97b161c9",
        "_to": "entities/ent_1dc492cd",
        "context": "ific training data. Furthermore, we showed that AZR"
      },
      {
        "_from": "sections/sec_b3c1564c",
        "_to": "entities/ent_ae115213",
        "context": "learning and growth(Hughes et\u00a0al.,2024). This "
      },
      {
        "_from": "sections/sec_b3c1564c",
        "_to": "entities/ent_ae115213",
        "context": "learning and growth(Hughes et\u00a0al.,2024). This "
      },
      {
        "_from": "sections/sec_b3c1564c",
        "_to": "entities/ent_4778f3ba",
        "context": "his end, we propose\u201cAbsolute Zero\u201d, a new paradigm fo"
      },
      {
        "_from": "sections/sec_b3c1564c",
        "_to": "entities/ent_4778f3ba",
        "context": "his end, we propose\u201cAbsolute Zero\u201d, a new paradigm fo"
      },
      {
        "_from": "sections/sec_b3c1564c",
        "_to": "entities/ent_4778f3ba",
        "context": "his end, we propose\u201cAbsolute Zero\u201d, a new paradigm fo"
      },
      {
        "_from": "sections/sec_f9e77f68",
        "_to": "entities/ent_4778f3ba",
        "context": "it scalability. The Absolute Zero paradigm removes th"
      },
      {
        "_from": "sections/sec_f9e77f68",
        "_to": "entities/ent_4778f3ba",
        "context": "it scalability. The Absolute Zero paradigm removes th"
      },
      {
        "_from": "sections/sec_f9e77f68",
        "_to": "entities/ent_4778f3ba",
        "context": "it scalability. The Absolute Zero paradigm removes th"
      },
      {
        "_from": "sections/sec_0af4c861",
        "_to": "entities/ent_4778f3ba",
        "context": "We propose the Absolute Zero paradigm, where dur"
      },
      {
        "_from": "sections/sec_0af4c861",
        "_to": "entities/ent_4778f3ba",
        "context": "We propose the Absolute Zero paradigm, where dur"
      },
      {
        "_from": "sections/sec_0af4c861",
        "_to": "entities/ent_4778f3ba",
        "context": "We propose the Absolute Zero paradigm, where dur"
      },
      {
        "_from": "sections/sec_1a5d9820",
        "_to": "entities/ent_4778f3ba",
        "context": " section, we presentAbsolute Zero Reasoner(AZR) as th"
      },
      {
        "_from": "sections/sec_6d8d3b93",
        "_to": "entities/ent_4778f3ba",
        "context": "as specified by the Absolute Zero objective inEquatio"
      },
      {
        "_from": "sections/sec_5c55d4bc",
        "_to": "entities/ent_4778f3ba",
        "context": "-Coder, resulting inAbsolute Zero Reasoner-base-7Band"
      },
      {
        "_from": "sections/sec_56cabe86",
        "_to": "entities/ent_4778f3ba",
        "context": "32.745.055.641.648.6Absolute Zero Training w/ No Cura"
      },
      {
        "_from": "sections/sec_9cc89151",
        "_to": "entities/ent_4778f3ba",
        "context": " performance in the Absolute Zero paradigm. (a)Model "
      },
      {
        "_from": "sections/sec_ab2bd446",
        "_to": "entities/ent_4778f3ba",
        "context": "rk, we proposed the Absolute Zero paradigm, a novel s"
      },
      {
        "_from": "sections/sec_97b161c9",
        "_to": "entities/ent_4778f3ba",
        "context": "rk, we proposed the Absolute Zero paradigm, a novel s"
      },
      {
        "_from": "sections/sec_b3c1564c",
        "_to": "entities/ent_f96e345f",
        "context": "re prone to hacking(Silver et\u00a0al.,2017;Chen et"
      },
      {
        "_from": "sections/sec_b3c1564c",
        "_to": "entities/ent_f96e345f",
        "context": "re prone to hacking(Silver et\u00a0al.,2017;Chen et"
      },
      {
        "_from": "sections/sec_95e6043e",
        "_to": "entities/ent_f96e345f",
        "context": "phaGo and AlphaZero(Silver et\u00a0al.,2016;2017)ex"
      },
      {
        "_from": "sections/sec_247e121e",
        "_to": "entities/ent_f96e345f",
        "context": "phaGo and AlphaZero(Silver et\u00a0al.,2016;2017)ex"
      },
      {
        "_from": "sections/sec_b3c1564c",
        "_to": "entities/ent_ef6bf3fd",
        "context": "(Silver et\u00a0al.,2017;Chen et\u00a0al.,2025;2024), "
      },
      {
        "_from": "sections/sec_95e6043e",
        "_to": "entities/ent_ef6bf3fd",
        "context": "ing Language Models(Chen et\u00a0al.,2024;Yuan et"
      },
      {
        "_from": "sections/sec_247e121e",
        "_to": "entities/ent_ef6bf3fd",
        "context": "ing Language Models(Chen et\u00a0al.,2024;Yuan et"
      },
      {
        "_from": "sections/sec_b3c1564c",
        "_to": "entities/ent_74d6c578",
        "context": ";2024), theAbsolute Zeroparadigm is designed to oper"
      },
      {
        "_from": "sections/sec_b3c1564c",
        "_to": "entities/ent_0efa04d9",
        "context": "ughes et\u00a0al.,2024). Similar to AlphaZero(Silver"
      },
      {
        "_from": "sections/sec_b3c1564c",
        "_to": "entities/ent_0efa04d9",
        "context": "ughes et\u00a0al.,2024). Similar to AlphaZero(Silver"
      },
      {
        "_from": "sections/sec_b3c1564c",
        "_to": "entities/ent_c39b56d4",
        "context": "oning capabilities. Building on this new reasoni"
      },
      {
        "_from": "sections/sec_b3c1564c",
        "_to": "entities/ent_f40795eb",
        "context": "troduce theAbsolute Zero Reasoner (AZR), which propos"
      },
      {
        "_from": "sections/sec_1a5d9820",
        "_to": "entities/ent_f40795eb",
        "context": " we presentAbsolute Zero Reasoner(AZR) as the first a"
      },
      {
        "_from": "sections/sec_5c55d4bc",
        "_to": "entities/ent_f40795eb",
        "context": "esulting inAbsolute Zero Reasoner-base-7BandAbsolute "
      },
      {
        "_from": "sections/sec_5c55d4bc",
        "_to": "entities/ent_f40795eb",
        "context": "esulting inAbsolute Zero Reasoner-base-7BandAbsolute "
      },
      {
        "_from": "sections/sec_5c55d4bc",
        "_to": "entities/ent_f40795eb",
        "context": "esulting inAbsolute Zero Reasoner-base-7BandAbsolute "
      },
      {
        "_from": "sections/sec_5c55d4bc",
        "_to": "entities/ent_f40795eb",
        "context": "esulting inAbsolute Zero Reasoner-base-7BandAbsolute "
      },
      {
        "_from": "sections/sec_6ba6439f",
        "_to": "entities/ent_f40795eb",
        "context": "esulting inAbsolute Zero Reasoner-base-7BandAbsolute "
      },
      {
        "_from": "sections/sec_6ba6439f",
        "_to": "entities/ent_f40795eb",
        "context": "esulting inAbsolute Zero Reasoner-base-7BandAbsolute "
      },
      {
        "_from": "sections/sec_ba8c62bf",
        "_to": "entities/ent_f40795eb",
        "context": "esulting inAbsolute Zero Reasoner-base-7BandAbsolute "
      },
      {
        "_from": "sections/sec_ba8c62bf",
        "_to": "entities/ent_f40795eb",
        "context": "esulting inAbsolute Zero Reasoner-base-7BandAbsolute "
      },
      {
        "_from": "sections/sec_56cabe86",
        "_to": "entities/ent_f40795eb",
        "context": "1. Notably,Absolute Zero Reasoner-Coder-7Bachieves st"
      },
      {
        "_from": "sections/sec_56cabe86",
        "_to": "entities/ent_f40795eb",
        "context": "1. Notably,Absolute Zero Reasoner-Coder-7Bachieves st"
      },
      {
        "_from": "sections/sec_72c37985",
        "_to": "entities/ent_f40795eb",
        "context": "patterns inAbsolute Zero Reasoner-Llama3.1-8B, simila"
      },
      {
        "_from": "sections/sec_94b98c7f",
        "_to": "entities/ent_f40795eb",
        "context": " using onlyAbsolute Zero Reasoner-Base-7B. We begin b"
      },
      {
        "_from": "sections/sec_b3c1564c",
        "_to": "entities/ent_b3043682",
        "context": " proposed approach. Despite being trained entir"
      },
      {
        "_from": "sections/sec_5c55d4bc",
        "_to": "entities/ent_b3043682",
        "context": "average categories. Despite being entirely out-"
      },
      {
        "_from": "sections/sec_56cabe86",
        "_to": "entities/ent_b3043682",
        "context": "average categories. Despite being entirely out-"
      },
      {
        "_from": "sections/sec_773a923f",
        "_to": "entities/ent_b3043682",
        "context": "average categories. Despite being entirely out-"
      },
      {
        "_from": "sections/sec_b3c1564c",
        "_to": "entities/ent_37341076",
        "context": " pivotal milestone. Besides the remarkable resu"
      },
      {
        "_from": "sections/sec_b3c1564c",
        "_to": "entities/ent_ca0dbad9",
        "context": "s summarized below:\u2022Code priors amplify reas"
      },
      {
        "_from": "sections/sec_b3c1564c",
        "_to": "entities/ent_14c0f98e",
        "context": "soning.The baseQwen-Coder-7bmodel started wit"
      },
      {
        "_from": "sections/sec_b3c1564c",
        "_to": "entities/ent_14c0f98e",
        "context": "soning.The baseQwen-Coder-7bmodel started wit"
      },
      {
        "_from": "sections/sec_5c55d4bc",
        "_to": "entities/ent_14c0f98e",
        "context": "2.5-7BandQwen2.5-7B-Coder, resulting inAbsolu"
      },
      {
        "_from": "sections/sec_5c55d4bc",
        "_to": "entities/ent_14c0f98e",
        "context": "2.5-7BandQwen2.5-7B-Coder, resulting inAbsolu"
      },
      {
        "_from": "sections/sec_5c55d4bc",
        "_to": "entities/ent_14c0f98e",
        "context": "2.5-7BandQwen2.5-7B-Coder, resulting inAbsolu"
      },
      {
        "_from": "sections/sec_5c55d4bc",
        "_to": "entities/ent_14c0f98e",
        "context": "2.5-7BandQwen2.5-7B-Coder, resulting inAbsolu"
      },
      {
        "_from": "sections/sec_5c55d4bc",
        "_to": "entities/ent_14c0f98e",
        "context": "2.5-7BandQwen2.5-7B-Coder, resulting inAbsolu"
      },
      {
        "_from": "sections/sec_5c55d4bc",
        "_to": "entities/ent_14c0f98e",
        "context": "2.5-7BandQwen2.5-7B-Coder, resulting inAbsolu"
      },
      {
        "_from": "sections/sec_5c55d4bc",
        "_to": "entities/ent_14c0f98e",
        "context": "2.5-7BandQwen2.5-7B-Coder, resulting inAbsolu"
      },
      {
        "_from": "sections/sec_5c55d4bc",
        "_to": "entities/ent_14c0f98e",
        "context": "2.5-7BandQwen2.5-7B-Coder, resulting inAbsolu"
      },
      {
        "_from": "sections/sec_5c55d4bc",
        "_to": "entities/ent_14c0f98e",
        "context": "2.5-7BandQwen2.5-7B-Coder, resulting inAbsolu"
      },
      {
        "_from": "sections/sec_5c55d4bc",
        "_to": "entities/ent_14c0f98e",
        "context": "2.5-7BandQwen2.5-7B-Coder, resulting inAbsolu"
      },
      {
        "_from": "sections/sec_5c55d4bc",
        "_to": "entities/ent_14c0f98e",
        "context": "2.5-7BandQwen2.5-7B-Coder, resulting inAbsolu"
      },
      {
        "_from": "sections/sec_6ba6439f",
        "_to": "entities/ent_14c0f98e",
        "context": "2.5-7BandQwen2.5-7B-Coder, resulting inAbsolu"
      },
      {
        "_from": "sections/sec_6ba6439f",
        "_to": "entities/ent_14c0f98e",
        "context": "2.5-7BandQwen2.5-7B-Coder, resulting inAbsolu"
      },
      {
        "_from": "sections/sec_6ba6439f",
        "_to": "entities/ent_14c0f98e",
        "context": "2.5-7BandQwen2.5-7B-Coder, resulting inAbsolu"
      },
      {
        "_from": "sections/sec_6ba6439f",
        "_to": "entities/ent_14c0f98e",
        "context": "2.5-7BandQwen2.5-7B-Coder, resulting inAbsolu"
      },
      {
        "_from": "sections/sec_6ba6439f",
        "_to": "entities/ent_14c0f98e",
        "context": "2.5-7BandQwen2.5-7B-Coder, resulting inAbsolu"
      },
      {
        "_from": "sections/sec_ba8c62bf",
        "_to": "entities/ent_14c0f98e",
        "context": "2.5-7BandQwen2.5-7B-Coder, resulting inAbsolu"
      },
      {
        "_from": "sections/sec_ba8c62bf",
        "_to": "entities/ent_14c0f98e",
        "context": "2.5-7BandQwen2.5-7B-Coder, resulting inAbsolu"
      },
      {
        "_from": "sections/sec_ba8c62bf",
        "_to": "entities/ent_14c0f98e",
        "context": "2.5-7BandQwen2.5-7B-Coder, resulting inAbsolu"
      },
      {
        "_from": "sections/sec_ba8c62bf",
        "_to": "entities/ent_14c0f98e",
        "context": "2.5-7BandQwen2.5-7B-Coder, resulting inAbsolu"
      },
      {
        "_from": "sections/sec_f6a941fe",
        "_to": "entities/ent_14c0f98e",
        "context": "variants:Qwen2.5-7B-Coder,Qwen2.5-7B-Instruct"
      },
      {
        "_from": "sections/sec_56cabe86",
        "_to": "entities/ent_14c0f98e",
        "context": "337.046.7Qwen2.5-7B-Coder[26]--80.569.319.96."
      },
      {
        "_from": "sections/sec_56cabe86",
        "_to": "entities/ent_14c0f98e",
        "context": "337.046.7Qwen2.5-7B-Coder[26]--80.569.319.96."
      },
      {
        "_from": "sections/sec_56cabe86",
        "_to": "entities/ent_14c0f98e",
        "context": "337.046.7Qwen2.5-7B-Coder[26]--80.569.319.96."
      },
      {
        "_from": "sections/sec_56cabe86",
        "_to": "entities/ent_14c0f98e",
        "context": "337.046.7Qwen2.5-7B-Coder[26]--80.569.319.96."
      },
      {
        "_from": "sections/sec_56cabe86",
        "_to": "entities/ent_14c0f98e",
        "context": "337.046.7Qwen2.5-7B-Coder[26]--80.569.319.96."
      },
      {
        "_from": "sections/sec_56cabe86",
        "_to": "entities/ent_14c0f98e",
        "context": "337.046.7Qwen2.5-7B-Coder[26]--80.569.319.96."
      },
      {
        "_from": "sections/sec_773a923f",
        "_to": "entities/ent_14c0f98e",
        "context": "olute Zero Reasoner-Coder-7Bachieves state-of"
      },
      {
        "_from": "sections/sec_9cc89151",
        "_to": "entities/ent_14c0f98e",
        "context": "variants:Qwen2.5-3B-CoderandQwen2.5-14B-Coder"
      },
      {
        "_from": "sections/sec_9cc89151",
        "_to": "entities/ent_14c0f98e",
        "context": "variants:Qwen2.5-3B-CoderandQwen2.5-14B-Coder"
      },
      {
        "_from": "sections/sec_9cc89151",
        "_to": "entities/ent_14c0f98e",
        "context": "variants:Qwen2.5-3B-CoderandQwen2.5-14B-Coder"
      },
      {
        "_from": "sections/sec_9cc89151",
        "_to": "entities/ent_14c0f98e",
        "context": "variants:Qwen2.5-3B-CoderandQwen2.5-14B-Coder"
      },
      {
        "_from": "sections/sec_b3c1564c",
        "_to": "entities/ent_e76b449b",
        "context": "after AZR training.\u2022Cross domain transfer is "
      },
      {
        "_from": "sections/sec_b3c1564c",
        "_to": "entities/ent_7bfcadb5",
        "context": " pronounced for AZR.After RLVR, expert code m"
      },
      {
        "_from": "sections/sec_5c55d4bc",
        "_to": "entities/ent_7bfcadb5",
        "context": "oding environments. After training, most expe"
      },
      {
        "_from": "sections/sec_56cabe86",
        "_to": "entities/ent_7bfcadb5",
        "context": "oding environments. After training, most expe"
      },
      {
        "_from": "sections/sec_773a923f",
        "_to": "entities/ent_7bfcadb5",
        "context": "oding environments. After training, most expe"
      },
      {
        "_from": "sections/sec_b3c1564c",
        "_to": "entities/ent_095a1b43",
        "context": "average, whereasAZR-Base-7BandAZR-Coder-7Btr"
      },
      {
        "_from": "sections/sec_5c55d4bc",
        "_to": "entities/ent_095a1b43",
        "context": "ure reproducibility.Baselines.For our main r"
      },
      {
        "_from": "sections/sec_56cabe86",
        "_to": "entities/ent_095a1b43",
        "context": "ModelBase#dataHEval+MBPP+LCBv"
      },
      {
        "_from": "sections/sec_94b98c7f",
        "_to": "entities/ent_095a1b43",
        "context": "olute Zero Reasoner-Base-7B. We begin by tes"
      },
      {
        "_from": "sections/sec_b3c1564c",
        "_to": "entities/ent_a2890fe0",
        "context": "g capability gains.\u2022Bigger bases yield bigger "
      },
      {
        "_from": "sections/sec_b3c1564c",
        "_to": "entities/ent_9446a98a",
        "context": " yield bigger gains.Performance improvements scale "
      },
      {
        "_from": "sections/sec_5c55d4bc",
        "_to": "entities/ent_9446a98a",
        "context": "RIPT end_ARGTable 1:Performance of RL-Trained Reaso"
      },
      {
        "_from": "sections/sec_5c55d4bc",
        "_to": "entities/ent_9446a98a",
        "context": "RIPT end_ARGTable 1:Performance of RL-Trained Reaso"
      },
      {
        "_from": "sections/sec_56cabe86",
        "_to": "entities/ent_9446a98a",
        "context": "RIPT end_ARGTable 1:Performance of RL-Trained Reaso"
      },
      {
        "_from": "sections/sec_56cabe86",
        "_to": "entities/ent_9446a98a",
        "context": "RIPT end_ARGTable 1:Performance of RL-Trained Reaso"
      },
      {
        "_from": "sections/sec_b3c1564c",
        "_to": "entities/ent_8413c683",
        "context": "vantageous for AZR.\u2022Comments as intermediate pla"
      },
      {
        "_from": "sections/sec_b3c1564c",
        "_to": "entities/ent_4e97aeea",
        "context": "ns emerge naturally.When solving code induct"
      },
      {
        "_from": "sections/sec_f9e77f68",
        "_to": "entities/ent_4e97aeea",
        "context": "stainable training. When proposing,z\ud835\udc67zitalic"
      },
      {
        "_from": "sections/sec_0af4c861",
        "_to": "entities/ent_4e97aeea",
        "context": "stainable training. When proposing,z\ud835\udc67zitalic"
      },
      {
        "_from": "sections/sec_5c55d4bc",
        "_to": "entities/ent_4e97aeea",
        "context": "es the given input. When predicting outputs,"
      },
      {
        "_from": "sections/sec_5c55d4bc",
        "_to": "entities/ent_4e97aeea",
        "context": "es the given input. When predicting outputs,"
      },
      {
        "_from": "sections/sec_56cabe86",
        "_to": "entities/ent_4e97aeea",
        "context": "es the given input. When predicting outputs,"
      },
      {
        "_from": "sections/sec_56cabe86",
        "_to": "entities/ent_4e97aeea",
        "context": "es the given input. When predicting outputs,"
      },
      {
        "_from": "sections/sec_72c37985",
        "_to": "entities/ent_4e97aeea",
        "context": "es the given input. When predicting outputs,"
      },
      {
        "_from": "sections/sec_72c37985",
        "_to": "entities/ent_4e97aeea",
        "context": "es the given input. When predicting outputs,"
      },
      {
        "_from": "sections/sec_b3c1564c",
        "_to": "entities/ent_26dcda57",
        "context": "ls such as DeepSeek Prover v2 (671B)(Ren et\u00a0al"
      },
      {
        "_from": "sections/sec_5c55d4bc",
        "_to": "entities/ent_26dcda57",
        "context": "ls, such asDeepSeek Prover v2, which is signif"
      },
      {
        "_from": "sections/sec_56cabe86",
        "_to": "entities/ent_26dcda57",
        "context": "ls, such asDeepSeek Prover v2, which is signif"
      },
      {
        "_from": "sections/sec_72c37985",
        "_to": "entities/ent_26dcda57",
        "context": "ls, such asDeepSeek Prover v2, which is signif"
      },
      {
        "_from": "sections/sec_95e6043e",
        "_to": "entities/ent_26dcda57",
        "context": "er et\u00a0al.(2024)uses Prover-Verifier Game for i"
      },
      {
        "_from": "sections/sec_247e121e",
        "_to": "entities/ent_26dcda57",
        "context": "er et\u00a0al.(2024)uses Prover-Verifier Game for i"
      },
      {
        "_from": "sections/sec_b3c1564c",
        "_to": "entities/ent_5f4fea76",
        "context": "er domains as well.\u2022Cognitive Behaviors and Token length de"
      },
      {
        "_from": "sections/sec_b3c1564c",
        "_to": "entities/ent_459a6f79",
        "context": "itive Behaviors and Token length depends on r"
      },
      {
        "_from": "sections/sec_b3c1564c",
        "_to": "entities/ent_41516cd0",
        "context": "s on reasoning mode.Distinct cognitive behaviors"
      },
      {
        "_from": "sections/sec_b3c1564c",
        "_to": "entities/ent_6472ce41",
        "context": "tion grow modestly.\u2022Safety alarms ringing.We o"
      },
      {
        "_from": "sections/sec_b3c1564c",
        "_to": "entities/ent_96641e4a",
        "context": "fety-aware training(Zhang et\u00a0al.,2025a)."
      },
      {
        "_from": "sections/sec_1a5d9820",
        "_to": "entities/ent_96641e4a",
        "context": "ment learning setup(Zhang & Yang,2021;Zhao et"
      },
      {
        "_from": "sections/sec_3d319639",
        "_to": "entities/ent_96641e4a",
        "context": "ment learning setup(Zhang & Yang,2021;Zhao et"
      },
      {
        "_from": "sections/sec_730b34d8",
        "_to": "entities/ent_96641e4a",
        "context": "ment learning setup(Zhang & Yang,2021;Zhao et"
      },
      {
        "_from": "sections/sec_5c55d4bc",
        "_to": "entities/ent_96641e4a",
        "context": "tCodeR1models(Liu & Zhang,2025). For math dat"
      },
      {
        "_from": "sections/sec_6ba6439f",
        "_to": "entities/ent_96641e4a",
        "context": "tCodeR1models(Liu & Zhang,2025). For math dat"
      },
      {
        "_from": "sections/sec_f6a941fe",
        "_to": "entities/ent_96641e4a",
        "context": "tCodeR1models(Liu & Zhang,2025). For math dat"
      },
      {
        "_from": "sections/sec_95e6043e",
        "_to": "entities/ent_96641e4a",
        "context": "TTRL(Xu et\u00a0al.,2025;Zhang et\u00a0al.,2025b;Zuo et"
      },
      {
        "_from": "sections/sec_247e121e",
        "_to": "entities/ent_96641e4a",
        "context": "TTRL(Xu et\u00a0al.,2025;Zhang et\u00a0al.,2025b;Zuo et"
      },
      {
        "_from": "sections/sec_f9e77f68",
        "_to": "entities/ent_5999b890",
        "context": "iminariesSupervised Fine-Tuning (SFT).SFT re"
      },
      {
        "_from": "sections/sec_f9e77f68",
        "_to": "entities/ent_89dd2948",
        "context": "riesSupervised Fine-Tuning (SFT).SFT requires "
      },
      {
        "_from": "sections/sec_157180aa",
        "_to": "entities/ent_89dd2948",
        "context": "Supervised Fine-Tuning (SFT).SFT requires "
      },
      {
        "_from": "sections/sec_f9e77f68",
        "_to": "entities/ent_3826805b",
        "context": "tive log-likelihood(Ouyang et\u00a0al.,2022):\u2112SFT\u2062("
      },
      {
        "_from": "sections/sec_157180aa",
        "_to": "entities/ent_3826805b",
        "context": "tive log-likelihood(Ouyang et\u00a0al.,2022):\u2112SFT\u2062("
      },
      {
        "_from": "sections/sec_ef8e3d10",
        "_to": "entities/ent_3826805b",
        "context": "tive log-likelihood(Ouyang et\u00a0al.,2022): \u2112SFT\u2062"
      },
      {
        "_from": "sections/sec_f9e77f68",
        "_to": "entities/ent_97f3c113",
        "context": " limit scalability. The Absolute Zero paradigm removes th"
      },
      {
        "_from": "sections/sec_f9e77f68",
        "_to": "entities/ent_97f3c113",
        "context": " limit scalability. The Absolute Zero paradigm removes th"
      },
      {
        "_from": "sections/sec_157180aa",
        "_to": "entities/ent_97f3c113",
        "context": " limit scalability. The Absolute Zero paradigm removes th"
      },
      {
        "_from": "sections/sec_90f30199",
        "_to": "entities/ent_97f3c113",
        "context": " limit scalability. The Absolute Zero paradigm removes th"
      },
      {
        "_from": "sections/sec_0af4c861",
        "_to": "entities/ent_97f3c113",
        "context": " training. Figure 3:The Absolute Zero Loop.The Absolute Z"
      },
      {
        "_from": "sections/sec_f9e77f68",
        "_to": "entities/ent_666df2f4",
        "context": "ate this paradigm inFigure2, which contrasts A"
      },
      {
        "_from": "sections/sec_0af4c861",
        "_to": "entities/ent_666df2f4",
        "context": "ate this paradigm inFigure2, which contrasts A"
      },
      {
        "_from": "sections/sec_1a5d9820",
        "_to": "entities/ent_666df2f4",
        "context": "Reasoner approach inFigure4. To expedite futur"
      },
      {
        "_from": "sections/sec_1a5d9820",
        "_to": "entities/ent_666df2f4",
        "context": "Reasoner approach inFigure4. To expedite futur"
      },
      {
        "_from": "sections/sec_6d8d3b93",
        "_to": "entities/ent_666df2f4",
        "context": " end_CELL end_ROW(4)Figure 4:Absolute Zero Rea"
      },
      {
        "_from": "sections/sec_2f0cfe08",
        "_to": "entities/ent_666df2f4",
        "context": "end_CELL end_ROW(4) Figure 4:Absolute Zero Rea"
      },
      {
        "_from": "sections/sec_0d24aa19",
        "_to": "entities/ent_666df2f4",
        "context": "eralized induction. Figure 5:The Seed AZR Zero"
      },
      {
        "_from": "sections/sec_5c55d4bc",
        "_to": "entities/ent_666df2f4",
        "context": "tribution results inFigure6(a) and (b), respec"
      },
      {
        "_from": "sections/sec_5c55d4bc",
        "_to": "entities/ent_666df2f4",
        "context": "tribution results inFigure6(a) and (b), respec"
      },
      {
        "_from": "sections/sec_56cabe86",
        "_to": "entities/ent_666df2f4",
        "context": "tribution results inFigure6(a) and (b), respec"
      },
      {
        "_from": "sections/sec_56cabe86",
        "_to": "entities/ent_666df2f4",
        "context": "tribution results inFigure6(a) and (b), respec"
      },
      {
        "_from": "sections/sec_9cc89151",
        "_to": "entities/ent_666df2f4",
        "context": "tribution results inFigure6(a) and (b), respec"
      },
      {
        "_from": "sections/sec_04cca2bb",
        "_to": "entities/ent_666df2f4",
        "context": "as the base shown inFigure6. Unlike the 3B and"
      },
      {
        "_from": "sections/sec_f9e77f68",
        "_to": "entities/ent_214ecbca",
        "context": "g training.Figure 3:The Absolute Zero Loop.The Absolute Zero l"
      },
      {
        "_from": "sections/sec_0af4c861",
        "_to": "entities/ent_214ecbca",
        "context": " training. Figure 3:The Absolute Zero Loop.The Absolute Zero l"
      },
      {
        "_from": "sections/sec_f9e77f68",
        "_to": "entities/ent_d48a5cda",
        "context": "PTfor learnability. Then, a standard RL step"
      },
      {
        "_from": "sections/sec_f9e77f68",
        "_to": "entities/ent_d48a5cda",
        "context": "PTfor learnability. Then, a standard RL step"
      },
      {
        "_from": "sections/sec_0af4c861",
        "_to": "entities/ent_d48a5cda",
        "context": "PTfor learnability. Then, a standard RL step"
      },
      {
        "_from": "sections/sec_0af4c861",
        "_to": "entities/ent_d48a5cda",
        "context": "PTfor learnability. Then, a standard RL step"
      },
      {
        "_from": "sections/sec_1a5d9820",
        "_to": "entities/ent_d48a5cda",
        "context": "reference examples. Then we executesp\u2062(i)\ud835\udc5d\ud835\udc56p"
      },
      {
        "_from": "sections/sec_0d24aa19",
        "_to": "entities/ent_d48a5cda",
        "context": "reference examples. Then we executesp\u2062(i)\ud835\udc5d\ud835\udc56p"
      },
      {
        "_from": "sections/sec_f9e77f68",
        "_to": "entities/ent_265b922d",
        "context": "T ( \u22c5 \u2223 italic_x ). Each proposed task\u03c4\ud835\udf0f\\tau"
      },
      {
        "_from": "sections/sec_0af4c861",
        "_to": "entities/ent_265b922d",
        "context": "T ( \u22c5 \u2223 italic_x ). Each proposed task\u03c4\ud835\udf0f\\tau"
      },
      {
        "_from": "sections/sec_1a5d9820",
        "_to": "entities/ent_265b922d",
        "context": "he simplest program.Each reasoning task type"
      },
      {
        "_from": "sections/sec_1a5d9820",
        "_to": "entities/ent_265b922d",
        "context": "he simplest program.Each reasoning task type"
      },
      {
        "_from": "sections/sec_0d24aa19",
        "_to": "entities/ent_265b922d",
        "context": "e simplest program. Each reasoning task type"
      },
      {
        "_from": "sections/sec_3d319639",
        "_to": "entities/ent_265b922d",
        "context": "ase language model. Each prompt samples up t"
      },
      {
        "_from": "sections/sec_4af9d86a",
        "_to": "entities/ent_265b922d",
        "context": "ase language model. Each prompt samples up t"
      },
      {
        "_from": "sections/sec_f9e77f68",
        "_to": "entities/ent_b27dae22",
        "context": "k queryx\ud835\udc65xitalic_x. Moreover, the same policy al"
      },
      {
        "_from": "sections/sec_f9e77f68",
        "_to": "entities/ent_b27dae22",
        "context": "k queryx\ud835\udc65xitalic_x. Moreover, the same policy al"
      },
      {
        "_from": "sections/sec_0af4c861",
        "_to": "entities/ent_b27dae22",
        "context": "k queryx\ud835\udc65xitalic_x. Moreover, the same policy al"
      },
      {
        "_from": "sections/sec_0af4c861",
        "_to": "entities/ent_b27dae22",
        "context": "k queryx\ud835\udc65xitalic_x. Moreover, the same policy al"
      },
      {
        "_from": "sections/sec_1a5d9820",
        "_to": "entities/ent_b27dae22",
        "context": "s shown inFigure33. Moreover, for the proposer, "
      },
      {
        "_from": "sections/sec_6d8d3b93",
        "_to": "entities/ent_b27dae22",
        "context": "s shown inFigure33. Moreover, for the proposer, "
      },
      {
        "_from": "sections/sec_2f0cfe08",
        "_to": "entities/ent_b27dae22",
        "context": "s shown inFigure33. Moreover, for the proposer, "
      },
      {
        "_from": "sections/sec_95e6043e",
        "_to": "entities/ent_b27dae22",
        "context": "irely through RLVR. Moreover, our goal is not to"
      },
      {
        "_from": "sections/sec_95e6043e",
        "_to": "entities/ent_b27dae22",
        "context": "irely through RLVR. Moreover, our goal is not to"
      },
      {
        "_from": "sections/sec_485ba230",
        "_to": "entities/ent_b27dae22",
        "context": "irely through RLVR. Moreover, our goal is not to"
      },
      {
        "_from": "sections/sec_247e121e",
        "_to": "entities/ent_b27dae22",
        "context": " in the game of Go. Moreover, methods such as as"
      },
      {
        "_from": "sections/sec_f9e77f68",
        "_to": "entities/ent_b98186a9",
        "context": "b{E}_{z\\sim p(%\nz)}\\Bigg{[}\\;\\mathbb{E}_{{\\c"
      },
      {
        "_from": "sections/sec_f9e77f68",
        "_to": "entities/ent_b98186a9",
        "context": "b{E}_{z\\sim p(%\nz)}\\Bigg{[}\\;\\mathbb{E}_{{\\c"
      },
      {
        "_from": "sections/sec_0af4c861",
        "_to": "entities/ent_b98186a9",
        "context": "b{E}_{z\\sim p(%\nz)}\\Bigg{[}\\;\\mathbb{E}_{{\\c"
      },
      {
        "_from": "sections/sec_0af4c861",
        "_to": "entities/ent_b98186a9",
        "context": "b{E}_{z\\sim p(%\nz)}\\Bigg{[}\\;\\mathbb{E}_{{\\c"
      },
      {
        "_from": "sections/sec_f9e77f68",
        "_to": "entities/ent_24efa7ee",
        "context": "RSCRIPT ) ] ] ] .(3)Notice that we shift the b"
      },
      {
        "_from": "sections/sec_0af4c861",
        "_to": "entities/ent_24efa7ee",
        "context": "SCRIPT ) ] ] ] .(3) Notice that we shift the b"
      },
      {
        "_from": "sections/sec_f9e77f68",
        "_to": "entities/ent_8a923c72",
        "context": "eneration of tasks. Practically,z\ud835\udc67zitalic_zcan be i"
      },
      {
        "_from": "sections/sec_0af4c861",
        "_to": "entities/ent_8a923c72",
        "context": "eneration of tasks. Practically,z\ud835\udc67zitalic_zcan be i"
      },
      {
        "_from": "sections/sec_f9e77f68",
        "_to": "entities/ent_95d83e98",
        "context": "the model\u2019s output. Together, these two signals "
      },
      {
        "_from": "sections/sec_0af4c861",
        "_to": "entities/ent_95d83e98",
        "context": "the model\u2019s output. Together, these two signals "
      },
      {
        "_from": "sections/sec_157180aa",
        "_to": "entities/ent_ab4d6983",
        "context": "Supervised Fine-Tuning (SFT).SFT re"
      },
      {
        "_from": "sections/sec_1a5d9820",
        "_to": "entities/ent_90cb35ef",
        "context": "empt to embrace the Absolute Zero Paradigm. In AZR, an unified"
      },
      {
        "_from": "sections/sec_1a5d9820",
        "_to": "entities/ent_90cb35ef",
        "context": "empt to embrace the Absolute Zero Paradigm. In AZR, an unified"
      },
      {
        "_from": "sections/sec_0d24aa19",
        "_to": "entities/ent_90cb35ef",
        "context": ", aligning with the Absolute Zero Paradigm\u2019s goals of fully se"
      },
      {
        "_from": "sections/sec_1a5d9820",
        "_to": "entities/ent_37bac6dc",
        "context": "ively\u00a0(Section3.1). Within this self-play trai"
      },
      {
        "_from": "sections/sec_1a5d9820",
        "_to": "entities/ent_3f05d6f3",
        "context": "ction\u00a0(Section3.2). Using coding tasks is mot"
      },
      {
        "_from": "sections/sec_95e6043e",
        "_to": "entities/ent_3f05d6f3",
        "context": "Reasoning with RL.Using RL to enhance reaso"
      },
      {
        "_from": "sections/sec_485ba230",
        "_to": "entities/ent_3f05d6f3",
        "context": "Using RL to enhance reaso"
      },
      {
        "_from": "sections/sec_1a5d9820",
        "_to": "entities/ent_bbe51039",
        "context": "is motivated by the Turing-completeness of pro"
      },
      {
        "_from": "sections/sec_1a5d9820",
        "_to": "entities/ent_892098dc",
        "context": "ogramming languages(Stuart,2015)and empirical "
      },
      {
        "_from": "sections/sec_1a5d9820",
        "_to": "entities/ent_892098dc",
        "context": "ogramming languages(Stuart,2015)and empirical "
      },
      {
        "_from": "sections/sec_0d24aa19",
        "_to": "entities/ent_892098dc",
        "context": "ode reasoning tasks(Stuart,2015;Aryabumi et\u00a0al"
      },
      {
        "_from": "sections/sec_1a5d9820",
        "_to": "entities/ent_a1982ba4",
        "context": " improves reasoning(Aryabumi et\u00a0al.,2024). We ad"
      },
      {
        "_from": "sections/sec_1a5d9820",
        "_to": "entities/ent_a1982ba4",
        "context": " improves reasoning(Aryabumi et\u00a0al.,2024). We ad"
      },
      {
        "_from": "sections/sec_0d24aa19",
        "_to": "entities/ent_a1982ba4",
        "context": "g tasks(Stuart,2015;Aryabumi et\u00a0al.,2024). Give "
      },
      {
        "_from": "sections/sec_1a5d9820",
        "_to": "entities/ent_5f12a065",
        "context": "ation\u00a0(Section3.3). Finally, the model is updat"
      },
      {
        "_from": "sections/sec_1a5d9820",
        "_to": "entities/ent_5f12a065",
        "context": "ation\u00a0(Section3.3). Finally, the model is updat"
      },
      {
        "_from": "sections/sec_6d8d3b93",
        "_to": "entities/ent_5f12a065",
        "context": "cribed inEquation5. Finally, the Absolute Zero "
      },
      {
        "_from": "sections/sec_2f0cfe08",
        "_to": "entities/ent_5f12a065",
        "context": "cribed inEquation5. Finally, the Absolute Zero "
      },
      {
        "_from": "sections/sec_5c55d4bc",
        "_to": "entities/ent_5f12a065",
        "context": "t parameter scales. Finally, we compare ourLlam"
      },
      {
        "_from": "sections/sec_5c55d4bc",
        "_to": "entities/ent_5f12a065",
        "context": "t parameter scales. Finally, we compare ourLlam"
      },
      {
        "_from": "sections/sec_5c55d4bc",
        "_to": "entities/ent_5f12a065",
        "context": "t parameter scales. Finally, we compare ourLlam"
      },
      {
        "_from": "sections/sec_5c55d4bc",
        "_to": "entities/ent_5f12a065",
        "context": "t parameter scales. Finally, we compare ourLlam"
      },
      {
        "_from": "sections/sec_6ba6439f",
        "_to": "entities/ent_5f12a065",
        "context": "t parameter scales. Finally, we compare ourLlam"
      },
      {
        "_from": "sections/sec_f6a941fe",
        "_to": "entities/ent_5f12a065",
        "context": "t parameter scales. Finally, we compare ourLlam"
      },
      {
        "_from": "sections/sec_56cabe86",
        "_to": "entities/ent_5f12a065",
        "context": "epends on Task Type.Finally, we observed that t"
      },
      {
        "_from": "sections/sec_56cabe86",
        "_to": "entities/ent_5f12a065",
        "context": "epends on Task Type.Finally, we observed that t"
      },
      {
        "_from": "sections/sec_56cabe86",
        "_to": "entities/ent_5f12a065",
        "context": "epends on Task Type.Finally, we observed that t"
      },
      {
        "_from": "sections/sec_72c37985",
        "_to": "entities/ent_5f12a065",
        "context": "epends on Task Type.Finally, we observed that t"
      },
      {
        "_from": "sections/sec_bb5ac41e",
        "_to": "entities/ent_5f12a065",
        "context": "ning problem space. Finally, we consider a case"
      },
      {
        "_from": "sections/sec_985245d2",
        "_to": "entities/ent_5f12a065",
        "context": "e model inFigure14. Finally, we invite interest"
      },
      {
        "_from": "sections/sec_95e6043e",
        "_to": "entities/ent_5f12a065",
        "context": " task distribution. Finally, Minimo(Poesia et\u00a0a"
      },
      {
        "_from": "sections/sec_247e121e",
        "_to": "entities/ent_5f12a065",
        "context": " task distribution. Finally, Minimo(Poesia et\u00a0a"
      },
      {
        "_from": "sections/sec_1a5d9820",
        "_to": "entities/ent_456ab015",
        "context": " section, we presentAbsolute Zero Reasoner(AZR) as the first a"
      },
      {
        "_from": "sections/sec_1a5d9820",
        "_to": "entities/ent_456ab015",
        "context": " section, we presentAbsolute Zero Reasoner(AZR) as the first a"
      },
      {
        "_from": "sections/sec_1a5d9820",
        "_to": "entities/ent_456ab015",
        "context": " section, we presentAbsolute Zero Reasoner(AZR) as the first a"
      },
      {
        "_from": "sections/sec_1a5d9820",
        "_to": "entities/ent_456ab015",
        "context": " section, we presentAbsolute Zero Reasoner(AZR) as the first a"
      },
      {
        "_from": "sections/sec_6d8d3b93",
        "_to": "entities/ent_456ab015",
        "context": " end_ROW(4)Figure 4:Absolute Zero Reasoner Training Overview.A"
      },
      {
        "_from": "sections/sec_6d8d3b93",
        "_to": "entities/ent_456ab015",
        "context": " end_ROW(4)Figure 4:Absolute Zero Reasoner Training Overview.A"
      },
      {
        "_from": "sections/sec_2f0cfe08",
        "_to": "entities/ent_456ab015",
        "context": "end_ROW(4) Figure 4:Absolute Zero Reasoner Training Overview.A"
      },
      {
        "_from": "sections/sec_2f0cfe08",
        "_to": "entities/ent_456ab015",
        "context": "end_ROW(4) Figure 4:Absolute Zero Reasoner Training Overview.A"
      },
      {
        "_from": "sections/sec_3d319639",
        "_to": "entities/ent_456ab015",
        "context": "lf-Play Training of Absolute Zero Reasoner (AZR)1:Pretrained b"
      },
      {
        "_from": "sections/sec_1020a1e3",
        "_to": "entities/ent_456ab015",
        "context": "lf-Play Training of Absolute Zero Reasoner (AZR)1:Pretrained b"
      },
      {
        "_from": "sections/sec_5c55d4bc",
        "_to": "entities/ent_456ab015",
        "context": "-Coder, resulting inAbsolute Zero Reasoner-base-7BandAbsolute "
      },
      {
        "_from": "sections/sec_5c55d4bc",
        "_to": "entities/ent_456ab015",
        "context": "-Coder, resulting inAbsolute Zero Reasoner-base-7BandAbsolute "
      },
      {
        "_from": "sections/sec_5c55d4bc",
        "_to": "entities/ent_456ab015",
        "context": "-Coder, resulting inAbsolute Zero Reasoner-base-7BandAbsolute "
      },
      {
        "_from": "sections/sec_56cabe86",
        "_to": "entities/ent_456ab015",
        "context": "s inTable1. Notably,Absolute Zero Reasoner-Coder-7Bachieves st"
      },
      {
        "_from": "sections/sec_56cabe86",
        "_to": "entities/ent_456ab015",
        "context": "s inTable1. Notably,Absolute Zero Reasoner-Coder-7Bachieves st"
      },
      {
        "_from": "sections/sec_56cabe86",
        "_to": "entities/ent_456ab015",
        "context": "s inTable1. Notably,Absolute Zero Reasoner-Coder-7Bachieves st"
      },
      {
        "_from": "sections/sec_773a923f",
        "_to": "entities/ent_456ab015",
        "context": "s inTable1. Notably,Absolute Zero Reasoner-Coder-7Bachieves st"
      },
      {
        "_from": "sections/sec_b69f3870",
        "_to": "entities/ent_456ab015",
        "context": "bilities within the Absolute Zero Reasoner approach."
      },
      {
        "_from": "sections/sec_94b98c7f",
        "_to": "entities/ent_456ab015",
        "context": " the next using onlyAbsolute Zero Reasoner-Base-7B. We begin b"
      },
      {
        "_from": "sections/sec_ab2bd446",
        "_to": "entities/ent_456ab015",
        "context": " instantiation, the Absolute Zero Reasoner (AZR), which is tra"
      },
      {
        "_from": "sections/sec_97b161c9",
        "_to": "entities/ent_456ab015",
        "context": " instantiation, the Absolute Zero Reasoner (AZR), which is tra"
      },
      {
        "_from": "sections/sec_1a5d9820",
        "_to": "entities/ent_a5cd3ed1",
        "context": "inAppendixD. 3.1Two Roles in One: Proposer an"
      },
      {
        "_from": "sections/sec_1a5d9820",
        "_to": "entities/ent_e77d2db6",
        "context": ".1Two Roles in One: Proposer and SolverLarge lan"
      },
      {
        "_from": "sections/sec_1a5d9820",
        "_to": "entities/ent_79777c39",
        "context": "sk learning context(Radford et\u00a0al.,2019), as bo"
      },
      {
        "_from": "sections/sec_6d8d3b93",
        "_to": "entities/ent_79777c39",
        "context": "sk learning context(Radford et\u00a0al.,2019), as bo"
      },
      {
        "_from": "sections/sec_1a5d9820",
        "_to": "entities/ent_130c5b34",
        "context": "ts model responses. Both task proposal and p"
      },
      {
        "_from": "sections/sec_6d8d3b93",
        "_to": "entities/ent_130c5b34",
        "context": "ts model responses. Both task proposal and p"
      },
      {
        "_from": "sections/sec_1a5d9820",
        "_to": "entities/ent_8e4661a2",
        "context": " used for each role.Reward Design.Prior work has show"
      },
      {
        "_from": "sections/sec_6d8d3b93",
        "_to": "entities/ent_8e4661a2",
        "context": "used for each role. Reward Design.Prior work has show"
      },
      {
        "_from": "sections/sec_1a5d9820",
        "_to": "entities/ent_e3d5e887",
        "context": " role.Reward Design.Prior work has shown that"
      },
      {
        "_from": "sections/sec_6d8d3b93",
        "_to": "entities/ent_e3d5e887",
        "context": "role. Reward Design.Prior work has shown that"
      },
      {
        "_from": "sections/sec_2f0cfe08",
        "_to": "entities/ent_e3d5e887",
        "context": "Prior work has shown that"
      },
      {
        "_from": "sections/sec_1a5d9820",
        "_to": "entities/ent_244a92ec",
        "context": "n reasoning systems(Zeng et\u00a0al.,2025b). Moti"
      },
      {
        "_from": "sections/sec_6d8d3b93",
        "_to": "entities/ent_244a92ec",
        "context": "n reasoning systems(Zeng et\u00a0al.,2025b). Moti"
      },
      {
        "_from": "sections/sec_2f0cfe08",
        "_to": "entities/ent_244a92ec",
        "context": "n reasoning systems(Zeng et\u00a0al.,2025b). Moti"
      },
      {
        "_from": "sections/sec_5c55d4bc",
        "_to": "entities/ent_244a92ec",
        "context": "ants of theAceCoder(Zeng et\u00a0al.,2025a)and tw"
      },
      {
        "_from": "sections/sec_5c55d4bc",
        "_to": "entities/ent_244a92ec",
        "context": "ants of theAceCoder(Zeng et\u00a0al.,2025a)and tw"
      },
      {
        "_from": "sections/sec_5c55d4bc",
        "_to": "entities/ent_244a92ec",
        "context": "ants of theAceCoder(Zeng et\u00a0al.,2025a)and tw"
      },
      {
        "_from": "sections/sec_5c55d4bc",
        "_to": "entities/ent_244a92ec",
        "context": "ants of theAceCoder(Zeng et\u00a0al.,2025a)and tw"
      },
      {
        "_from": "sections/sec_6ba6439f",
        "_to": "entities/ent_244a92ec",
        "context": "ants of theAceCoder(Zeng et\u00a0al.,2025a)and tw"
      },
      {
        "_from": "sections/sec_6ba6439f",
        "_to": "entities/ent_244a92ec",
        "context": "ants of theAceCoder(Zeng et\u00a0al.,2025a)and tw"
      },
      {
        "_from": "sections/sec_6ba6439f",
        "_to": "entities/ent_244a92ec",
        "context": "ants of theAceCoder(Zeng et\u00a0al.,2025a)and tw"
      },
      {
        "_from": "sections/sec_f6a941fe",
        "_to": "entities/ent_244a92ec",
        "context": "ants of theAceCoder(Zeng et\u00a0al.,2025a)and tw"
      },
      {
        "_from": "sections/sec_f6a941fe",
        "_to": "entities/ent_244a92ec",
        "context": "ants of theAceCoder(Zeng et\u00a0al.,2025a)and tw"
      },
      {
        "_from": "sections/sec_f6a941fe",
        "_to": "entities/ent_244a92ec",
        "context": "ants of theAceCoder(Zeng et\u00a0al.,2025a)and tw"
      },
      {
        "_from": "sections/sec_56cabe86",
        "_to": "entities/ent_244a92ec",
        "context": "g baseline,SimpleRL(Zeng et\u00a0al.,2025b), whic"
      },
      {
        "_from": "sections/sec_04cca2bb",
        "_to": "entities/ent_244a92ec",
        "context": "g baseline,SimpleRL(Zeng et\u00a0al.,2025b), whic"
      },
      {
        "_from": "sections/sec_95e6043e",
        "_to": "entities/ent_244a92ec",
        "context": " learning algorithm(Zeng et\u00a0al.,2025b;Liu et"
      },
      {
        "_from": "sections/sec_485ba230",
        "_to": "entities/ent_244a92ec",
        "context": " learning algorithm(Zeng et\u00a0al.,2025b;Liu et"
      },
      {
        "_from": "sections/sec_1a5d9820",
        "_to": "entities/ent_827b1b3d",
        "context": "Zeng et\u00a0al.,2025b). Motivated by this, we design "
      },
      {
        "_from": "sections/sec_6d8d3b93",
        "_to": "entities/ent_827b1b3d",
        "context": "Zeng et\u00a0al.,2025b). Motivated by this, we design "
      },
      {
        "_from": "sections/sec_2f0cfe08",
        "_to": "entities/ent_827b1b3d",
        "context": "Zeng et\u00a0al.,2025b). Motivated by this, we design "
      },
      {
        "_from": "sections/sec_1a5d9820",
        "_to": "entities/ent_fb778167",
        "context": "the current solver. Concretely, we use the same la"
      },
      {
        "_from": "sections/sec_6d8d3b93",
        "_to": "entities/ent_fb778167",
        "context": "the current solver. Concretely, we use the same la"
      },
      {
        "_from": "sections/sec_2f0cfe08",
        "_to": "entities/ent_fb778167",
        "context": "the current solver. Concretely, we use the same la"
      },
      {
        "_from": "sections/sec_1a5d9820",
        "_to": "entities/ent_40deab2d",
        "context": "t design literature(Sukhbaatar et\u00a0al.,2018). We pe"
      },
      {
        "_from": "sections/sec_6d8d3b93",
        "_to": "entities/ent_40deab2d",
        "context": "t design literature(Sukhbaatar et\u00a0al.,2018). We pe"
      },
      {
        "_from": "sections/sec_2f0cfe08",
        "_to": "entities/ent_40deab2d",
        "context": "t design literature(Sukhbaatar et\u00a0al.,2018). We pe"
      },
      {
        "_from": "sections/sec_95e6043e",
        "_to": "entities/ent_40deab2d",
        "context": "symmetric self-play(Sukhbaatar et\u00a0al.,2018;OpenAI "
      },
      {
        "_from": "sections/sec_247e121e",
        "_to": "entities/ent_40deab2d",
        "context": "symmetric self-play(Sukhbaatar et\u00a0al.,2018;OpenAI "
      },
      {
        "_from": "sections/sec_1a5d9820",
        "_to": "entities/ent_2a5a93ca",
        "context": "ormn\ud835\udc5bnitalic_nMonte Carlo rollouts of the sol"
      },
      {
        "_from": "sections/sec_6d8d3b93",
        "_to": "entities/ent_2a5a93ca",
        "context": "ormn\ud835\udc5bnitalic_nMonte Carlo rollouts of the sol"
      },
      {
        "_from": "sections/sec_2f0cfe08",
        "_to": "entities/ent_2a5a93ca",
        "context": "ormn\ud835\udc5bnitalic_nMonte Carlo rollouts of the sol"
      },
      {
        "_from": "sections/sec_1a5d9820",
        "_to": "entities/ent_34e6e3d1",
        "context": " end_ROW(4)Figure 4:Absolute Zero Reasoner Training Overview.At every iteration,"
      },
      {
        "_from": "sections/sec_6d8d3b93",
        "_to": "entities/ent_34e6e3d1",
        "context": " end_ROW(4)Figure 4:Absolute Zero Reasoner Training Overview.At every iteration,"
      },
      {
        "_from": "sections/sec_2f0cfe08",
        "_to": "entities/ent_34e6e3d1",
        "context": "end_ROW(4) Figure 4:Absolute Zero Reasoner Training Overview.At every iteration,"
      },
      {
        "_from": "sections/sec_1a5d9820",
        "_to": "entities/ent_5da618e8",
        "context": "ction\u00a0(Section3.2). From these generated tas"
      },
      {
        "_from": "sections/sec_6d8d3b93",
        "_to": "entities/ent_5da618e8",
        "context": "ction\u00a0(Section3.2). From these generated tas"
      },
      {
        "_from": "sections/sec_2f0cfe08",
        "_to": "entities/ent_5da618e8",
        "context": "ction\u00a0(Section3.2). From these generated tas"
      },
      {
        "_from": "sections/sec_1a5d9820",
        "_to": "entities/ent_a7f5f354",
        "context": "se generated tasks, Python is used to filter a"
      },
      {
        "_from": "sections/sec_1a5d9820",
        "_to": "entities/ent_a7f5f354",
        "context": "se generated tasks, Python is used to filter a"
      },
      {
        "_from": "sections/sec_1a5d9820",
        "_to": "entities/ent_a7f5f354",
        "context": "se generated tasks, Python is used to filter a"
      },
      {
        "_from": "sections/sec_1a5d9820",
        "_to": "entities/ent_a7f5f354",
        "context": "se generated tasks, Python is used to filter a"
      },
      {
        "_from": "sections/sec_1a5d9820",
        "_to": "entities/ent_a7f5f354",
        "context": "se generated tasks, Python is used to filter a"
      },
      {
        "_from": "sections/sec_6d8d3b93",
        "_to": "entities/ent_a7f5f354",
        "context": "se generated tasks, Python is used to filter a"
      },
      {
        "_from": "sections/sec_6d8d3b93",
        "_to": "entities/ent_a7f5f354",
        "context": "se generated tasks, Python is used to filter a"
      },
      {
        "_from": "sections/sec_6d8d3b93",
        "_to": "entities/ent_a7f5f354",
        "context": "se generated tasks, Python is used to filter a"
      },
      {
        "_from": "sections/sec_2f0cfe08",
        "_to": "entities/ent_a7f5f354",
        "context": "se generated tasks, Python is used to filter a"
      },
      {
        "_from": "sections/sec_2f0cfe08",
        "_to": "entities/ent_a7f5f354",
        "context": "se generated tasks, Python is used to filter a"
      },
      {
        "_from": "sections/sec_2f0cfe08",
        "_to": "entities/ent_a7f5f354",
        "context": "se generated tasks, Python is used to filter a"
      },
      {
        "_from": "sections/sec_3d319639",
        "_to": "entities/ent_a7f5f354",
        "context": "egrity.We first use Python to run the programp"
      },
      {
        "_from": "sections/sec_3d319639",
        "_to": "entities/ent_a7f5f354",
        "context": "egrity.We first use Python to run the programp"
      },
      {
        "_from": "sections/sec_ff7baeac",
        "_to": "entities/ent_a7f5f354",
        "context": "egrity.We first use Python to run the programp"
      },
      {
        "_from": "sections/sec_ff7baeac",
        "_to": "entities/ent_a7f5f354",
        "context": "egrity.We first use Python to run the programp"
      },
      {
        "_from": "sections/sec_95e6043e",
        "_to": "entities/ent_a7f5f354",
        "context": " problem space as a Python input/output/functi"
      },
      {
        "_from": "sections/sec_247e121e",
        "_to": "entities/ent_a7f5f354",
        "context": " problem space as a Python input/output/functi"
      },
      {
        "_from": "sections/sec_1a5d9820",
        "_to": "entities/ent_e60f3fbe",
        "context": "efined inEquation4. The Absolute Zero Reasoner thenSOLVESthe batch"
      },
      {
        "_from": "sections/sec_6d8d3b93",
        "_to": "entities/ent_e60f3fbe",
        "context": "efined inEquation4. The Absolute Zero Reasoner thenSOLVESthe batch"
      },
      {
        "_from": "sections/sec_2f0cfe08",
        "_to": "entities/ent_e60f3fbe",
        "context": "efined inEquation4. The Absolute Zero Reasoner thenSOLVESthe batch"
      },
      {
        "_from": "sections/sec_1a5d9820",
        "_to": "entities/ent_370964ee",
        "context": "ively\u00a0(Section3.1). Within this self-play tr"
      },
      {
        "_from": "sections/sec_6d8d3b93",
        "_to": "entities/ent_370964ee",
        "context": " equality in Python.With the primary rewards"
      },
      {
        "_from": "sections/sec_2f0cfe08",
        "_to": "entities/ent_370964ee",
        "context": "equality in Python. With the primary rewards"
      },
      {
        "_from": "sections/sec_1a5d9820",
        "_to": "entities/ent_76bdbc44",
        "context": "matted. 3.2Learning Different Modes of Reasoning: Deduc"
      },
      {
        "_from": "sections/sec_1a5d9820",
        "_to": "entities/ent_87a22257",
        "context": " Different Modes of Reasoning: Deduction, Inducti"
      },
      {
        "_from": "sections/sec_95e6043e",
        "_to": "entities/ent_87a22257",
        "context": "Reasoning with RL.Using RL to"
      },
      {
        "_from": "sections/sec_1a5d9820",
        "_to": "entities/ent_bf05fbc5",
        "context": "Modes of Reasoning: Deduction, Induction, and Abd"
      },
      {
        "_from": "sections/sec_1a5d9820",
        "_to": "entities/ent_bf05fbc5",
        "context": "Modes of Reasoning: Deduction, Induction, and Abd"
      },
      {
        "_from": "sections/sec_0d24aa19",
        "_to": "entities/ent_bf05fbc5",
        "context": "given the others: 1.Deduction: predicting the out"
      },
      {
        "_from": "sections/sec_5c55d4bc",
        "_to": "entities/ent_bf05fbc5",
        "context": "ath Avg.Overall Avg.Deduction onlyDed//54.632.043"
      },
      {
        "_from": "sections/sec_56cabe86",
        "_to": "entities/ent_bf05fbc5",
        "context": "ath Avg.Overall Avg.Deduction onlyDed//54.632.043"
      },
      {
        "_from": "sections/sec_94b98c7f",
        "_to": "entities/ent_bf05fbc5",
        "context": "ath Avg.Overall Avg.Deduction onlyDed//54.632.043"
      },
      {
        "_from": "sections/sec_1a5d9820",
        "_to": "entities/ent_5f76baee",
        "context": "asoning: Deduction, Induction, and AbductionAZR u"
      },
      {
        "_from": "sections/sec_1a5d9820",
        "_to": "entities/ent_5f76baee",
        "context": "asoning: Deduction, Induction, and AbductionAZR u"
      },
      {
        "_from": "sections/sec_0d24aa19",
        "_to": "entities/ent_5f76baee",
        "context": "act input matches.3.Induction:synthesizing a prog"
      },
      {
        "_from": "sections/sec_1a5d9820",
        "_to": "entities/ent_2f355d9f",
        "context": "abumi et\u00a0al.,2024). Give program space\ud835\udcab\ud835\udcab\\mat"
      },
      {
        "_from": "sections/sec_0d24aa19",
        "_to": "entities/ent_2f355d9f",
        "context": "abumi et\u00a0al.,2024). Give program space\ud835\udcab\ud835\udcab\\mat"
      },
      {
        "_from": "sections/sec_1a5d9820",
        "_to": "entities/ent_aaa405a4",
        "context": "ion, Induction, and AbductionAZR uses code execut"
      },
      {
        "_from": "sections/sec_0d24aa19",
        "_to": "entities/ent_aaa405a4",
        "context": "ing or fractions).2.Abduction: inferring a plausi"
      },
      {
        "_from": "sections/sec_1a5d9820",
        "_to": "entities/ent_38c50b73",
        "context": "CRIPT ) = italic_o. Since programs may not be"
      },
      {
        "_from": "sections/sec_1a5d9820",
        "_to": "entities/ent_38c50b73",
        "context": "CRIPT ) = italic_o. Since programs may not be"
      },
      {
        "_from": "sections/sec_1a5d9820",
        "_to": "entities/ent_38c50b73",
        "context": "CRIPT ) = italic_o. Since programs may not be"
      },
      {
        "_from": "sections/sec_1a5d9820",
        "_to": "entities/ent_38c50b73",
        "context": "CRIPT ) = italic_o. Since programs may not be"
      },
      {
        "_from": "sections/sec_0d24aa19",
        "_to": "entities/ent_38c50b73",
        "context": "CRIPT ) = italic_o. Since programs may not be"
      },
      {
        "_from": "sections/sec_0d24aa19",
        "_to": "entities/ent_38c50b73",
        "context": "CRIPT ) = italic_o. Since programs may not be"
      },
      {
        "_from": "sections/sec_3d319639",
        "_to": "entities/ent_38c50b73",
        "context": "c end_POSTSUBSCRIPT.Since the output of proba"
      },
      {
        "_from": "sections/sec_3d319639",
        "_to": "entities/ent_38c50b73",
        "context": "c end_POSTSUBSCRIPT.Since the output of proba"
      },
      {
        "_from": "sections/sec_ff7baeac",
        "_to": "entities/ent_38c50b73",
        "context": "c end_POSTSUBSCRIPT.Since the output of proba"
      },
      {
        "_from": "sections/sec_730b34d8",
        "_to": "entities/ent_38c50b73",
        "context": "Since AZR trains the comb"
      },
      {
        "_from": "sections/sec_1a5d9820",
        "_to": "entities/ent_4bd71603",
        "context": " induction.Figure 5:The Seed AZR Zero Triplet.Th"
      },
      {
        "_from": "sections/sec_0d24aa19",
        "_to": "entities/ent_4bd71603",
        "context": "induction. Figure 5:The Seed AZR Zero Triplet.Th"
      },
      {
        "_from": "sections/sec_1a5d9820",
        "_to": "entities/ent_9be306c4",
        "context": "gure 5:The Seed AZR Zero Triplet.The above identity "
      },
      {
        "_from": "sections/sec_0d24aa19",
        "_to": "entities/ent_9be306c4",
        "context": "gure 5:The Seed AZR Zero Triplet.The above identity "
      },
      {
        "_from": "sections/sec_1a5d9820",
        "_to": "entities/ent_10ac3d04",
        "context": "6,34,35,39,37and38. Next, we outline exact d"
      },
      {
        "_from": "sections/sec_0d24aa19",
        "_to": "entities/ent_10ac3d04",
        "context": "6,34,35,39,37and38. Next, we outline exact d"
      },
      {
        "_from": "sections/sec_5c55d4bc",
        "_to": "entities/ent_10ac3d04",
        "context": "formance (Ablation)?Next, we ablate two comp"
      },
      {
        "_from": "sections/sec_56cabe86",
        "_to": "entities/ent_10ac3d04",
        "context": "formance (Ablation)?Next, we ablate two comp"
      },
      {
        "_from": "sections/sec_bb5ac41e",
        "_to": "entities/ent_10ac3d04",
        "context": "Next, we ablate two comp"
      },
      {
        "_from": "sections/sec_1a5d9820",
        "_to": "entities/ent_04333d3a",
        "context": "orithm. 3.3Absolute Zero Reasoner Learning AlgorithmIn this se"
      },
      {
        "_from": "sections/sec_1a5d9820",
        "_to": "entities/ent_6bff1838",
        "context": "let show inFigure5. During the seeding stage, "
      },
      {
        "_from": "sections/sec_3d319639",
        "_to": "entities/ent_6bff1838",
        "context": "let show inFigure5. During the seeding stage, "
      },
      {
        "_from": "sections/sec_4af9d86a",
        "_to": "entities/ent_6bff1838",
        "context": "let show inFigure5. During the seeding stage, "
      },
      {
        "_from": "sections/sec_1020a1e3",
        "_to": "entities/ent_6bff1838",
        "context": "During the actual self-pla"
      },
      {
        "_from": "sections/sec_1a5d9820",
        "_to": "entities/ent_7fb55ed0",
        "context": "inFigures34,35and36.First, for deduction and "
      },
      {
        "_from": "sections/sec_1a5d9820",
        "_to": "entities/ent_7fb55ed0",
        "context": "inFigures34,35and36.First, for deduction and "
      },
      {
        "_from": "sections/sec_3d319639",
        "_to": "entities/ent_7fb55ed0",
        "context": "inFigures34,35and36.First, for deduction and "
      },
      {
        "_from": "sections/sec_3d319639",
        "_to": "entities/ent_7fb55ed0",
        "context": "inFigures34,35and36.First, for deduction and "
      },
      {
        "_from": "sections/sec_4af9d86a",
        "_to": "entities/ent_7fb55ed0",
        "context": "nFigures34,35and36. First, for deduction and "
      },
      {
        "_from": "sections/sec_1020a1e3",
        "_to": "entities/ent_7fb55ed0",
        "context": "uffer in three ways.First, for the proposer o"
      },
      {
        "_from": "sections/sec_5c55d4bc",
        "_to": "entities/ent_7fb55ed0",
        "context": "e results inTable2. First, we examine whether"
      },
      {
        "_from": "sections/sec_56cabe86",
        "_to": "entities/ent_7fb55ed0",
        "context": "e results inTable2. First, we examine whether"
      },
      {
        "_from": "sections/sec_bb5ac41e",
        "_to": "entities/ent_7fb55ed0",
        "context": "e results inTable2. First, we examine whether"
      },
      {
        "_from": "sections/sec_1a5d9820",
        "_to": "entities/ent_e31d55ba",
        "context": " during this phase. Similarly, to initialize the "
      },
      {
        "_from": "sections/sec_1a5d9820",
        "_to": "entities/ent_e31d55ba",
        "context": " during this phase. Similarly, to initialize the "
      },
      {
        "_from": "sections/sec_3d319639",
        "_to": "entities/ent_e31d55ba",
        "context": " during this phase. Similarly, to initialize the "
      },
      {
        "_from": "sections/sec_3d319639",
        "_to": "entities/ent_e31d55ba",
        "context": " during this phase. Similarly, to initialize the "
      },
      {
        "_from": "sections/sec_4af9d86a",
        "_to": "entities/ent_e31d55ba",
        "context": " during this phase. Similarly, to initialize the "
      },
      {
        "_from": "sections/sec_1020a1e3",
        "_to": "entities/ent_e31d55ba",
        "context": "ts any task reward. Similarly, for induction task"
      },
      {
        "_from": "sections/sec_5c55d4bc",
        "_to": "entities/ent_e31d55ba",
        "context": "oning improvements. Similarly, although also out-"
      },
      {
        "_from": "sections/sec_56cabe86",
        "_to": "entities/ent_e31d55ba",
        "context": "oning improvements. Similarly, although also out-"
      },
      {
        "_from": "sections/sec_773a923f",
        "_to": "entities/ent_e31d55ba",
        "context": "oning improvements. Similarly, although also out-"
      },
      {
        "_from": "sections/sec_1a5d9820",
        "_to": "entities/ent_57d70f17",
        "context": " italic_S.3.3.2Task Proposal Inputs and Buffer Manageme"
      },
      {
        "_from": "sections/sec_3d319639",
        "_to": "entities/ent_57d70f17",
        "context": "italic_S. 3.3.2Task Proposal Inputs and Buffer Manageme"
      },
      {
        "_from": "sections/sec_1a5d9820",
        "_to": "entities/ent_7e62bc34",
        "context": "R inAlgorithm1.3.3.1Buffer InitializationTo in"
      },
      {
        "_from": "sections/sec_3d319639",
        "_to": "entities/ent_7e62bc34",
        "context": " inAlgorithm1. 3.3.1Buffer InitializationTo in"
      },
      {
        "_from": "sections/sec_1a5d9820",
        "_to": "entities/ent_c7d42e3d",
        "context": "o promote diversity(Zhao et\u00a0al.,2025a).Secon"
      },
      {
        "_from": "sections/sec_1a5d9820",
        "_to": "entities/ent_c7d42e3d",
        "context": "o promote diversity(Zhao et\u00a0al.,2025a).Secon"
      },
      {
        "_from": "sections/sec_3d319639",
        "_to": "entities/ent_c7d42e3d",
        "context": "o promote diversity(Zhao et\u00a0al.,2025a).Secon"
      },
      {
        "_from": "sections/sec_3d319639",
        "_to": "entities/ent_c7d42e3d",
        "context": "o promote diversity(Zhao et\u00a0al.,2025a).Secon"
      },
      {
        "_from": "sections/sec_1020a1e3",
        "_to": "entities/ent_c7d42e3d",
        "context": "o promote diversity(Zhao et\u00a0al.,2025a).Secon"
      },
      {
        "_from": "sections/sec_730b34d8",
        "_to": "entities/ent_c7d42e3d",
        "context": "p(Zhang & Yang,2021;Zhao et\u00a0al.,2022;Wang et"
      },
      {
        "_from": "sections/sec_95e6043e",
        "_to": "entities/ent_c7d42e3d",
        "context": "(Laskin et\u00a0al.,2021;Zhao et\u00a0al.,2022;2025b),"
      },
      {
        "_from": "sections/sec_247e121e",
        "_to": "entities/ent_c7d42e3d",
        "context": "(Laskin et\u00a0al.,2021;Zhao et\u00a0al.,2022;2025b),"
      },
      {
        "_from": "sections/sec_1a5d9820",
        "_to": "entities/ent_c22cf837",
        "context": "(Zhao et\u00a0al.,2025a).Second, we sample one trip"
      },
      {
        "_from": "sections/sec_3d319639",
        "_to": "entities/ent_c22cf837",
        "context": "(Zhao et\u00a0al.,2025a).Second, we sample one trip"
      },
      {
        "_from": "sections/sec_1020a1e3",
        "_to": "entities/ent_c22cf837",
        "context": "(Zhao et\u00a0al.,2025a).Second, we sample one trip"
      },
      {
        "_from": "sections/sec_1a5d9820",
        "_to": "entities/ent_98fef2d5",
        "context": " messagem\ud835\udc5amitalic_m.Lastly, to maintain stable"
      },
      {
        "_from": "sections/sec_3d319639",
        "_to": "entities/ent_98fef2d5",
        "context": " messagem\ud835\udc5amitalic_m.Lastly, to maintain stable"
      },
      {
        "_from": "sections/sec_1020a1e3",
        "_to": "entities/ent_98fef2d5",
        "context": " messagem\ud835\udc5amitalic_m.Lastly, to maintain stable"
      },
      {
        "_from": "sections/sec_1a5d9820",
        "_to": "entities/ent_4afa80e7",
        "context": "overall algorithm inAlgorithm1and highlight an il"
      },
      {
        "_from": "sections/sec_3d319639",
        "_to": "entities/ent_4afa80e7",
        "context": " procedure of AZR inAlgorithm1. 3.3.1Buffer Initi"
      },
      {
        "_from": "sections/sec_1020a1e3",
        "_to": "entities/ent_4afa80e7",
        "context": "dded to the buffer. Algorithm 1Self-Play Training"
      },
      {
        "_from": "sections/sec_1a5d9820",
        "_to": "entities/ent_d994b6e9",
        "context": "fer.Algorithm 1Self-Play Training of Absolute Zero Re"
      },
      {
        "_from": "sections/sec_3d319639",
        "_to": "entities/ent_d994b6e9",
        "context": "fer.Algorithm 1Self-Play Training of Absolute Zero Re"
      },
      {
        "_from": "sections/sec_1020a1e3",
        "_to": "entities/ent_d994b6e9",
        "context": "er. Algorithm 1Self-Play Training of Absolute Zero Re"
      },
      {
        "_from": "sections/sec_1a5d9820",
        "_to": "entities/ent_8296e3db",
        "context": "ero Reasoner (AZR)1:Pretrained base LLM\u03c0\u03b8subscript"
      },
      {
        "_from": "sections/sec_3d319639",
        "_to": "entities/ent_8296e3db",
        "context": "ero Reasoner (AZR)1:Pretrained base LLM\u03c0\u03b8subscript"
      },
      {
        "_from": "sections/sec_1020a1e3",
        "_to": "entities/ent_8296e3db",
        "context": "ero Reasoner (AZR)1:Pretrained base LLM\u03c0\u03b8subscript"
      },
      {
        "_from": "sections/sec_1a5d9820",
        "_to": "entities/ent_35281ac0",
        "context": " used for each role.Reward Design.Prior work h"
      },
      {
        "_from": "sections/sec_3d319639",
        "_to": "entities/ent_35281ac0",
        "context": "RIPT ( italic_x )17:Reward:Use proposed task t"
      },
      {
        "_from": "sections/sec_1020a1e3",
        "_to": "entities/ent_35281ac0",
        "context": "RIPT ( italic_x )17:Reward:Use proposed task t"
      },
      {
        "_from": "sections/sec_1a5d9820",
        "_to": "entities/ent_e9be9e95",
        "context": "3.118:RL update:use Task Relative REINFORCE++ to upda"
      },
      {
        "_from": "sections/sec_3d319639",
        "_to": "entities/ent_e9be9e95",
        "context": "3.118:RL update:use Task Relative REINFORCE++ to upda"
      },
      {
        "_from": "sections/sec_1020a1e3",
        "_to": "entities/ent_e9be9e95",
        "context": "3.118:RL update:use Task Relative REINFORCE++ to upda"
      },
      {
        "_from": "sections/sec_1a5d9820",
        "_to": "entities/ent_3ac705f2",
        "context": "7:if{(i\u03c0n,o\u03c0n)}n=1N\u2190ValidateByExecuting\u2062(p,{i"
      },
      {
        "_from": "sections/sec_3d319639",
        "_to": "entities/ent_3ac705f2",
        "context": "7:if{(i\u03c0n,o\u03c0n)}n=1N\u2190ValidateByExecuting\u2062(p,{i"
      },
      {
        "_from": "sections/sec_1a5d9820",
        "_to": "entities/ent_ea2da2ac",
        "context": "Valid TasksProposal Task Validation.We first describe h"
      },
      {
        "_from": "sections/sec_3d319639",
        "_to": "entities/ent_ea2da2ac",
        "context": "Valid TasksProposal Task Validation.We first describe h"
      },
      {
        "_from": "sections/sec_1a5d9820",
        "_to": "entities/ent_9c674ba8",
        "context": "olicy\u03c0\ud835\udf0b\\piitalic_\u03c0. Fordeduction and abductiontasks,"
      },
      {
        "_from": "sections/sec_3d319639",
        "_to": "entities/ent_9c674ba8",
        "context": "olicy\u03c0\ud835\udf0b\\piitalic_\u03c0. Fordeduction and abductiontasks,"
      },
      {
        "_from": "sections/sec_ff7baeac",
        "_to": "entities/ent_9c674ba8",
        "context": "olicy\u03c0\ud835\udf0b\\piitalic_\u03c0. Fordeduction and abductiontasks,"
      },
      {
        "_from": "sections/sec_1a5d9820",
        "_to": "entities/ent_8cd58a62",
        "context": "lic_i , italic_o ). Forinductiontasks, given a programp\ud835\udc5dp"
      },
      {
        "_from": "sections/sec_3d319639",
        "_to": "entities/ent_8cd58a62",
        "context": "lic_i , italic_o ). Forinductiontasks, given a programp\ud835\udc5dp"
      },
      {
        "_from": "sections/sec_ff7baeac",
        "_to": "entities/ent_8cd58a62",
        "context": "lic_i , italic_o ). Forinductiontasks, given a programp\ud835\udc5dp"
      },
      {
        "_from": "sections/sec_1a5d9820",
        "_to": "entities/ent_c37ac867",
        "context": "ents are satisfied. Thetask validation procedur"
      },
      {
        "_from": "sections/sec_3d319639",
        "_to": "entities/ent_c37ac867",
        "context": "ents are satisfied. Thetask validation procedur"
      },
      {
        "_from": "sections/sec_ff7baeac",
        "_to": "entities/ent_c37ac867",
        "context": "ents are satisfied. Thetask validation procedur"
      },
      {
        "_from": "sections/sec_1a5d9820",
        "_to": "entities/ent_298afc25",
        "context": " procedureentails:1.Program Integrity.We first use Python"
      },
      {
        "_from": "sections/sec_3d319639",
        "_to": "entities/ent_298afc25",
        "context": " procedureentails:1.Program Integrity.We first use Python"
      },
      {
        "_from": "sections/sec_ff7baeac",
        "_to": "entities/ent_298afc25",
        "context": "procedureentails: 1.Program Integrity.We first use Python"
      },
      {
        "_from": "sections/sec_1a5d9820",
        "_to": "entities/ent_5d3a70a7",
        "context": " has valid syntax.2.Program Safety.We also check wheth"
      },
      {
        "_from": "sections/sec_3d319639",
        "_to": "entities/ent_5d3a70a7",
        "context": " has valid syntax.2.Program Safety.We also check wheth"
      },
      {
        "_from": "sections/sec_ff7baeac",
        "_to": "entities/ent_5d3a70a7",
        "context": " has valid syntax.2.Program Safety.We also check wheth"
      },
      {
        "_from": "sections/sec_1a5d9820",
        "_to": "entities/ent_060bf2d5",
        "context": "Figures34,35and36.3.Check for Determinism.In "
      },
      {
        "_from": "sections/sec_3d319639",
        "_to": "entities/ent_060bf2d5",
        "context": "Figures34,35and36.3.Check for Determinism.In "
      },
      {
        "_from": "sections/sec_ff7baeac",
        "_to": "entities/ent_060bf2d5",
        "context": "Figures34,35and36.3.Check for Determinism.In "
      },
      {
        "_from": "sections/sec_1a5d9820",
        "_to": "entities/ent_700de0d7",
        "context": "35and36.3.Check for Determinism.In our setting, we "
      },
      {
        "_from": "sections/sec_3d319639",
        "_to": "entities/ent_700de0d7",
        "context": "35and36.3.Check for Determinism.In our setting, we "
      },
      {
        "_from": "sections/sec_ff7baeac",
        "_to": "entities/ent_700de0d7",
        "context": "35and36.3.Check for Determinism.In our setting, we "
      },
      {
        "_from": "sections/sec_1a5d9820",
        "_to": "entities/ent_70dc9df8",
        "context": "ion of the program. Avalid program/input/outpu"
      },
      {
        "_from": "sections/sec_3d319639",
        "_to": "entities/ent_70dc9df8",
        "context": "ion of the program. Avalid program/input/outpu"
      },
      {
        "_from": "sections/sec_ff7baeac",
        "_to": "entities/ent_70dc9df8",
        "context": "ion of the program. Avalid program/input/outpu"
      },
      {
        "_from": "sections/sec_1a5d9820",
        "_to": "entities/ent_1f4771f8",
        "context": "tness of an answer. Therefore, to keep the verifi"
      },
      {
        "_from": "sections/sec_3d319639",
        "_to": "entities/ent_1f4771f8",
        "context": "tness of an answer. Therefore, to keep the verifi"
      },
      {
        "_from": "sections/sec_ff7baeac",
        "_to": "entities/ent_1f4771f8",
        "context": "tness of an answer. Therefore, to keep the verifi"
      },
      {
        "_from": "sections/sec_5c55d4bc",
        "_to": "entities/ent_1f4771f8",
        "context": "ance final answers. Therefore, it may be benefici"
      },
      {
        "_from": "sections/sec_56cabe86",
        "_to": "entities/ent_1f4771f8",
        "context": "ance final answers. Therefore, it may be benefici"
      },
      {
        "_from": "sections/sec_72c37985",
        "_to": "entities/ent_1f4771f8",
        "context": "ance final answers. Therefore, it may be benefici"
      },
      {
        "_from": "sections/sec_1a5d9820",
        "_to": "entities/ent_c05d7d4f",
        "context": "for all experiments.Solving Task Construction.If a task proposal "
      },
      {
        "_from": "sections/sec_3d319639",
        "_to": "entities/ent_c05d7d4f",
        "context": "for all experiments.Solving Task Construction.If a task proposal "
      },
      {
        "_from": "sections/sec_ff7baeac",
        "_to": "entities/ent_c05d7d4f",
        "context": "or all experiments. Solving Task Construction.If a task proposal "
      },
      {
        "_from": "sections/sec_1a5d9820",
        "_to": "entities/ent_29b5a122",
        "context": "plet to the solver. Specifically, we setx=(p,i)\ud835\udc65\ud835\udc5d\ud835\udc56x="
      },
      {
        "_from": "sections/sec_3d319639",
        "_to": "entities/ent_29b5a122",
        "context": "plet to the solver. Specifically, we setx=(p,i)\ud835\udc65\ud835\udc5d\ud835\udc56x="
      },
      {
        "_from": "sections/sec_ff7baeac",
        "_to": "entities/ent_29b5a122",
        "context": "plet to the solver. Specifically, we setx=(p,i)\ud835\udc65\ud835\udc5d\ud835\udc56x="
      },
      {
        "_from": "sections/sec_1a5d9820",
        "_to": "entities/ent_2ca94698",
        "context": ":RL update:use Task Relative REINFORCE++ to upda"
      },
      {
        "_from": "sections/sec_1a5d9820",
        "_to": "entities/ent_2ca94698",
        "context": ":RL update:use Task Relative REINFORCE++ to upda"
      },
      {
        "_from": "sections/sec_3d319639",
        "_to": "entities/ent_2ca94698",
        "context": ":RL update:use Task Relative REINFORCE++ to upda"
      },
      {
        "_from": "sections/sec_3d319639",
        "_to": "entities/ent_2ca94698",
        "context": ":RL update:use Task Relative REINFORCE++ to upda"
      },
      {
        "_from": "sections/sec_730b34d8",
        "_to": "entities/ent_2ca94698",
        "context": "this variant asTask-Relative REINFORCE++ (TRR++)"
      },
      {
        "_from": "sections/sec_1a5d9820",
        "_to": "entities/ent_2422f0f0",
        "context": "rning setup(Zhang & Yang,2021;Zhao et\u00a0al.,20"
      },
      {
        "_from": "sections/sec_3d319639",
        "_to": "entities/ent_2422f0f0",
        "context": "rning setup(Zhang & Yang,2021;Zhao et\u00a0al.,20"
      },
      {
        "_from": "sections/sec_730b34d8",
        "_to": "entities/ent_2422f0f0",
        "context": "rning setup(Zhang & Yang,2021;Zhao et\u00a0al.,20"
      },
      {
        "_from": "sections/sec_5c55d4bc",
        "_to": "entities/ent_2422f0f0",
        "context": ".5-14B,Llama-3.1-8B(Yang et\u00a0al.,2024a;Hui et"
      },
      {
        "_from": "sections/sec_5c55d4bc",
        "_to": "entities/ent_2422f0f0",
        "context": ".5-14B,Llama-3.1-8B(Yang et\u00a0al.,2024a;Hui et"
      },
      {
        "_from": "sections/sec_5c55d4bc",
        "_to": "entities/ent_2422f0f0",
        "context": ".5-14B,Llama-3.1-8B(Yang et\u00a0al.,2024a;Hui et"
      },
      {
        "_from": "sections/sec_6ba6439f",
        "_to": "entities/ent_2422f0f0",
        "context": ".5-14B,Llama-3.1-8B(Yang et\u00a0al.,2024a;Hui et"
      },
      {
        "_from": "sections/sec_6ba6439f",
        "_to": "entities/ent_2422f0f0",
        "context": ".5-14B,Llama-3.1-8B(Yang et\u00a0al.,2024a;Hui et"
      },
      {
        "_from": "sections/sec_6ba6439f",
        "_to": "entities/ent_2422f0f0",
        "context": ".5-14B,Llama-3.1-8B(Yang et\u00a0al.,2024a;Hui et"
      },
      {
        "_from": "sections/sec_ba8c62bf",
        "_to": "entities/ent_2422f0f0",
        "context": ".5-14B,Llama-3.1-8B(Yang et\u00a0al.,2024a;Hui et"
      },
      {
        "_from": "sections/sec_f6a941fe",
        "_to": "entities/ent_2422f0f0",
        "context": " andQwen2.5-Math-7B(Yang et\u00a0al.,2024a;Hui et"
      },
      {
        "_from": "sections/sec_f6a941fe",
        "_to": "entities/ent_2422f0f0",
        "context": " andQwen2.5-Math-7B(Yang et\u00a0al.,2024a;Hui et"
      },
      {
        "_from": "sections/sec_1a5d9820",
        "_to": "entities/ent_957b05eb",
        "context": "21;Zhao et\u00a0al.,2022;Wang et\u00a0al.,2023;Yue et\u00a0"
      },
      {
        "_from": "sections/sec_3d319639",
        "_to": "entities/ent_957b05eb",
        "context": "21;Zhao et\u00a0al.,2022;Wang et\u00a0al.,2023;Yue et\u00a0"
      },
      {
        "_from": "sections/sec_730b34d8",
        "_to": "entities/ent_957b05eb",
        "context": "21;Zhao et\u00a0al.,2022;Wang et\u00a0al.,2023;Yue et\u00a0"
      },
      {
        "_from": "sections/sec_95e6043e",
        "_to": "entities/ent_957b05eb",
        "context": "rmance of thousands(Wang et\u00a0al.,2025b). We e"
      },
      {
        "_from": "sections/sec_95e6043e",
        "_to": "entities/ent_957b05eb",
        "context": "rmance of thousands(Wang et\u00a0al.,2025b). We e"
      },
      {
        "_from": "sections/sec_485ba230",
        "_to": "entities/ent_957b05eb",
        "context": "rmance of thousands(Wang et\u00a0al.,2025b). We e"
      },
      {
        "_from": "sections/sec_247e121e",
        "_to": "entities/ent_957b05eb",
        "context": " environment design(Wang et\u00a0al.,2019;Dennis "
      },
      {
        "_from": "sections/sec_1a5d9820",
        "_to": "entities/ent_4c4a9cf4",
        "context": "3;Yue et\u00a0al.,2023). Instead of computing a sing"
      },
      {
        "_from": "sections/sec_3d319639",
        "_to": "entities/ent_4c4a9cf4",
        "context": "3;Yue et\u00a0al.,2023). Instead of computing a sing"
      },
      {
        "_from": "sections/sec_730b34d8",
        "_to": "entities/ent_4c4a9cf4",
        "context": "3;Yue et\u00a0al.,2023). Instead of computing a sing"
      },
      {
        "_from": "sections/sec_5c55d4bc",
        "_to": "entities/ent_4c4a9cf4",
        "context": "he proposer at all. Instead, we only prompt it "
      },
      {
        "_from": "sections/sec_56cabe86",
        "_to": "entities/ent_4c4a9cf4",
        "context": "he proposer at all. Instead, we only prompt it "
      },
      {
        "_from": "sections/sec_bb5ac41e",
        "_to": "entities/ent_4c4a9cf4",
        "context": "he proposer at all. Instead, we only prompt it "
      },
      {
        "_from": "sections/sec_1a5d9820",
        "_to": "entities/ent_c2860167",
        "context": "selines, as in GRPO(Shao et\u00a0al.,2024), and a"
      },
      {
        "_from": "sections/sec_3d319639",
        "_to": "entities/ent_c2860167",
        "context": "selines, as in GRPO(Shao et\u00a0al.,2024), and a"
      },
      {
        "_from": "sections/sec_730b34d8",
        "_to": "entities/ent_c2860167",
        "context": "selines, as in GRPO(Shao et\u00a0al.,2024), and a"
      },
      {
        "_from": "sections/sec_1a5d9820",
        "_to": "entities/ent_6513376e",
        "context": "CRIPTis computed as:Atask,rolenorm=r\u2212\u03bctask,ro"
      },
      {
        "_from": "sections/sec_3d319639",
        "_to": "entities/ent_6513376e",
        "context": "CRIPTis computed as:Atask,rolenorm=r\u2212\u03bctask,ro"
      },
      {
        "_from": "sections/sec_730b34d8",
        "_to": "entities/ent_6513376e",
        "context": "CRIPTis computed as:Atask,rolenorm=r\u2212\u03bctask,ro"
      },
      {
        "_from": "sections/sec_ff7baeac",
        "_to": "entities/ent_3caac635",
        "context": "Proposal Task Validation.We first describe h"
      },
      {
        "_from": "sections/sec_5c55d4bc",
        "_to": "entities/ent_3ec365dd",
        "context": "iment SetupTraining Details.For all experiments"
      },
      {
        "_from": "sections/sec_5c55d4bc",
        "_to": "entities/ent_bbb8cd10",
        "context": "the AdamW optimizer(Loshchilov & Hutter,2019). Com"
      },
      {
        "_from": "sections/sec_6ba6439f",
        "_to": "entities/ent_bbb8cd10",
        "context": "the AdamW optimizer(Loshchilov & Hutter,2019). Com"
      },
      {
        "_from": "sections/sec_ba8c62bf",
        "_to": "entities/ent_bbb8cd10",
        "context": "the AdamW optimizer(Loshchilov & Hutter,2019). Com"
      },
      {
        "_from": "sections/sec_5c55d4bc",
        "_to": "entities/ent_300ba426",
        "context": "imizer(Loshchilov & Hutter,2019). Complete lis"
      },
      {
        "_from": "sections/sec_6ba6439f",
        "_to": "entities/ent_300ba426",
        "context": "imizer(Loshchilov & Hutter,2019). Complete lis"
      },
      {
        "_from": "sections/sec_ba8c62bf",
        "_to": "entities/ent_300ba426",
        "context": "imizer(Loshchilov & Hutter,2019). Complete lis"
      },
      {
        "_from": "sections/sec_5c55d4bc",
        "_to": "entities/ent_ae94f80b",
        "context": "lov & Hutter,2019). Complete list of hyperparame"
      },
      {
        "_from": "sections/sec_6ba6439f",
        "_to": "entities/ent_ae94f80b",
        "context": "lov & Hutter,2019). Complete list of hyperparame"
      },
      {
        "_from": "sections/sec_ba8c62bf",
        "_to": "entities/ent_ae94f80b",
        "context": "lov & Hutter,2019). Complete list of hyperparame"
      },
      {
        "_from": "sections/sec_5c55d4bc",
        "_to": "entities/ent_27b948ac",
        "context": "r-7B, respectively. Additional experiments include"
      },
      {
        "_from": "sections/sec_6ba6439f",
        "_to": "entities/ent_27b948ac",
        "context": "r-7B, respectively. Additional experiments include"
      },
      {
        "_from": "sections/sec_ba8c62bf",
        "_to": "entities/ent_27b948ac",
        "context": "r-7B, respectively. Additional experiments include"
      },
      {
        "_from": "sections/sec_5c55d4bc",
        "_to": "entities/ent_9ef4f785",
        "context": "der-14B,Qwen2.5-14B,Llama-3.1-8B(Yang et\u00a0al.,"
      },
      {
        "_from": "sections/sec_5c55d4bc",
        "_to": "entities/ent_9ef4f785",
        "context": "der-14B,Qwen2.5-14B,Llama-3.1-8B(Yang et\u00a0al.,"
      },
      {
        "_from": "sections/sec_5c55d4bc",
        "_to": "entities/ent_9ef4f785",
        "context": "der-14B,Qwen2.5-14B,Llama-3.1-8B(Yang et\u00a0al.,"
      },
      {
        "_from": "sections/sec_6ba6439f",
        "_to": "entities/ent_9ef4f785",
        "context": "der-14B,Qwen2.5-14B,Llama-3.1-8B(Yang et\u00a0al.,"
      },
      {
        "_from": "sections/sec_ba8c62bf",
        "_to": "entities/ent_9ef4f785",
        "context": "der-14B,Qwen2.5-14B,Llama-3.1-8B(Yang et\u00a0al.,"
      },
      {
        "_from": "sections/sec_56cabe86",
        "_to": "entities/ent_9ef4f785",
        "context": "AvgMath AvgTotal AvgLlama3.1-8b28.53.416.0Lla"
      },
      {
        "_from": "sections/sec_56cabe86",
        "_to": "entities/ent_9ef4f785",
        "context": "AvgMath AvgTotal AvgLlama3.1-8b28.53.416.0Lla"
      },
      {
        "_from": "sections/sec_72c37985",
        "_to": "entities/ent_9ef4f785",
        "context": "gnitive Behavior in Llama.Interestingly, we a"
      },
      {
        "_from": "sections/sec_72c37985",
        "_to": "entities/ent_9ef4f785",
        "context": "gnitive Behavior in Llama.Interestingly, we a"
      },
      {
        "_from": "sections/sec_5c55d4bc",
        "_to": "entities/ent_52560fd5",
        "context": "24a;Hui et\u00a0al.,2024;Dubey et\u00a0al.,2024).Evalua"
      },
      {
        "_from": "sections/sec_6ba6439f",
        "_to": "entities/ent_52560fd5",
        "context": "24a;Hui et\u00a0al.,2024;Dubey et\u00a0al.,2024). Evalu"
      },
      {
        "_from": "sections/sec_ba8c62bf",
        "_to": "entities/ent_52560fd5",
        "context": "24a;Hui et\u00a0al.,2024;Dubey et\u00a0al.,2024)."
      },
      {
        "_from": "sections/sec_5c55d4bc",
        "_to": "entities/ent_aaefd6f8",
        "context": ";Dubey et\u00a0al.,2024).Evaluation Protocol.To evaluate our mod"
      },
      {
        "_from": "sections/sec_6ba6439f",
        "_to": "entities/ent_aaefd6f8",
        "context": "Dubey et\u00a0al.,2024). Evaluation Protocol.To evaluate our mod"
      },
      {
        "_from": "sections/sec_5c55d4bc",
        "_to": "entities/ent_03aa8029",
        "context": ", we evaluate using Evalplus(Liu et\u00a0al.,2023)on "
      },
      {
        "_from": "sections/sec_6ba6439f",
        "_to": "entities/ent_03aa8029",
        "context": ", we evaluate using Evalplus(Liu et\u00a0al.,2023)on "
      },
      {
        "_from": "sections/sec_4b5715ec",
        "_to": "entities/ent_03aa8029",
        "context": ", we evaluate using Evalplus(Liu et\u00a0al.,2023)on "
      },
      {
        "_from": "sections/sec_5c55d4bc",
        "_to": "entities/ent_e6a79fd8",
        "context": "ll as LiveCodeBench Generation (v1-5, May 23-Feb 2"
      },
      {
        "_from": "sections/sec_6ba6439f",
        "_to": "entities/ent_e6a79fd8",
        "context": "ll as LiveCodeBench Generation (v1-5, May 23-Feb 2"
      },
      {
        "_from": "sections/sec_4b5715ec",
        "_to": "entities/ent_e6a79fd8",
        "context": "ll as LiveCodeBench Generation (v1-5, May 23-Feb 2"
      },
      {
        "_from": "sections/sec_5c55d4bc",
        "_to": "entities/ent_3c5ba135",
        "context": "1-5, May 23-Feb 25)(Jain et\u00a0al.,2024). For m"
      },
      {
        "_from": "sections/sec_5c55d4bc",
        "_to": "entities/ent_3c5ba135",
        "context": "1-5, May 23-Feb 25)(Jain et\u00a0al.,2024). For m"
      },
      {
        "_from": "sections/sec_6ba6439f",
        "_to": "entities/ent_3c5ba135",
        "context": "1-5, May 23-Feb 25)(Jain et\u00a0al.,2024). For m"
      },
      {
        "_from": "sections/sec_6ba6439f",
        "_to": "entities/ent_3c5ba135",
        "context": "1-5, May 23-Feb 25)(Jain et\u00a0al.,2024). For m"
      },
      {
        "_from": "sections/sec_4b5715ec",
        "_to": "entities/ent_3c5ba135",
        "context": "1-5, May 23-Feb 25)(Jain et\u00a0al.,2024). For m"
      },
      {
        "_from": "sections/sec_4b5715ec",
        "_to": "entities/ent_3c5ba135",
        "context": "1-5, May 23-Feb 25)(Jain et\u00a0al.,2024). For m"
      },
      {
        "_from": "sections/sec_5c55d4bc",
        "_to": "entities/ent_931603f1",
        "context": "ch(He et\u00a0al.,2024), Minerva, Math500(Hendrycks "
      },
      {
        "_from": "sections/sec_5c55d4bc",
        "_to": "entities/ent_931603f1",
        "context": "ch(He et\u00a0al.,2024), Minerva, Math500(Hendrycks "
      },
      {
        "_from": "sections/sec_6ba6439f",
        "_to": "entities/ent_931603f1",
        "context": "ch(He et\u00a0al.,2024), Minerva, Math500(Hendrycks "
      },
      {
        "_from": "sections/sec_4b5715ec",
        "_to": "entities/ent_931603f1",
        "context": "ch(He et\u00a0al.,2024), Minerva, Math500(Hendrycks "
      },
      {
        "_from": "sections/sec_56cabe86",
        "_to": "entities/ent_931603f1",
        "context": "5, AMC\u201923, MATH500, Minerva, OlympiadBench). Av"
      },
      {
        "_from": "sections/sec_5c55d4bc",
        "_to": "entities/ent_8543783d",
        "context": "), Minerva, Math500(Hendrycks et\u00a0al.,2021), and A"
      },
      {
        "_from": "sections/sec_6ba6439f",
        "_to": "entities/ent_8543783d",
        "context": "), Minerva, Math500(Hendrycks et\u00a0al.,2021), and A"
      },
      {
        "_from": "sections/sec_4b5715ec",
        "_to": "entities/ent_8543783d",
        "context": "), Minerva, Math500(Hendrycks et\u00a0al.,2021), and A"
      },
      {
        "_from": "sections/sec_5c55d4bc",
        "_to": "entities/ent_8f44785c",
        "context": ", and LiveCodeBench-Execution(Gu et\u00a0al.,2024;Jain"
      },
      {
        "_from": "sections/sec_5c55d4bc",
        "_to": "entities/ent_8f44785c",
        "context": ", and LiveCodeBench-Execution(Gu et\u00a0al.,2024;Jain"
      },
      {
        "_from": "sections/sec_6ba6439f",
        "_to": "entities/ent_8f44785c",
        "context": ", and LiveCodeBench-Execution(Gu et\u00a0al.,2024;Jain"
      },
      {
        "_from": "sections/sec_4b5715ec",
        "_to": "entities/ent_8f44785c",
        "context": ", and LiveCodeBench-Execution(Gu et\u00a0al.,2024;Jain"
      },
      {
        "_from": "sections/sec_56cabe86",
        "_to": "entities/ent_8f44785c",
        "context": ", and LiveCodeBench-Execution, which correspond t"
      },
      {
        "_from": "sections/sec_9cc89151",
        "_to": "entities/ent_8f44785c",
        "context": ", and LiveCodeBench-Execution, which correspond t"
      },
      {
        "_from": "sections/sec_5c55d4bc",
        "_to": "entities/ent_bb6c5ecb",
        "context": "ams(Li et\u00a0al.,2025).Greedy decodingis used for"
      },
      {
        "_from": "sections/sec_6ba6439f",
        "_to": "entities/ent_bb6c5ecb",
        "context": "ams(Li et\u00a0al.,2025).Greedy decodingis used for"
      },
      {
        "_from": "sections/sec_4b5715ec",
        "_to": "entities/ent_bb6c5ecb",
        "context": "ams(Li et\u00a0al.,2025).Greedy decodingis used for"
      },
      {
        "_from": "sections/sec_5c55d4bc",
        "_to": "entities/ent_e6165364",
        "context": "ure reproducibility.Baselines.For our main result"
      },
      {
        "_from": "sections/sec_6ba6439f",
        "_to": "entities/ent_e6165364",
        "context": "re reproducibility. Baselines.For our main result"
      },
      {
        "_from": "sections/sec_5c55d4bc",
        "_to": "entities/ent_fbc39220",
        "context": "7B-Coder,Qwen2.5-7B-Instruct, andQwen2.5-Math-7B"
      },
      {
        "_from": "sections/sec_6ba6439f",
        "_to": "entities/ent_fbc39220",
        "context": "7B-Coder,Qwen2.5-7B-Instruct, andQwen2.5-Math-7B"
      },
      {
        "_from": "sections/sec_f6a941fe",
        "_to": "entities/ent_fbc39220",
        "context": "7B-Coder,Qwen2.5-7B-Instruct, andQwen2.5-Math-7B"
      },
      {
        "_from": "sections/sec_5c55d4bc",
        "_to": "entities/ent_a49950aa",
        "context": "al.,2024), Minerva, Math500(Hendrycks et\u00a0al."
      },
      {
        "_from": "sections/sec_5c55d4bc",
        "_to": "entities/ent_a49950aa",
        "context": "al.,2024), Minerva, Math500(Hendrycks et\u00a0al."
      },
      {
        "_from": "sections/sec_5c55d4bc",
        "_to": "entities/ent_a49950aa",
        "context": "al.,2024), Minerva, Math500(Hendrycks et\u00a0al."
      },
      {
        "_from": "sections/sec_6ba6439f",
        "_to": "entities/ent_a49950aa",
        "context": "al.,2024), Minerva, Math500(Hendrycks et\u00a0al."
      },
      {
        "_from": "sections/sec_6ba6439f",
        "_to": "entities/ent_a49950aa",
        "context": "al.,2024), Minerva, Math500(Hendrycks et\u00a0al."
      },
      {
        "_from": "sections/sec_f6a941fe",
        "_to": "entities/ent_a49950aa",
        "context": "nstruct, andQwen2.5-Math-7B(Yang et\u00a0al.,2024"
      },
      {
        "_from": "sections/sec_f6a941fe",
        "_to": "entities/ent_a49950aa",
        "context": "nstruct, andQwen2.5-Math-7B(Yang et\u00a0al.,2024"
      },
      {
        "_from": "sections/sec_56cabe86",
        "_to": "entities/ent_a49950aa",
        "context": "623.940.2Qwen2.5-7B-Math[74]--61.057.916.210"
      },
      {
        "_from": "sections/sec_5c55d4bc",
        "_to": "entities/ent_d7ed4ee1",
        "context": "esulting inAbsolute Zero Reasoner-base-7Band"
      },
      {
        "_from": "sections/sec_5c55d4bc",
        "_to": "entities/ent_d7ed4ee1",
        "context": "esulting inAbsolute Zero Reasoner-base-7Band"
      },
      {
        "_from": "sections/sec_5c55d4bc",
        "_to": "entities/ent_d7ed4ee1",
        "context": "esulting inAbsolute Zero Reasoner-base-7Band"
      },
      {
        "_from": "sections/sec_5c55d4bc",
        "_to": "entities/ent_d7ed4ee1",
        "context": "esulting inAbsolute Zero Reasoner-base-7Band"
      },
      {
        "_from": "sections/sec_5c55d4bc",
        "_to": "entities/ent_d7ed4ee1",
        "context": "esulting inAbsolute Zero Reasoner-base-7Band"
      },
      {
        "_from": "sections/sec_6ba6439f",
        "_to": "entities/ent_d7ed4ee1",
        "context": "esulting inAbsolute Zero Reasoner-base-7Band"
      },
      {
        "_from": "sections/sec_6ba6439f",
        "_to": "entities/ent_d7ed4ee1",
        "context": "esulting inAbsolute Zero Reasoner-base-7Band"
      },
      {
        "_from": "sections/sec_6ba6439f",
        "_to": "entities/ent_d7ed4ee1",
        "context": "esulting inAbsolute Zero Reasoner-base-7Band"
      },
      {
        "_from": "sections/sec_f6a941fe",
        "_to": "entities/ent_d7ed4ee1",
        "context": "nlyEurus-2-7B-PRIME-Zero(Cui et\u00a0al.,2025)was"
      },
      {
        "_from": "sections/sec_f6a941fe",
        "_to": "entities/ent_d7ed4ee1",
        "context": "nlyEurus-2-7B-PRIME-Zero(Cui et\u00a0al.,2025)was"
      },
      {
        "_from": "sections/sec_f6a941fe",
        "_to": "entities/ent_d7ed4ee1",
        "context": "nlyEurus-2-7B-PRIME-Zero(Cui et\u00a0al.,2025)was"
      },
      {
        "_from": "sections/sec_56cabe86",
        "_to": "entities/ent_d7ed4ee1",
        "context": "15.428.045.029.537.3Zero-Style Reasoners Tra"
      },
      {
        "_from": "sections/sec_56cabe86",
        "_to": "entities/ent_d7ed4ee1",
        "context": "15.428.045.029.537.3Zero-Style Reasoners Tra"
      },
      {
        "_from": "sections/sec_5c55d4bc",
        "_to": "entities/ent_c3bf447e",
        "context": "ro(Liu et\u00a0al.,2025),Open-Reasoner-Zero-7B(OR"
      },
      {
        "_from": "sections/sec_6ba6439f",
        "_to": "entities/ent_c3bf447e",
        "context": "ro(Liu et\u00a0al.,2025),Open-Reasoner-Zero-7B(OR"
      },
      {
        "_from": "sections/sec_f6a941fe",
        "_to": "entities/ent_c3bf447e",
        "context": "ro(Liu et\u00a0al.,2025),Open-Reasoner-Zero-7B(OR"
      },
      {
        "_from": "sections/sec_5c55d4bc",
        "_to": "entities/ent_fc64a2b6",
        "context": "ing inAbsolute Zero Reasoner-base-7BandAbsolute "
      },
      {
        "_from": "sections/sec_6ba6439f",
        "_to": "entities/ent_fc64a2b6",
        "context": "ing inAbsolute Zero Reasoner-base-7BandAbsolute "
      },
      {
        "_from": "sections/sec_f6a941fe",
        "_to": "entities/ent_fc64a2b6",
        "context": "u et\u00a0al.,2025),Open-Reasoner-Zero-7B(ORZ)(Hu et\u00a0"
      },
      {
        "_from": "sections/sec_5c55d4bc",
        "_to": "entities/ent_fb22fe09",
        "context": " train AZR models onQwen2.5-7BandQwen2.5-7B-"
      },
      {
        "_from": "sections/sec_6ba6439f",
        "_to": "entities/ent_fb22fe09",
        "context": " train AZR models onQwen2.5-7BandQwen2.5-7B-"
      },
      {
        "_from": "sections/sec_f6a941fe",
        "_to": "entities/ent_fb22fe09",
        "context": "main results, we useQwen2.5-7Bas the base mo"
      },
      {
        "_from": "sections/sec_5c55d4bc",
        "_to": "entities/ent_4c082ef7",
        "context": "8.045.029.537.3Zero-Style Reasoners Trained on Curated Coding D"
      },
      {
        "_from": "sections/sec_5c55d4bc",
        "_to": "entities/ent_4c082ef7",
        "context": "8.045.029.537.3Zero-Style Reasoners Trained on Curated Coding D"
      },
      {
        "_from": "sections/sec_56cabe86",
        "_to": "entities/ent_4c082ef7",
        "context": "8.045.029.537.3Zero-Style Reasoners Trained on Curated Coding D"
      },
      {
        "_from": "sections/sec_56cabe86",
        "_to": "entities/ent_4c082ef7",
        "context": "8.045.029.537.3Zero-Style Reasoners Trained on Curated Coding D"
      },
      {
        "_from": "sections/sec_5c55d4bc",
        "_to": "entities/ent_c283a720",
        "context": "easoners Trained on Curated Coding DataAceCoder-RM[84]"
      },
      {
        "_from": "sections/sec_56cabe86",
        "_to": "entities/ent_c283a720",
        "context": "easoners Trained on Curated Coding DataAceCoder-RM[84]"
      },
      {
        "_from": "sections/sec_5c55d4bc",
        "_to": "entities/ent_ab7a485e",
        "context": "8.337.447.9AceCoder-Rule[84]Ins22k77.469.019"
      },
      {
        "_from": "sections/sec_5c55d4bc",
        "_to": "entities/ent_ab7a485e",
        "context": "8.337.447.9AceCoder-Rule[84]Ins22k77.469.019"
      },
      {
        "_from": "sections/sec_56cabe86",
        "_to": "entities/ent_ab7a485e",
        "context": "8.337.447.9AceCoder-Rule[84]Ins22k77.469.019"
      },
      {
        "_from": "sections/sec_56cabe86",
        "_to": "entities/ent_ab7a485e",
        "context": "8.337.447.9AceCoder-Rule[84]Ins22k77.469.019"
      },
      {
        "_from": "sections/sec_5c55d4bc",
        "_to": "entities/ent_ed09eab4",
        "context": "easoners Trained on Curated Math DataPRIME-Zero[9]Co"
      },
      {
        "_from": "sections/sec_56cabe86",
        "_to": "entities/ent_ed09eab4",
        "context": "easoners Trained on Curated Math DataPRIME-Zero[9]Co"
      },
      {
        "_from": "sections/sec_5c55d4bc",
        "_to": "entities/ent_2d9a7bb6",
        "context": "5.641.648.6Absolute Zero Training w/ No Curated Data "
      },
      {
        "_from": "sections/sec_56cabe86",
        "_to": "entities/ent_2d9a7bb6",
        "context": "5.641.648.6Absolute Zero Training w/ No Curated Data "
      },
      {
        "_from": "sections/sec_5c55d4bc",
        "_to": "entities/ent_a2a36d51",
        "context": "te Zero Training w/ No Curated Data (Ours)AZR (Ours)Bas"
      },
      {
        "_from": "sections/sec_56cabe86",
        "_to": "entities/ent_a2a36d51",
        "context": "te Zero Training w/ No Curated Data (Ours)AZR (Ours)Bas"
      },
      {
        "_from": "sections/sec_5c55d4bc",
        "_to": "entities/ent_b7b4497a",
        "context": "w/ No Curated Data (Ours)AZR (Ours)Base071.3"
      },
      {
        "_from": "sections/sec_5c55d4bc",
        "_to": "entities/ent_b7b4497a",
        "context": "w/ No Curated Data (Ours)AZR (Ours)Base071.3"
      },
      {
        "_from": "sections/sec_5c55d4bc",
        "_to": "entities/ent_b7b4497a",
        "context": "w/ No Curated Data (Ours)AZR (Ours)Base071.3"
      },
      {
        "_from": "sections/sec_5c55d4bc",
        "_to": "entities/ent_b7b4497a",
        "context": "w/ No Curated Data (Ours)AZR (Ours)Base071.3"
      },
      {
        "_from": "sections/sec_5c55d4bc",
        "_to": "entities/ent_b7b4497a",
        "context": "w/ No Curated Data (Ours)AZR (Ours)Base071.3"
      },
      {
        "_from": "sections/sec_5c55d4bc",
        "_to": "entities/ent_b7b4497a",
        "context": "w/ No Curated Data (Ours)AZR (Ours)Base071.3"
      },
      {
        "_from": "sections/sec_5c55d4bc",
        "_to": "entities/ent_b7b4497a",
        "context": "w/ No Curated Data (Ours)AZR (Ours)Base071.3"
      },
      {
        "_from": "sections/sec_56cabe86",
        "_to": "entities/ent_b7b4497a",
        "context": "w/ No Curated Data (Ours)AZR (Ours)Base071.3"
      },
      {
        "_from": "sections/sec_56cabe86",
        "_to": "entities/ent_b7b4497a",
        "context": "w/ No Curated Data (Ours)AZR (Ours)Base071.3"
      },
      {
        "_from": "sections/sec_56cabe86",
        "_to": "entities/ent_b7b4497a",
        "context": "w/ No Curated Data (Ours)AZR (Ours)Base071.3"
      },
      {
        "_from": "sections/sec_56cabe86",
        "_to": "entities/ent_b7b4497a",
        "context": "w/ No Curated Data (Ours)AZR (Ours)Base071.3"
      },
      {
        "_from": "sections/sec_56cabe86",
        "_to": "entities/ent_b7b4497a",
        "context": "w/ No Curated Data (Ours)AZR (Ours)Base071.3"
      },
      {
        "_from": "sections/sec_56cabe86",
        "_to": "entities/ent_b7b4497a",
        "context": "w/ No Curated Data (Ours)AZR (Ours)Base071.3"
      },
      {
        "_from": "sections/sec_56cabe86",
        "_to": "entities/ent_b7b4497a",
        "context": "w/ No Curated Data (Ours)AZR (Ours)Base071.3"
      },
      {
        "_from": "sections/sec_9cc89151",
        "_to": "entities/ent_b7b4497a",
        "context": "RGLlama3.1-8b+ AZR (Ours)31.6+3.131.6\\mathrl"
      },
      {
        "_from": "sections/sec_9cc89151",
        "_to": "entities/ent_b7b4497a",
        "context": "RGLlama3.1-8b+ AZR (Ours)31.6+3.131.6\\mathrl"
      },
      {
        "_from": "sections/sec_9cc89151",
        "_to": "entities/ent_b7b4497a",
        "context": "RGLlama3.1-8b+ AZR (Ours)31.6+3.131.6\\mathrl"
      },
      {
        "_from": "sections/sec_9cc89151",
        "_to": "entities/ent_b7b4497a",
        "context": "RGLlama3.1-8b+ AZR (Ours)31.6+3.131.6\\mathrl"
      },
      {
        "_from": "sections/sec_5c55d4bc",
        "_to": "entities/ent_b2b928f0",
        "context": "1:Performance of RL-Trained Reasoner on Reasoning Benchm"
      },
      {
        "_from": "sections/sec_56cabe86",
        "_to": "entities/ent_b2b928f0",
        "context": "1:Performance of RL-Trained Reasoner on Reasoning Benchm"
      },
      {
        "_from": "sections/sec_5c55d4bc",
        "_to": "entities/ent_49291bd3",
        "context": "Trained Reasoner on Reasoning Benchmarks Based on Qwen2.5-7B Model"
      },
      {
        "_from": "sections/sec_56cabe86",
        "_to": "entities/ent_49291bd3",
        "context": "Trained Reasoner on Reasoning Benchmarks Based on Qwen2.5-7B Model"
      },
      {
        "_from": "sections/sec_5c55d4bc",
        "_to": "entities/ent_25ac429f",
        "context": "piadCAvgMAvgAVGBase ModelsQwen2.5-7B[73]--73.2"
      },
      {
        "_from": "sections/sec_56cabe86",
        "_to": "entities/ent_25ac429f",
        "context": "piadCAvgMAvgAVGBase ModelsQwen2.5-7B[73]--73.2"
      },
      {
        "_from": "sections/sec_5c55d4bc",
        "_to": "entities/ent_b1897515",
        "context": "va, OlympiadBench). Average performance across "
      },
      {
        "_from": "sections/sec_56cabe86",
        "_to": "entities/ent_b1897515",
        "context": "va, OlympiadBench). Average performance across "
      },
      {
        "_from": "sections/sec_5c55d4bc",
        "_to": "entities/ent_a97ea56b",
        "context": "ed inTable4Research Question 1: How does AZR com"
      },
      {
        "_from": "sections/sec_5c55d4bc",
        "_to": "entities/ent_31ad45a6",
        "context": " settings inTable1. Notably,Absolute Zero Reaso"
      },
      {
        "_from": "sections/sec_56cabe86",
        "_to": "entities/ent_31ad45a6",
        "context": " settings inTable1. Notably,Absolute Zero Reaso"
      },
      {
        "_from": "sections/sec_773a923f",
        "_to": "entities/ent_31ad45a6",
        "context": " settings inTable1. Notably,Absolute Zero Reaso"
      },
      {
        "_from": "sections/sec_5c55d4bc",
        "_to": "entities/ent_35537fbc",
        "context": "solute percentages. Even more strikingly, it"
      },
      {
        "_from": "sections/sec_56cabe86",
        "_to": "entities/ent_35537fbc",
        "context": "solute percentages. Even more strikingly, it"
      },
      {
        "_from": "sections/sec_773a923f",
        "_to": "entities/ent_35537fbc",
        "context": "solute percentages. Even more strikingly, it"
      },
      {
        "_from": "sections/sec_5c55d4bc",
        "_to": "entities/ent_9c0502f5",
        "context": "to such data itself.Strong Cross-domain Generalizati"
      },
      {
        "_from": "sections/sec_56cabe86",
        "_to": "entities/ent_9c0502f5",
        "context": "to such data itself.Strong Cross-domain Generalizati"
      },
      {
        "_from": "sections/sec_773a923f",
        "_to": "entities/ent_9c0502f5",
        "context": "o such data itself. Strong Cross-domain Generalizati"
      },
      {
        "_from": "sections/sec_5c55d4bc",
        "_to": "entities/ent_e60de48d",
        "context": "Strong Cross-domain Generalization.To assess cross-dom"
      },
      {
        "_from": "sections/sec_56cabe86",
        "_to": "entities/ent_e60de48d",
        "context": "Strong Cross-domain Generalization.To assess cross-dom"
      },
      {
        "_from": "sections/sec_773a923f",
        "_to": "entities/ent_e60de48d",
        "context": "Strong Cross-domain Generalization.To assess cross-dom"
      },
      {
        "_from": "sections/sec_5c55d4bc",
        "_to": "entities/ent_9c831ae0",
        "context": "g (+2.0 on average).Overall, these results high"
      },
      {
        "_from": "sections/sec_5c55d4bc",
        "_to": "entities/ent_9c831ae0",
        "context": "g (+2.0 on average).Overall, these results high"
      },
      {
        "_from": "sections/sec_5c55d4bc",
        "_to": "entities/ent_9c831ae0",
        "context": "g (+2.0 on average).Overall, these results high"
      },
      {
        "_from": "sections/sec_56cabe86",
        "_to": "entities/ent_9c831ae0",
        "context": "g (+2.0 on average).Overall, these results high"
      },
      {
        "_from": "sections/sec_56cabe86",
        "_to": "entities/ent_9c831ae0",
        "context": "g (+2.0 on average).Overall, these results high"
      },
      {
        "_from": "sections/sec_56cabe86",
        "_to": "entities/ent_9c831ae0",
        "context": "g (+2.0 on average).Overall, these results high"
      },
      {
        "_from": "sections/sec_773a923f",
        "_to": "entities/ent_9c831ae0",
        "context": " (+2.0 on average). Overall, these results high"
      },
      {
        "_from": "sections/sec_72c37985",
        "_to": "entities/ent_9c831ae0",
        "context": "gh trial-and-error. Overall, the models trained"
      },
      {
        "_from": "sections/sec_94b98c7f",
        "_to": "entities/ent_9c831ae0",
        "context": "esCode Avg.Math Avg.Overall Avg.Deduction onlyD"
      },
      {
        "_from": "sections/sec_5c55d4bc",
        "_to": "entities/ent_01456a90",
        "context": "ails listed inTable4Research Question 1: How does AZR com"
      },
      {
        "_from": "sections/sec_5c55d4bc",
        "_to": "entities/ent_01456a90",
        "context": "ails listed inTable4Research Question 1: How does AZR com"
      },
      {
        "_from": "sections/sec_5c55d4bc",
        "_to": "entities/ent_01456a90",
        "context": "ails listed inTable4Research Question 1: How does AZR com"
      },
      {
        "_from": "sections/sec_5c55d4bc",
        "_to": "entities/ent_01456a90",
        "context": "ails listed inTable4Research Question 1: How does AZR com"
      },
      {
        "_from": "sections/sec_5c55d4bc",
        "_to": "entities/ent_01456a90",
        "context": "ails listed inTable4Research Question 1: How does AZR com"
      },
      {
        "_from": "sections/sec_5c55d4bc",
        "_to": "entities/ent_01456a90",
        "context": "ails listed inTable4Research Question 1: How does AZR com"
      },
      {
        "_from": "sections/sec_56cabe86",
        "_to": "entities/ent_01456a90",
        "context": "ils listed inTable4 Research Question 1: How does AZR com"
      },
      {
        "_from": "sections/sec_56cabe86",
        "_to": "entities/ent_01456a90",
        "context": "ils listed inTable4 Research Question 1: How does AZR com"
      },
      {
        "_from": "sections/sec_56cabe86",
        "_to": "entities/ent_01456a90",
        "context": "ils listed inTable4 Research Question 1: How does AZR com"
      },
      {
        "_from": "sections/sec_56cabe86",
        "_to": "entities/ent_01456a90",
        "context": "ils listed inTable4 Research Question 1: How does AZR com"
      },
      {
        "_from": "sections/sec_56cabe86",
        "_to": "entities/ent_01456a90",
        "context": "ils listed inTable4 Research Question 1: How does AZR com"
      },
      {
        "_from": "sections/sec_56cabe86",
        "_to": "entities/ent_01456a90",
        "context": "ils listed inTable4 Research Question 1: How does AZR com"
      },
      {
        "_from": "sections/sec_56cabe86",
        "_to": "entities/ent_01456a90",
        "context": "ils listed inTable4 Research Question 1: How does AZR com"
      },
      {
        "_from": "sections/sec_5c55d4bc",
        "_to": "entities/ent_0762465d",
        "context": " self-play process. Strikingly, although the coder"
      },
      {
        "_from": "sections/sec_56cabe86",
        "_to": "entities/ent_0762465d",
        "context": " self-play process. Strikingly, although the coder"
      },
      {
        "_from": "sections/sec_b69f3870",
        "_to": "entities/ent_0762465d",
        "context": " self-play process. Strikingly, although the coder"
      },
      {
        "_from": "sections/sec_5c55d4bc",
        "_to": "entities/ent_0dfcf23e",
        "context": " (b), respectively. Given the strong performa"
      },
      {
        "_from": "sections/sec_56cabe86",
        "_to": "entities/ent_0dfcf23e",
        "context": " (b), respectively. Given the strong performa"
      },
      {
        "_from": "sections/sec_9cc89151",
        "_to": "entities/ent_0dfcf23e",
        "context": " (b), respectively. Given the strong performa"
      },
      {
        "_from": "sections/sec_5c55d4bc",
        "_to": "entities/ent_a559b870",
        "context": "se model. 4.2ResultsModelBase#dataHEval+MBPP+"
      },
      {
        "_from": "sections/sec_5c55d4bc",
        "_to": "entities/ent_a559b870",
        "context": "se model. 4.2ResultsModelBase#dataHEval+MBPP+"
      },
      {
        "_from": "sections/sec_56cabe86",
        "_to": "entities/ent_a559b870",
        "context": "ModelBase#dataHEval+MBPP+"
      },
      {
        "_from": "sections/sec_56cabe86",
        "_to": "entities/ent_a559b870",
        "context": "ModelBase#dataHEval+MBPP+"
      },
      {
        "_from": "sections/sec_9cc89151",
        "_to": "entities/ent_a559b870",
        "context": "e Zero paradigm. (a)Model FamilyVariantCode A"
      },
      {
        "_from": "sections/sec_04cca2bb",
        "_to": "entities/ent_a559b870",
        "context": "gure 7:Example of a Model-Proposed Task and I"
      },
      {
        "_from": "sections/sec_5c55d4bc",
        "_to": "entities/ent_f0bac093",
        "context": "G(b)Figure 6:(a) In-Distribution & (b) Out-of-Distri"
      },
      {
        "_from": "sections/sec_56cabe86",
        "_to": "entities/ent_f0bac093",
        "context": "G(b)Figure 6:(a) In-Distribution & (b) Out-of-Distri"
      },
      {
        "_from": "sections/sec_9cc89151",
        "_to": "entities/ent_f0bac093",
        "context": "G(b)Figure 6:(a) In-Distribution & (b) Out-of-Distri"
      },
      {
        "_from": "sections/sec_5c55d4bc",
        "_to": "entities/ent_92453493",
        "context": "bution & (b) Out-of-Distribution Reasoning Task Performances.(a)Scores on CruxEv"
      },
      {
        "_from": "sections/sec_56cabe86",
        "_to": "entities/ent_92453493",
        "context": "bution & (b) Out-of-Distribution Reasoning Task Performances.(a)Scores on CruxEv"
      },
      {
        "_from": "sections/sec_9cc89151",
        "_to": "entities/ent_92453493",
        "context": "bution & (b) Out-of-Distribution Reasoning Task Performances.(a)Scores on CruxEv"
      },
      {
        "_from": "sections/sec_5c55d4bc",
        "_to": "entities/ent_6660e1da",
        "context": "ask Performances.(a)Scores on CruxEval-I, Crux"
      },
      {
        "_from": "sections/sec_56cabe86",
        "_to": "entities/ent_6660e1da",
        "context": "ask Performances.(a)Scores on CruxEval-I, Crux"
      },
      {
        "_from": "sections/sec_9cc89151",
        "_to": "entities/ent_6660e1da",
        "context": "ask Performances.(a)Scores on CruxEval-I, Crux"
      },
      {
        "_from": "sections/sec_5c55d4bc",
        "_to": "entities/ent_0a527305",
        "context": "el potency.Figure 7:Example of a Model-Proposed"
      },
      {
        "_from": "sections/sec_56cabe86",
        "_to": "entities/ent_0a527305",
        "context": "el potency.Figure 7:Example of a Model-Proposed"
      },
      {
        "_from": "sections/sec_04cca2bb",
        "_to": "entities/ent_0a527305",
        "context": "l potency. Figure 7:Example of a Model-Proposed"
      },
      {
        "_from": "sections/sec_5c55d4bc",
        "_to": "entities/ent_1ed77a55",
        "context": ":Example of a Model-Proposed Task and Its Response fo"
      },
      {
        "_from": "sections/sec_56cabe86",
        "_to": "entities/ent_1ed77a55",
        "context": ":Example of a Model-Proposed Task and Its Response fo"
      },
      {
        "_from": "sections/sec_04cca2bb",
        "_to": "entities/ent_1ed77a55",
        "context": ":Example of a Model-Proposed Task and Its Response fo"
      },
      {
        "_from": "sections/sec_5c55d4bc",
        "_to": "entities/ent_44afea25",
        "context": "l-Proposed Task and Its Response for Solving an Abdu"
      },
      {
        "_from": "sections/sec_56cabe86",
        "_to": "entities/ent_44afea25",
        "context": "l-Proposed Task and Its Response for Solving an Abdu"
      },
      {
        "_from": "sections/sec_04cca2bb",
        "_to": "entities/ent_44afea25",
        "context": "l-Proposed Task and Its Response for Solving an Abdu"
      },
      {
        "_from": "sections/sec_5c55d4bc",
        "_to": "entities/ent_3b6e51cc",
        "context": "nd Its Response for Solving an Abduction Task.("
      },
      {
        "_from": "sections/sec_56cabe86",
        "_to": "entities/ent_3b6e51cc",
        "context": "nd Its Response for Solving an Abduction Task.("
      },
      {
        "_from": "sections/sec_04cca2bb",
        "_to": "entities/ent_3b6e51cc",
        "context": "nd Its Response for Solving an Abduction Task.("
      },
      {
        "_from": "sections/sec_5c55d4bc",
        "_to": "entities/ent_99616d94",
        "context": "onse for Solving an Abduction Task.(Left) The model au"
      },
      {
        "_from": "sections/sec_56cabe86",
        "_to": "entities/ent_99616d94",
        "context": "onse for Solving an Abduction Task.(Left) The model au"
      },
      {
        "_from": "sections/sec_04cca2bb",
        "_to": "entities/ent_99616d94",
        "context": "onse for Solving an Abduction Task.(Left) The model au"
      },
      {
        "_from": "sections/sec_5c55d4bc",
        "_to": "entities/ent_945d5e23",
        "context": " an Abduction Task.(Left) The model autonomo"
      },
      {
        "_from": "sections/sec_56cabe86",
        "_to": "entities/ent_945d5e23",
        "context": " an Abduction Task.(Left) The model autonomo"
      },
      {
        "_from": "sections/sec_04cca2bb",
        "_to": "entities/ent_945d5e23",
        "context": " an Abduction Task.(Left) The model autonomo"
      },
      {
        "_from": "sections/sec_5c55d4bc",
        "_to": "entities/ent_92b09c7c",
        "context": "responding output. (Right) The model\u2019s reason"
      },
      {
        "_from": "sections/sec_56cabe86",
        "_to": "entities/ent_92b09c7c",
        "context": "responding output. (Right) The model\u2019s reason"
      },
      {
        "_from": "sections/sec_04cca2bb",
        "_to": "entities/ent_92b09c7c",
        "context": "responding output. (Right) The model\u2019s reason"
      },
      {
        "_from": "sections/sec_5c55d4bc",
        "_to": "entities/ent_64cb339c",
        "context": "matches the target. Interestingly, the agent arrives "
      },
      {
        "_from": "sections/sec_5c55d4bc",
        "_to": "entities/ent_64cb339c",
        "context": "matches the target. Interestingly, the agent arrives "
      },
      {
        "_from": "sections/sec_5c55d4bc",
        "_to": "entities/ent_64cb339c",
        "context": "matches the target. Interestingly, the agent arrives "
      },
      {
        "_from": "sections/sec_56cabe86",
        "_to": "entities/ent_64cb339c",
        "context": "matches the target. Interestingly, the agent arrives "
      },
      {
        "_from": "sections/sec_56cabe86",
        "_to": "entities/ent_64cb339c",
        "context": "matches the target. Interestingly, the agent arrives "
      },
      {
        "_from": "sections/sec_56cabe86",
        "_to": "entities/ent_64cb339c",
        "context": "matches the target. Interestingly, the agent arrives "
      },
      {
        "_from": "sections/sec_04cca2bb",
        "_to": "entities/ent_64cb339c",
        "context": "matches the target. Interestingly, the agent arrives "
      },
      {
        "_from": "sections/sec_72c37985",
        "_to": "entities/ent_64cb339c",
        "context": "e Behavior in Llama.Interestingly, we also observed s"
      },
      {
        "_from": "sections/sec_72c37985",
        "_to": "entities/ent_64cb339c",
        "context": "e Behavior in Llama.Interestingly, we also observed s"
      },
      {
        "_from": "sections/sec_5c55d4bc",
        "_to": "entities/ent_2dde8f4a",
        "context": "iangle\u2019s area using Heron\u2019s formula). We show"
      },
      {
        "_from": "sections/sec_56cabe86",
        "_to": "entities/ent_2dde8f4a",
        "context": "iangle\u2019s area using Heron\u2019s formula). We show"
      },
      {
        "_from": "sections/sec_72c37985",
        "_to": "entities/ent_2dde8f4a",
        "context": "iangle\u2019s area using Heron\u2019s formula). We show"
      },
      {
        "_from": "sections/sec_5c55d4bc",
        "_to": "entities/ent_5dc13067",
        "context": "ks\u201d such as solving Sudoku and solving thesum-"
      },
      {
        "_from": "sections/sec_56cabe86",
        "_to": "entities/ent_5dc13067",
        "context": "ks\u201d such as solving Sudoku and solving thesum-"
      },
      {
        "_from": "sections/sec_72c37985",
        "_to": "entities/ent_5dc13067",
        "context": "ks\u201d such as solving Sudoku and solving thesum-"
      },
      {
        "_from": "sections/sec_5c55d4bc",
        "_to": "entities/ent_c62cf525",
        "context": "ameinFigures40and41.Intermediate Planning During Code Response.Another interesting"
      },
      {
        "_from": "sections/sec_56cabe86",
        "_to": "entities/ent_c62cf525",
        "context": "ameinFigures40and41.Intermediate Planning During Code Response.Another interesting"
      },
      {
        "_from": "sections/sec_72c37985",
        "_to": "entities/ent_c62cf525",
        "context": "meinFigures40and41. Intermediate Planning During Code Response.Another interesting"
      },
      {
        "_from": "sections/sec_5c55d4bc",
        "_to": "entities/ent_442c0184",
        "context": "uring Code Response.Another interesting pattern"
      },
      {
        "_from": "sections/sec_56cabe86",
        "_to": "entities/ent_442c0184",
        "context": "uring Code Response.Another interesting pattern"
      },
      {
        "_from": "sections/sec_72c37985",
        "_to": "entities/ent_442c0184",
        "context": "uring Code Response.Another interesting pattern"
      },
      {
        "_from": "sections/sec_5c55d4bc",
        "_to": "entities/ent_c1eef20b",
        "context": "cross other domains.Cognitive Behavior in Llama.Interestin"
      },
      {
        "_from": "sections/sec_56cabe86",
        "_to": "entities/ent_c1eef20b",
        "context": "cross other domains.Cognitive Behavior in Llama.Interestin"
      },
      {
        "_from": "sections/sec_72c37985",
        "_to": "entities/ent_c1eef20b",
        "context": "ross other domains. Cognitive Behavior in Llama.Interestin"
      },
      {
        "_from": "sections/sec_5c55d4bc",
        "_to": "entities/ent_d7379224",
        "context": "ential implications.Token Length Increase Depends on Task Type.Finall"
      },
      {
        "_from": "sections/sec_56cabe86",
        "_to": "entities/ent_d7379224",
        "context": "ential implications.Token Length Increase Depends on Task Type.Finall"
      },
      {
        "_from": "sections/sec_72c37985",
        "_to": "entities/ent_d7379224",
        "context": "ntial implications. Token Length Increase Depends on Task Type.Finall"
      },
      {
        "_from": "sections/sec_5c55d4bc",
        "_to": "entities/ent_9dd5fda3",
        "context": "Increase Depends on Task Type.Finally, we observe"
      },
      {
        "_from": "sections/sec_56cabe86",
        "_to": "entities/ent_9dd5fda3",
        "context": "Increase Depends on Task Type.Finally, we observe"
      },
      {
        "_from": "sections/sec_72c37985",
        "_to": "entities/ent_9dd5fda3",
        "context": "Increase Depends on Task Type.Finally, we observe"
      },
      {
        "_from": "sections/sec_5c55d4bc",
        "_to": "entities/ent_9002eb99",
        "context": "r good performance (Ablation)?Due to resource co"
      },
      {
        "_from": "sections/sec_5c55d4bc",
        "_to": "entities/ent_9002eb99",
        "context": "r good performance (Ablation)?Due to resource co"
      },
      {
        "_from": "sections/sec_56cabe86",
        "_to": "entities/ent_9002eb99",
        "context": "r good performance (Ablation)?Due to resource co"
      },
      {
        "_from": "sections/sec_56cabe86",
        "_to": "entities/ent_9002eb99",
        "context": "r good performance (Ablation)?Due to resource co"
      },
      {
        "_from": "sections/sec_5c55d4bc",
        "_to": "entities/ent_74369c56",
        "context": "amilyVariantCode AvgMath AvgTotal AvgLlama3.1-8b"
      },
      {
        "_from": "sections/sec_56cabe86",
        "_to": "entities/ent_74369c56",
        "context": "amilyVariantCode AvgMath AvgTotal AvgLlama3.1-8b"
      },
      {
        "_from": "sections/sec_94b98c7f",
        "_to": "entities/ent_74369c56",
        "context": "ained RolesCode Avg.Math Avg.Overall Avg.Deducti"
      },
      {
        "_from": "sections/sec_5c55d4bc",
        "_to": "entities/ent_e39c8281",
        "context": "esCode Avg.Math Avg.Overall Avg.Deduction onlyDed//"
      },
      {
        "_from": "sections/sec_56cabe86",
        "_to": "entities/ent_e39c8281",
        "context": "esCode Avg.Math Avg.Overall Avg.Deduction onlyDed//"
      },
      {
        "_from": "sections/sec_94b98c7f",
        "_to": "entities/ent_e39c8281",
        "context": "esCode Avg.Math Avg.Overall Avg.Deduction onlyDed//"
      },
      {
        "_from": "sections/sec_5c55d4bc",
        "_to": "entities/ent_72839bf5",
        "context": ".ExperimentTask TypeGen ReferenceTrained RolesCode Av"
      },
      {
        "_from": "sections/sec_56cabe86",
        "_to": "entities/ent_72839bf5",
        "context": ".ExperimentTask TypeGen ReferenceTrained RolesCode Av"
      },
      {
        "_from": "sections/sec_94b98c7f",
        "_to": "entities/ent_72839bf5",
        "context": " ExperimentTask TypeGen ReferenceTrained RolesCode Av"
      },
      {
        "_from": "sections/sec_5c55d4bc",
        "_to": "entities/ent_f6030637",
        "context": "0/54.433.143.8Train Solver Only//Solve Only54.836.0"
      },
      {
        "_from": "sections/sec_56cabe86",
        "_to": "entities/ent_f6030637",
        "context": "0/54.433.143.8Train Solver Only//Solve Only54.836.0"
      },
      {
        "_from": "sections/sec_94b98c7f",
        "_to": "entities/ent_f6030637",
        "context": "0/54.433.143.8Train Solver Only//Solve Only54.836.0"
      },
      {
        "_from": "sections/sec_5c55d4bc",
        "_to": "entities/ent_97817e09",
        "context": "0/54.433.143.8Train Solver Only//Solve Only54"
      },
      {
        "_from": "sections/sec_56cabe86",
        "_to": "entities/ent_97817e09",
        "context": "0/54.433.143.8Train Solver Only//Solve Only54"
      },
      {
        "_from": "sections/sec_94b98c7f",
        "_to": "entities/ent_97817e09",
        "context": "0/54.433.143.8Train Solver Only//Solve Only54"
      },
      {
        "_from": "sections/sec_5c55d4bc",
        "_to": "entities/ent_2ccaf84f",
        "context": "55.238.446.8Table 2:Ablation Results.We ablate task type"
      },
      {
        "_from": "sections/sec_56cabe86",
        "_to": "entities/ent_2ccaf84f",
        "context": "55.238.446.8Table 2:Ablation Results.We ablate task type"
      },
      {
        "_from": "sections/sec_94b98c7f",
        "_to": "entities/ent_2ccaf84f",
        "context": "55.238.446.8Table 2:Ablation Results.We ablate task type"
      },
      {
        "_from": "sections/sec_5c55d4bc",
        "_to": "entities/ent_e44b66d2",
        "context": "standard AZR setup. Removing induction or using "
      },
      {
        "_from": "sections/sec_56cabe86",
        "_to": "entities/ent_e44b66d2",
        "context": "standard AZR setup. Removing induction or using "
      },
      {
        "_from": "sections/sec_94b98c7f",
        "_to": "entities/ent_e44b66d2",
        "context": "standard AZR setup. Removing induction or using "
      },
      {
        "_from": "sections/sec_5c55d4bc",
        "_to": "entities/ent_115edd9d",
        "context": "learning literature(Suteu & Guo,2019). Thus, "
      },
      {
        "_from": "sections/sec_56cabe86",
        "_to": "entities/ent_115edd9d",
        "context": "learning literature(Suteu & Guo,2019). Thus, "
      },
      {
        "_from": "sections/sec_bb5ac41e",
        "_to": "entities/ent_115edd9d",
        "context": "learning literature(Suteu & Guo,2019). Thus, "
      },
      {
        "_from": "sections/sec_5c55d4bc",
        "_to": "entities/ent_fb55ffe3",
        "context": "(Suteu & Guo,2019). Thus, we believe that fu"
      },
      {
        "_from": "sections/sec_56cabe86",
        "_to": "entities/ent_fb55ffe3",
        "context": "(Suteu & Guo,2019). Thus, we believe that fu"
      },
      {
        "_from": "sections/sec_bb5ac41e",
        "_to": "entities/ent_fb55ffe3",
        "context": "(Suteu & Guo,2019). Thus, we believe that fu"
      },
      {
        "_from": "sections/sec_5c55d4bc",
        "_to": "entities/ent_a5a514e8",
        "context": "promising direction.Additional Results.Beyond the core res"
      },
      {
        "_from": "sections/sec_56cabe86",
        "_to": "entities/ent_a5a514e8",
        "context": "romising direction. Additional Results.Beyond the core res"
      },
      {
        "_from": "sections/sec_5c55d4bc",
        "_to": "entities/ent_4f991fd3",
        "context": ".Additional Results.Beyond the core research q"
      },
      {
        "_from": "sections/sec_56cabe86",
        "_to": "entities/ent_4f991fd3",
        "context": " Additional Results.Beyond the core research q"
      },
      {
        "_from": "sections/sec_985245d2",
        "_to": "entities/ent_4f991fd3",
        "context": "Beyond the core research q"
      },
      {
        "_from": "sections/sec_6ba6439f",
        "_to": "entities/ent_37391eed",
        "context": "Training Details.For all experiments"
      },
      {
        "_from": "sections/sec_95e6043e",
        "_to": "entities/ent_d3da97e2",
        "context": "he time of release. More recently, the R1 mo"
      },
      {
        "_from": "sections/sec_485ba230",
        "_to": "entities/ent_d3da97e2",
        "context": "he time of release. More recently, the R1 mo"
      },
      {
        "_from": "sections/sec_95e6043e",
        "_to": "entities/ent_08781b29",
        "context": " performance of o1. Most notably, the zero s"
      },
      {
        "_from": "sections/sec_95e6043e",
        "_to": "entities/ent_08781b29",
        "context": " performance of o1. Most notably, the zero s"
      },
      {
        "_from": "sections/sec_485ba230",
        "_to": "entities/ent_08781b29",
        "context": " performance of o1. Most notably, the zero s"
      },
      {
        "_from": "sections/sec_247e121e",
        "_to": "entities/ent_08781b29",
        "context": " the discriminator. Most recently, SPIN and "
      },
      {
        "_from": "sections/sec_95e6043e",
        "_to": "entities/ent_3d088ce7",
        "context": "2025;Yu et\u00a0al.,2025;Yuan et\u00a0al.,2025). Recen"
      },
      {
        "_from": "sections/sec_95e6043e",
        "_to": "entities/ent_3d088ce7",
        "context": "2025;Yu et\u00a0al.,2025;Yuan et\u00a0al.,2025). Recen"
      },
      {
        "_from": "sections/sec_485ba230",
        "_to": "entities/ent_3d088ce7",
        "context": "2025;Yu et\u00a0al.,2025;Yuan et\u00a0al.,2025). Recen"
      },
      {
        "_from": "sections/sec_247e121e",
        "_to": "entities/ent_3d088ce7",
        "context": "ls(Chen et\u00a0al.,2024;Yuan et\u00a0al.,2024)use the"
      },
      {
        "_from": "sections/sec_95e6043e",
        "_to": "entities/ent_dae52b80",
        "context": ";Yuan et\u00a0al.,2025). Recent work explored RL on"
      },
      {
        "_from": "sections/sec_485ba230",
        "_to": "entities/ent_dae52b80",
        "context": ";Yuan et\u00a0al.,2025). Recent work explored RL on"
      },
      {
        "_from": "sections/sec_95e6043e",
        "_to": "entities/ent_ad6e7652",
        "context": "em in the long run. Self-play.The self-play "
      },
      {
        "_from": "sections/sec_95e6043e",
        "_to": "entities/ent_ad6e7652",
        "context": "em in the long run. Self-play.The self-play "
      },
      {
        "_from": "sections/sec_247e121e",
        "_to": "entities/ent_ad6e7652",
        "context": " recently, SPIN and Self-Rewarding Language "
      },
      {
        "_from": "sections/sec_95e6043e",
        "_to": "entities/ent_3f8bcd1d",
        "context": "ver-ending progress(Schaul,2024). AlphaGo and "
      },
      {
        "_from": "sections/sec_247e121e",
        "_to": "entities/ent_3f8bcd1d",
        "context": "ver-ending progress(Schaul,2024). AlphaGo and "
      },
      {
        "_from": "sections/sec_95e6043e",
        "_to": "entities/ent_d0f7423e",
        "context": "gn(Wang et\u00a0al.,2019;Dennis et\u00a0al.,2020), unsup"
      },
      {
        "_from": "sections/sec_247e121e",
        "_to": "entities/ent_d0f7423e",
        "context": "gn(Wang et\u00a0al.,2019;Dennis et\u00a0al.,2020), unsup"
      },
      {
        "_from": "sections/sec_95e6043e",
        "_to": "entities/ent_39c0691f",
        "context": "nforcement learning(Laskin et\u00a0al.,2021;Zhao et"
      },
      {
        "_from": "sections/sec_247e121e",
        "_to": "entities/ent_39c0691f",
        "context": "nforcement learning(Laskin et\u00a0al.,2021;Zhao et"
      },
      {
        "_from": "sections/sec_95e6043e",
        "_to": "entities/ent_1098c710",
        "context": "tic goal generation(Florensa et\u00a0al.,2018)all cen"
      },
      {
        "_from": "sections/sec_247e121e",
        "_to": "entities/ent_1098c710",
        "context": "tic goal generation(Florensa et\u00a0al.,2018)all cen"
      },
      {
        "_from": "sections/sec_95e6043e",
        "_to": "entities/ent_da6b6361",
        "context": "tinuously evolving. Generative adversarial network"
      },
      {
        "_from": "sections/sec_247e121e",
        "_to": "entities/ent_da6b6361",
        "context": "tinuously evolving. Generative adversarial network"
      },
      {
        "_from": "sections/sec_95e6043e",
        "_to": "entities/ent_9065df87",
        "context": "dversarial networks(Goodfellow et\u00a0al.,2020), also "
      },
      {
        "_from": "sections/sec_247e121e",
        "_to": "entities/ent_9065df87",
        "context": "dversarial networks(Goodfellow et\u00a0al.,2020), also "
      },
      {
        "_from": "sections/sec_95e6043e",
        "_to": "entities/ent_90b74dd3",
        "context": "ntly, SPIN and Self-Rewarding Language Models(Chen et\u00a0al.,2024;Yu"
      },
      {
        "_from": "sections/sec_247e121e",
        "_to": "entities/ent_90b74dd3",
        "context": "ntly, SPIN and Self-Rewarding Language Models(Chen et\u00a0al.,2024;Yu"
      },
      {
        "_from": "sections/sec_95e6043e",
        "_to": "entities/ent_428648f9",
        "context": "e LLM for alignment.Kirchner et\u00a0al.(2024)uses Pr"
      },
      {
        "_from": "sections/sec_247e121e",
        "_to": "entities/ent_428648f9",
        "context": "e LLM for alignment.Kirchner et\u00a0al.(2024)uses Pr"
      },
      {
        "_from": "sections/sec_95e6043e",
        "_to": "entities/ent_8beb8be3",
        "context": "l.(2024)uses Prover-Verifier Game for increasing legi"
      },
      {
        "_from": "sections/sec_247e121e",
        "_to": "entities/ent_8beb8be3",
        "context": "l.(2024)uses Prover-Verifier Game for increasing legi"
      },
      {
        "_from": "sections/sec_95e6043e",
        "_to": "entities/ent_1e693308",
        "context": "in specific game of Adversarial Taboo. Concurrent works\u2014G"
      },
      {
        "_from": "sections/sec_247e121e",
        "_to": "entities/ent_1e693308",
        "context": "in specific game of Adversarial Taboo. Concurrent works\u2014G"
      },
      {
        "_from": "sections/sec_95e6043e",
        "_to": "entities/ent_3aee7460",
        "context": " Adversarial Taboo. Concurrent works\u2014Genius, EMPO,"
      },
      {
        "_from": "sections/sec_247e121e",
        "_to": "entities/ent_3aee7460",
        "context": " Adversarial Taboo. Concurrent works\u2014Genius, EMPO,"
      },
      {
        "_from": "sections/sec_95e6043e",
        "_to": "entities/ent_7ec5b99e",
        "context": "o. Concurrent works\u2014Genius, EMPO, and TTRL(Xu "
      },
      {
        "_from": "sections/sec_247e121e",
        "_to": "entities/ent_7ec5b99e",
        "context": "o. Concurrent works\u2014Genius, EMPO, and TTRL(Xu "
      },
      {
        "_from": "sections/sec_95e6043e",
        "_to": "entities/ent_a603e92e",
        "context": "tribution. Finally, Minimo(Poesia et\u00a0al.,2024)"
      },
      {
        "_from": "sections/sec_247e121e",
        "_to": "entities/ent_a603e92e",
        "context": "tribution. Finally, Minimo(Poesia et\u00a0al.,2024)"
      },
      {
        "_from": "sections/sec_95e6043e",
        "_to": "entities/ent_4b7e8830",
        "context": "on. Finally, Minimo(Poesia et\u00a0al.,2024)extends"
      },
      {
        "_from": "sections/sec_247e121e",
        "_to": "entities/ent_4b7e8830",
        "context": "on. Finally, Minimo(Poesia et\u00a0al.,2024)extends"
      },
      {
        "_from": "sections/sec_95e6043e",
        "_to": "entities/ent_7324e372",
        "context": "to facilitate RLVR. Weak-to-Strong Supervisi"
      },
      {
        "_from": "sections/sec_95e6043e",
        "_to": "entities/ent_db9a2167",
        "context": "itate RLVR. Weak-to-Strong Supervision.The concept of weak"
      },
      {
        "_from": "sections/sec_95e6043e",
        "_to": "entities/ent_590f62b3",
        "context": "des useful guidance(Burns et\u00a0al.,2024;Hinton "
      },
      {
        "_from": "sections/sec_5aa2a6bb",
        "_to": "entities/ent_590f62b3",
        "context": "des useful guidance(Burns et\u00a0al.,2024;Hinton "
      },
      {
        "_from": "sections/sec_95e6043e",
        "_to": "entities/ent_98d2ef46",
        "context": "e(Burns et\u00a0al.,2024;Hinton et\u00a0al.,2015;Christi"
      },
      {
        "_from": "sections/sec_5aa2a6bb",
        "_to": "entities/ent_98d2ef46",
        "context": "e(Burns et\u00a0al.,2024;Hinton et\u00a0al.,2015;Christi"
      },
      {
        "_from": "sections/sec_95e6043e",
        "_to": "entities/ent_8f470864",
        "context": ";Hinton et\u00a0al.,2015;Christiano,2018;2019;Demski & "
      },
      {
        "_from": "sections/sec_5aa2a6bb",
        "_to": "entities/ent_8f470864",
        "context": ";Hinton et\u00a0al.,2015;Christiano,2018;2019;Demski & "
      },
      {
        "_from": "sections/sec_95e6043e",
        "_to": "entities/ent_197db0da",
        "context": "hristiano,2018;2019;Demski & Garrabrant,2019;L"
      },
      {
        "_from": "sections/sec_5aa2a6bb",
        "_to": "entities/ent_197db0da",
        "context": "hristiano,2018;2019;Demski & Garrabrant,2019;L"
      },
      {
        "_from": "sections/sec_95e6043e",
        "_to": "entities/ent_a0aace70",
        "context": ",2018;2019;Demski & Garrabrant,2019;Leike & Sutske"
      },
      {
        "_from": "sections/sec_5aa2a6bb",
        "_to": "entities/ent_a0aace70",
        "context": ",2018;2019;Demski & Garrabrant,2019;Leike & Sutske"
      },
      {
        "_from": "sections/sec_95e6043e",
        "_to": "entities/ent_8321eb6d",
        "context": "i & Garrabrant,2019;Leike & Sutskever,2023;Hu"
      },
      {
        "_from": "sections/sec_5aa2a6bb",
        "_to": "entities/ent_8321eb6d",
        "context": "i & Garrabrant,2019;Leike & Sutskever,2023;Hu"
      },
      {
        "_from": "sections/sec_95e6043e",
        "_to": "entities/ent_61b9dceb",
        "context": "ke & Sutskever,2023;Hubinger et\u00a0al.,2019). We co"
      },
      {
        "_from": "sections/sec_5aa2a6bb",
        "_to": "entities/ent_61b9dceb",
        "context": "ke & Sutskever,2023;Hubinger et\u00a0al.,2019). We co"
      },
      {
        "_from": "sections/sec_ab2bd446",
        "_to": "entities/ent_6f8b794f",
        "context": "Conclusion.In this work, we pr"
      },
      {
        "_from": "sections/sec_ab2bd446",
        "_to": "entities/ent_a0da16a9",
        "context": " reasoning domains. Remarkably, even though our mo"
      },
      {
        "_from": "sections/sec_97b161c9",
        "_to": "entities/ent_a0da16a9",
        "context": " reasoning domains. Remarkably, even though our mo"
      }
    ]
  }
}